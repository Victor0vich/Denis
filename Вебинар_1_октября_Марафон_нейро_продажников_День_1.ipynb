{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victor0vich/Denis/blob/main/%D0%92%D0%B5%D0%B1%D0%B8%D0%BD%D0%B0%D1%80_1_%D0%BE%D0%BA%D1%82%D1%8F%D0%B1%D1%80%D1%8F_%D0%9C%D0%B0%D1%80%D0%B0%D1%84%D0%BE%D0%BD_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE_%D0%BF%D1%80%D0%BE%D0%B4%D0%B0%D0%B6%D0%BD%D0%B8%D0%BA%D0%BE%D0%B2_%D0%94%D0%B5%D0%BD%D1%8C_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekCriGf1FFbx"
      },
      "source": [
        "# Схема агентов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w260Of6uQCIe"
      },
      "source": [
        "                    \n",
        "\n",
        "```\n",
        "\n",
        "                      |Агент Отчета о потребностях|\n",
        "      _____________________________|__________________________________________\n",
        "     |                             |                                          |\n",
        "     |                             |                              |Агент Презентации и ПВ|\n",
        "     |                 |Агент Выявления Возражений|                           |\n",
        "     |                             |                                |Агент Стилизации 2|\n",
        "     |                             |                                          |\n",
        "     |                            / \\                                |Агент Консультант|  \n",
        "     |                           /   \\\n",
        "     |  |Агент Выявления вопросов|   |Агент Преодоления возражений|                       \n",
        "     |                 |                             |\n",
        "     |         |Агент Консультант|                   |          \n",
        "     |                 |                             |                         \n",
        "     |         |Агент Стилизации 1|                  |\n",
        "     |                 |_____________________________|    \n",
        "     |                             |      \n",
        "     |                    |Агент Потребностей|                         \n",
        "     |_____________________________|                   \n",
        "                        \n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml1ktWx6pneN"
      },
      "source": [
        "* `Агент Выявления возражений` - этот агент выявляет возражения в сообщении клиента\n",
        "\n",
        "* `Агент Отчета о потребностях` - этот агент создает отчет о потребностях\n",
        "\n",
        "* `Агент Потребностей` - этот агент формулирует вопросы для выявления потребностей клиента\n",
        "\n",
        "* `Агент Выявления вопросов` - этот агент определяет клиент размышляет/отвечает или задает вопрос. Если размышляет/отвечает, то эти размышления переделываются в форму вопроса перед подачей в `Агент Консультант`. Если клиент задает вопрос, то этот вопрос без изменений подается в `Агент Консультант`\n",
        "\n",
        "* `Агент Закрытия возражений` - этот агент на основании выявленного возражения формулирует сообщение, закрывающее это возражение\n",
        "\n",
        "* `Агент Консультант` - этот агент формирует ответы на основании базы знаний УИИ\n",
        "\n",
        "* `Агент Презентации` - этот агент формирует презентацию опираясь на отчет по потребностям\n",
        "\n",
        "* `Агент Стилизации 1` - этот агент \"причесывает\" итоговый ответ после `Агент Консультант`, убирая лишнее\n",
        "\n",
        "* `Агент Стилизации 2` - этот агент \"причесывает\" итоговый ответ в стиле продажи после `Агент Презентации`, убирая лишнее\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RayCjCyvv2FR",
        "outputId": "eb938fe6-8d73-4821-91a7-2ca849a67be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain==0.0.330\n",
            "  Downloading langchain-0.0.330-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (3.10.5)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.330)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.330)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.52 (from langchain==0.0.330)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (2.32.3)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.330)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (1.11.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.330) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.330) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.330) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.330)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.330)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.330)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.330) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.330) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.330) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.330) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.330) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.330) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.330) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.330)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.0.330-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, mypy-extensions, marshmallow, jsonpointer, faiss-cpu, typing-inspect, tiktoken, jsonpatch, langsmith, dataclasses-json, openai, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.8.0.post1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.0.330 langsmith-0.0.92 marshmallow-3.22.0 mypy-extensions-1.0.0 openai-0.28.1 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "#@title Установка и импорт библиотек\n",
        "\n",
        "!pip install tiktoken langchain==0.0.330 openai==0.28.1 faiss-cpu\n",
        "\n",
        "import textwrap\n",
        "import zipfile\n",
        "\n",
        "# Модуль для работы с функциями, связанными с паролями\n",
        "import getpass\n",
        "\n",
        "# Модуль для загрузки файлов из Google Drive\n",
        "import gdown\n",
        "\n",
        "\n",
        "# Модуль для работы с файловой системой и операционной системой\n",
        "import os\n",
        "\n",
        "# Модуль для работы с регулярными выражениями\n",
        "import re\n",
        "\n",
        "# Библиотека для работы с API OpenAI\n",
        "import openai\n",
        "\n",
        "# Модуль для создания глубоких копий объектов\n",
        "import copy\n",
        "\n",
        "# Импортируем стандартный модуль time, который предоставляет функции для работы с временем\n",
        "import time\n",
        "\n",
        "# Модуль для работы с токенизацией текста\n",
        "import tiktoken\n",
        "\n",
        "# Импортируем загрузчик текстовых документов из langchain\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# Импортируем прогресс-бар для Jupyter Notebook\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "# Модуль для работы с сериализацией и десериализацией объектов\n",
        "import pickle\n",
        "\n",
        "# Импортируем модель OpenAI из langchain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Импортируем класс Document из langchain для работы с документами\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# Библиотека для выполнения HTTP-запросов\n",
        "import requests\n",
        "\n",
        "# Импортируем класс для создания эмбеддингов с помощью OpenAI из langchain\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "# Импортируем класс FAISS для работы с векторными индексами из langchain\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Импортируем класс для рекурсивного разделения текста на фрагменты из langchain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Игнорирование предупреждений\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Настройка логирования для модуля text_splitter из langchain\n",
        "import logging\n",
        "logging.getLogger(\"langchain.text_splitter\").setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r4c1yT1v4jO",
        "outputId": "41cbfb2f-08ce-41be-91a4-92739f789623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ],
      "source": [
        "# Получение ключа API OpenAI от пользователя\n",
        "# Функция getpass.getpass() запрашивает ввод пароля или ключа без отображения ввода на экране\n",
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "\n",
        "# Установка ключа API в переменную окружения\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "\n",
        "# Установка ключа API для использования библиотекой openai\n",
        "openai.api_key = openai_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhMx1N6X1nLd"
      },
      "source": [
        "## Агент Консультант для ответов на вопросы по базе знаний"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KbMXDINyppmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882b86f3-a37b-428d-cba7-12d262e9ab0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=116pmFdDoPxmYRy-K1FPyUOLYQ7g6ftmq\n",
            "To: /content/index.zip\n",
            "100%|██████████| 8.21M/8.21M [00:00<00:00, 58.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title Загружаем базу знаний\n",
        "\n",
        "# Указание URL-адреса файла и путь для скачивания\n",
        "url = \"https://drive.google.com/uc?id=116pmFdDoPxmYRy-K1FPyUOLYQ7g6ftmq\"\n",
        "output_zip = \"index.zip\"  # Имя архива после скачивания\n",
        "\n",
        "# Скачивание файла\n",
        "gdown.download(url, output=output_zip, quiet=False)\n",
        "\n",
        "# Создание папки для распаковки (если не существует)\n",
        "output_folder = \"HistoryUII\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Разархивирование содержимого в папку UII\n",
        "with zipfile.ZipFile(output_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_folder)\n",
        "\n",
        "\n",
        "def create_search_index(db_path, course):\n",
        "    # Путь к файлу index.faiss\n",
        "    faiss_file = os.path.join(db_path, course, 'index.faiss')\n",
        "    #print(faiss_file)\n",
        "\n",
        "    # Загрузка базы данных FAISS\n",
        "    db = FAISS.load_local('/content/HistoryUII/', OpenAIEmbeddings())\n",
        "\n",
        "    return db\n",
        "\n",
        "# У вас только один курс\n",
        "course = 'HistoryUII'\n",
        "faiss_db_dir = \"/content/\"\n",
        "\n",
        "# Загружаем индекс\n",
        "search_index = create_search_index(faiss_db_dir, course)\n",
        "\n",
        "db = search_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MIPBJMhYnogG"
      },
      "outputs": [],
      "source": [
        "#@title Функция для получения ответа на вопрос на основе заданной темы и поискового индекса\n",
        "def answer_kons(system, instruction, topic, search_index, summary_history, temp=1, verbose=0, k=8, model=\"gpt-3.5-turbo-16k\"):\n",
        "    \"\"\"\n",
        "    Функция для получения ответа на вопрос на основе заданной темы и поискового индекса.\n",
        "\n",
        "    Параметры:\n",
        "    system (str): Промт.\n",
        "    instruction (str): Инструкция для пользователя.\n",
        "    topic (str): Тема или вопрос, на который нужно ответить.\n",
        "    search_index (object): Векторная база.\n",
        "    temp (float): Температура для генерации ответов модели (по умолчанию 1).\n",
        "    verbose (int): Флаг для включения/выключения подробного вывода (по умолчанию 0).\n",
        "    k (int): Количество похожих документов для поиска (по умолчанию 8).\n",
        "    model (str): Имя модели, используемой для генерации ответов (по умолчанию \"gpt-3.5-turbo-16k\").\n",
        "    \"\"\"\n",
        "\n",
        "    # Поиск документов, похожих на заданную тему/вопрос\n",
        "    docs = search_index.similarity_search(topic, k=k)\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель\n",
        "    #if verbose: print('\\n ========\\n')\n",
        "\n",
        "    # Создание содержимого сообщения, объединяя текст найденных документов\n",
        "    message_content = re.sub(r'\\r\\n', ' ', '\\n '.join([f'\\n--------------------\\n' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
        "\n",
        "    # Если включен подробный вывод, напечатать содержимое сообщения\n",
        "    if verbose: print('Чанки :\\n ======================================== \\n', message_content)\n",
        "\n",
        "    # Формирование сообщений для модели\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f\"{instruction}.\\n{message_content}.\\n\\nВопрос:\\n{topic}\\n\\nХронология предыдущих сообщений диалога: {summary_history}\\n\\nОтвет:\"}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    # Создание запроса к модели OpenAI\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,  # Имя модели\n",
        "        messages=messages,  # Сообщения для модели\n",
        "        temperature=temp  # Температура генерации\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель\n",
        "    #if verbose: print('\\n =========================================== ')\n",
        "\n",
        "\n",
        "    # Получение ответа от модели\n",
        "    answer = completion.choices[0].message.content\n",
        "    #print()\n",
        "    #print()\n",
        "    #print(\"Полный ответ от GPT:\")\n",
        "    #print(completion)\n",
        "    print('\\n==================')\n",
        "    print(\"Агент консультант:\")\n",
        "    # Форматирование ответа для удобства чтения\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    print(formatted_answer)\n",
        "    #print(f\"Количество использованных токенов на запрос: {completion['usage']['prompt_tokens']}\")\n",
        "    #print(f\"Количество использованных токенов на ответ: {completion['usage']['completion_tokens']}\")\n",
        "    #print(f\"Общее количество использованных токенов (вопрос-ответ): {completion['usage']['total_tokens']}\")\n",
        "    #print()\n",
        "    # Округляем результат до 5 знаков после запятой\n",
        "    price = round((5 * completion['usage']['prompt_tokens'] / 1000000) +\n",
        "                  (15 * completion['usage']['completion_tokens'] / 1000000), 5)\n",
        "\n",
        "    print('ЦЕНА запроса:', price, ' $')\n",
        "    print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "def answer_kons_d(system, instruction, topic, search_index, summary_history, temp=1, verbose=0, k=8, model=\"gpt-3.5-turbo-16k\"):\n",
        "    \"\"\"\n",
        "    Функция для получения ответа на вопрос на основе заданной темы и поискового индекса.\n",
        "\n",
        "    Параметры:\n",
        "    system (str): Промт.\n",
        "    instruction (str): Инструкция для пользователя.\n",
        "    topic (str): Тема или вопрос, на который нужно ответить.\n",
        "    search_index (object): Векторная база.\n",
        "    temp (float): Температура для генерации ответов модели (по умолчанию 1).\n",
        "    verbose (int): Флаг для включения/выключения подробного вывода (по умолчанию 0).\n",
        "    k (int): Количество похожих документов для поиска (по умолчанию 8).\n",
        "    model (str): Имя модели, используемой для генерации ответов (по умолчанию \"gpt-3.5-turbo-16k\").\n",
        "    \"\"\"\n",
        "\n",
        "    # Поиск документов, похожих на заданную тему/вопрос\n",
        "    docs = search_index.similarity_search(topic, k=k)\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель\n",
        "    #if verbose: print('\\n ========\\n')\n",
        "\n",
        "    # Создание содержимого сообщения, объединяя текст найденных документов\n",
        "    message_content = re.sub(r'\\r\\n', ' ', '\\n '.join([f'\\n--------------------\\n' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
        "\n",
        "    # Если включен подробный вывод, напечатать содержимое сообщения\n",
        "    if verbose: print('Чанки :\\n ======================================== \\n', message_content)\n",
        "\n",
        "    # Формирование сообщений для модели\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f\"{instruction}.\\n{message_content}.\\n\\nВопрос:\\n{topic}\\n\\nХронология предыдущих сообщений диалога: {summary_history}\\n\\nОтвет:\"}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    # Создание запроса к модели OpenAI\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,  # Имя модели\n",
        "        messages=messages,  # Сообщения для модели\n",
        "        temperature=temp  # Температура генерации\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель\n",
        "    #if verbose: print('\\n =========================================== ')\n",
        "\n",
        "\n",
        "    # Получение ответа от модели\n",
        "    answer = completion.choices[0].message.content\n",
        "    #print()\n",
        "    #print()\n",
        "    #print(\"Полный ответ от GPT:\")\n",
        "    #print(completion)\n",
        "    print('\\n==================')\n",
        "    print(\"Агент консультант:\")\n",
        "    # Форматирование ответа для удобства чтения\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    print(formatted_answer)\n",
        "    #print(f\"Количество использованных токенов на запрос: {completion['usage']['prompt_tokens']}\")\n",
        "    #print(f\"Количество использованных токенов на ответ: {completion['usage']['completion_tokens']}\")\n",
        "    #print(f\"Общее количество использованных токенов (вопрос-ответ): {completion['usage']['total_tokens']}\")\n",
        "    #print()\n",
        "    # Округляем результат до 5 знаков после запятой\n",
        "    price = round((5 * completion['usage']['prompt_tokens'] / 1000000) +\n",
        "                  (15 * completion['usage']['completion_tokens'] / 1000000), 5)\n",
        "\n",
        "    print('ЦЕНА запроса:', price, ' $')\n",
        "    print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOzY06DGBy0o"
      },
      "source": [
        "Промт и инструкция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZGqrK4DEwWY"
      },
      "outputs": [],
      "source": [
        "# Подгружаем промт\n",
        "system = ''' # Ты профессиональный помощник в чате компании Университета Искусственного интеллекта.\n",
        "\n",
        "\n",
        "## 1. Общие обязанности и цели - Компания продает курсы по AI. У компании есть большой документ со всеми материалами\n",
        "о продуктах компании. - Твоя обязанность: Дать Клиенту краткий корректный ответ на русском языке в чате, опираясь на отрывки\n",
        "из этого документа. - Твоя цель: Отвечать максимально кратко и точно по документу, не придумывать ничего от себя.\n",
        "\n",
        "\n",
        "## 2. Ограничения в общении - Запрещено общаться на стороннюю тему. Если Клиент задает стороннюю тему, спрашивает не\n",
        "по теме искусственного интеллекта и программирования, не по материалам и продуктам Компании, ты категорически отказываешься\n",
        "отвечать.\n",
        "\n",
        "\n",
        "## 3. Секретность документа\n",
        "- Запрещено упоминать в ответе, что ты анализировал отрывки документов и брал оттуда информацию.\n",
        "\n",
        "\n",
        "## Обрати внимание: курс по созданию нейроконсультантов - это курс \"Нейро-сотрудники\",\n",
        "## жпт - это chatGPT, если клиент употребляет слово жпт, понимай это слово как chatGPT '''\n",
        "\n",
        "# Инструкция для модели о том, как использовать контекст для ответа на вопрос\n",
        "instruction = '''Проанализируй предыдущий диалог чтобы написать свой ответ последовательным и логичным.\n",
        "Категорически запрещено повторяться и здороваться.\n",
        "Используйте следующие фрагменты контекста, чтобы ответить на вопрос в конце.\n",
        "Стилистика ответа должна быть поддерживающей беседу в контексте важности и полезности изучения искусственного интеллекта и программирования.\n",
        "Если вы не знаете ответа, просто скажите, что не знаете, не пытайтесь придумывать ответ.\n",
        "Тебе запрещено продавать, предлагать курсы. Запрещено спрашивать клиента что его еще интересует.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxexybqtBu55"
      },
      "source": [
        "Параметры для запроса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2cFqkdZDWiL"
      },
      "outputs": [],
      "source": [
        "# Задаем температуру генерации ответа\n",
        "# Температура 0 означает, что модель будет давать более детерминированные ответы, строго опираясь на предоставленный контекст\n",
        "temperature = 0\n",
        "\n",
        "# Задаем количество релевантных чанков (фрагментов текста) для формирования ответа\n",
        "relevant_chanks = 3\n",
        "\n",
        "# Флаг для включения/выключения вывода релевантных чанков\n",
        "verbose = 1\n",
        "\n",
        "# Имя модели, используемой для генерации ответов\n",
        "model = \"gpt-4o\"\n",
        "\n",
        "# История диалога\n",
        "\n",
        "history = [\"\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiktJDd_nVgg"
      },
      "source": [
        "Запрос"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Тема или вопрос, на который нужно получить ответ\n",
        "topic = \"Какая стоимость курса ChatGPT Professional light?\""
      ],
      "metadata": {
        "id": "QTid3LoLGOJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FwpIytale_1",
        "outputId": "02142334-aa4a-4fe4-8065-d730a56f6c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Чанки :\n",
            " ======================================== \n",
            " \n",
            "--------------------\n",
            "#### ChatGPT Professioal LIGHT+\n",
            " Стоимость тарифа составляет: 179 900\n",
            " Продолжительность курса: 11 месяцев\n",
            "В тариф входит:\n",
            "    - поддержка куратора в течение всего курса\n",
            "    - Курс нейро-сотрудники (6 занятий)\n",
            "    - Курс Python разработчик (36 занятий)\n",
            "    - 2 новых курса на выбор (10 занятий)\n",
            "    - Гарантия трудоустройства\n",
            "Количество мест на тарифе ограничено. УИИ набирает только 10 студентов на каждый поток тарифа\n",
            "\n",
            "#### ChatGPT Professional PRO+\n",
            "      Стоимость тарифа составляет: 239 900 рублей\n",
            "      Продолжительность курса: 11 месяцев \n",
            "Иерархия фрагмента текста в документе: # Университет Искусственного Интеллекта ## Формат курса СhatGPT Professional в записи и дата старта курса ### Стоимость курса ChatGPT Professional в записи и тарифы курса: #### ChatGPT Professional PRO+\n",
            "\n",
            " \n",
            "--------------------\n",
            "Тариф “AI под ключ” идеально подходит для компаний с проектом или для тех, кто предпочитает проходить курс индивидуально.\n",
            "Так же он подходит студентам, которые хотят пройти обучение на английском языке.\n",
            "В тариф входит гарантия трудоустройства. \n",
            "\n",
            "## Тарифы курса ChatGPT Professional:\n",
            "\n",
            "### Тариф “Professional light”\n",
            "Стоимость тарифа “Professional light” составляет 149 900 рублей\n",
            "Продолжительность прохождения курса: 9 месяцев \n",
            "Иерархия фрагмента текста в документе: # - 5.958 ## Тарифы курса ChatGPT Professional: ### Тариф “Professional light” пункт 19.\n",
            "\n",
            " \n",
            "--------------------\n",
            "#### Тариф ChatGPT Professional light\n",
            "Стоимость: 149 900 рублей\n",
            "Продолжительность курса: 11 месяцев\n",
            "В тариф входит поддержка куратора в течение всего прохождения курса\n",
            "\n",
            "#### Тариф ChatGPT Professional PRO\n",
            "Стоимость: 209 900 рублей\n",
            "Продолжительность курса: 11 месяцев\n",
            "Состав тарифа: \n",
            "- поддержка куратора, \n",
            "- 20 zoom консультаций с тимлидами и кураторами,\n",
            "- 4 стажировки длительностью по 3 месяца каждая. \n",
            "Стажировка представляет собой создание реального проекта в группе из 15-20 человек. Еженедельно студенты будут созваниваться с тимлидом в zoom. \n",
            "\n",
            "#### Тариф Professional PRO MAX \n",
            "Стоимость: 299 900\n",
            "Состав тарифа: 45 занятий по ChatGPT, 3 года куратора, 4 стажировки, 60 zoom-консультаций с куратором, помощь в создании ChatGPT проекта, курс Python-разработчик, курс LLM тестировщик, курс по SQL, курс фишки речевых моделей, гарантия трудоустройства \n",
            "Иерархия фрагмента текста в документе: # Университет Искусственного Интеллекта ## Формат курса СhatGPT Professional в записи и дата старта курса ### Стоимость курса ChatGPT Professional в записи и тарифы курса: #### Тариф Professional PRO MAX \n",
            "\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Стоимость курса ChatGPT Professional light составляет 149 900 рублей.\n",
            "ЦЕНА запроса: 0.00562  $\n",
            "Время ответа: 0.40 секунд\n"
          ]
        }
      ],
      "source": [
        "answer_kons(system, instruction, topic, db, history, temperature, verbose, relevant_chanks, model);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1PX07khGzcH"
      },
      "source": [
        "Запрос"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Тема или вопрос, на который нужно получить ответ\n",
        "topic = \"Что такое выкуп стоимости?\""
      ],
      "metadata": {
        "id": "QL6jQcwTGzcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41acc882-3ba7-43e5-c3ba-9b414e005a47",
        "id": "BH-U2MiFGzcH"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Чанки :\n",
            " ======================================== \n",
            " \n",
            "--------------------\n",
            "### Условия выкупа стоимости прохождения курса\n",
            "Студентам предоставляется возможность вернуть всю стоимость курса и трудоустроиться в УИИ после прохождения программы. \n",
            "Гарантия трудоустройства прописана в договоре. Возможность трудоустроиться предоставляется на следующий день после защиты диплома. Таким образом, студент возвращает всю стоимость курса в виде заработной платы. На выкуп стоимости открывается 10 мест. Более 150 студентов уже вернули стоимость своего курса.\n",
            "Все условия выкупа прописаны в отдельном дополнительном соглашении.\n",
            "Чтобы ознакомиться с дополнительным соглашением на выкуп стоимости курса от УИИ, необходимо обратиться к менеджеру УИИ.\n",
            "Необходимо в полном объеме программу курса, в том числе выполнить все без исключения домашние задания продвинутого (Pro) уровня сложности к каждому занятию не более чем за 10 месяцев пользованием платформой или за определенное сторонами Договора количество занятий (промежуточные аттестации), успешно защитить нейросетевой проект, предусмотренный курсом. \n",
            "Иерархия фрагмента текста в документе: # Список курсов по компьютерному зрению (CV) от УИИ: ## Выкуп стоимости прохождения курса ### Условия выкупа стоимости прохождения курса пункт 5.\n",
            "\n",
            " \n",
            "--------------------\n",
            "### Примеры студентов, которые получили выкуп стоимости курса \n",
            "1. Светлана Лунева - создает фреймворк по генетическим алгоритмам. \n",
            "«Сила Университета - в преподавателях, которые умеют объяснить сложные вещи простым языком, в огромном количестве учебных материалов, где можно найти ответы на все вопросы, и в замечательных кураторах, к которым можно обращаться 1 на 1, а не в группе в слаке, где порой стесняешься задавать глупые вопросы.\n",
            "Честно признаться, я боялась, что что-то пойдет не так, и мне не удастся начать работать в УИИ, но, к моему удивлению, все прошло просто отлично. Мне во многом пошли на встречу - я попросилась работать не целый день, а рабочий день я могла начинать позже, чем по Москве - все это было без проблем учтено. В итоге - 4 месяца оплачиваемой работы в университете на половину рабочей ставки. Большим плюсом для меня является тот факт, что можно самостоятельно решать, в какое время работать - главное, это справляться с поставленными на неделю задачами. \n",
            "Иерархия фрагмента текста в документе: # Список курсов по компьютерному зрению (CV) от УИИ: ## Выкуп стоимости прохождения курса ### Примеры студентов, которые получили выкуп стоимости курса \n",
            "\n",
            " \n",
            "--------------------\n",
            "### Студенты, на которых распространяется выкуп стоимости\n",
            "Выкуп стоимости распространяется на студентов из всех стран и его условия одинаковы для студентов из всех стран.\n",
            "Выкуп стоимости прохождения курса не зависит от страны проживания студента.\n",
            "Выкуп стоимости распространяется на студентов курсов «Data Science и нейронные сети, машинное обучение и искусственный интеллект» и «Python-разработчик», в которых предусмотрена обязательная аттестация.\n",
            "\n",
            "### Возможность обучиться фактически бесплатно по выкупу стоимости.\n",
            "Для того чтобы обучиться бесплатно, необходимо сделать 5 шагов:\n",
            "1. Оформить рассрочку по любому тарифу\n",
            "2. Добавить отложенный платеж на 7 месяцев\n",
            "3. Пройти программу курса по AI за 6 месяцев\n",
            "4. Начать работу в УИИ по выкупу стоимости курса\n",
            "5. Осуществить первый платеж с зарплаты AI разработчика \n",
            "Иерархия фрагмента текста в документе: # Список курсов по компьютерному зрению (CV) от УИИ: ## Выкуп стоимости прохождения курса ### Возможность обучиться фактически бесплатно по выкупу стоимости.\n",
            "\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Выкуп стоимости — это возможность для студентов вернуть всю стоимость курса после его завершения. Для этого необходимо\n",
            "успешно пройти программу, выполнить все задания и защитить дипломный проект. После этого студент может трудоустроиться в\n",
            "Университете Искусственного Интеллекта, и заработная плата покроет стоимость курса.\n",
            "ЦЕНА запроса: 0.00737  $\n",
            "Время ответа: 1.56 секунд\n"
          ]
        }
      ],
      "source": [
        "answer_kons(system, instruction, topic, db, history, temperature, verbose, relevant_chanks, model);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "HYYbJNnwZZVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Тема или вопрос, на который нужно получить ответ\n",
        "topic = \"Сколько времени необходимо для обучения?\""
      ],
      "metadata": {
        "id": "NISTdizLMjR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f45dee8-7ed5-4f63-eaf8-bc00c54959c5",
        "id": "zrtWTcgOMjSA"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Чанки :\n",
            " ======================================== \n",
            " \n",
            "--------------------\n",
            "Дефицит времени достаточно распространенная проблема в современном мире. Известно, что дефицит времени у людей встречается чаще, чем дефицит денег.\n",
            "Образовательный процесс в УИИ выстроен таким образом, чтобы проходить курс в удобное время, не отвлекаясь от профессиональных и домашних дел. Студенту потребуется минимум 4 часа, а лучше 10 часов в неделю, которые включают в себя 2 часа теории, 2 часа практических занятий и 6 часов выполнения домашнего задания или стажировки. Все, что необходимо от студента - желание освоить новые знания, так как проходить курс возможно в обеденный перерыв на работе, в дороге, в очереди. Видеоуроки открываются в том месте, где студент остановил просмотр. По подсчетам УИИ, курс занимает всего 7 % времени в неделю.\n",
            "\n",
            "В среднем, распределение времени человека в возрасте 35-40 лет происходит так:\n",
            "35% - работа\n",
            "37% - семья и друзья\n",
            "13% - отдых (кино, кафе, отпуск)\n",
            "8% - хобби (занятия творчеством,спортом)\n",
            "7% - прохождение курсов (10 часов в неделю) \n",
            "Иерархия фрагмента текста в документе: # Университет Искусственного Интеллекта ## Как найти время на прохождение курсов:\n",
            "\n",
            " \n",
            "--------------------\n",
            "Информация для закрытия возражения:\n",
            "Удобный формат наших курсов позволит любому человеку найти время\n",
            "1. Для прохождения курса вам нужно всего 10 часов в неделю\n",
            "2. Гибкий график курса: проходите занятия когда вам удобно\n",
            "3. Заниматься можно в любом комфортном для вас месте, даже в дороге с телефона\n",
            "4. Мы можем предоставить вам гибкую систему заморозок, если возникнет необходимость\n",
            "5. В самом начале можно уделять прохождению курса 2-3 часа в неделю, постепенно увеличивая количество часов до 10     \n",
            "6. У нас нет дедлайнов по домашним заданиям и урокам - заниматься можно когда угодно\n",
            "7. Средний возраст студентов -- 35-40 лет. То есть, это занятые люди, которые смогли совместить прохождение курса, работу, семью и хобби\n",
            "\n",
            "## Возражение: Не смогу проходить программу, потому что нет опыта программирования и знаний математики \n",
            "Иерархия фрагмента текста в документе: # Пример сроков проекта по созданию нейро-менеджера чата УИИ ## Возражение: Не смогу проходить программу, потому что нет опыта программирования и знаний математики\n",
            "\n",
            " \n",
            "--------------------\n",
            "Представьте, что каждый год многие тратят 1200 часов на дорогу до работы в Москве. Это огромное количество времени, которое можно потратить на что-то более значимое. Теперь представьте, что курс УИИ занимает всего 320 часов, что является всего лишь долей от общего времени, которое вы тратите на дорогу каждый год.\n",
            "Cтудентам, прошедшим курс УИИ, не придется больше тратить время на дорогу до работы. Благодаря возможности работать удаленно, они сэкономят целых 1200 часов в год. Время, которое студенты вложили в прохождение курса УИИ, вернется к ним в виде свободы и дополнительных возможностей \n",
            "Иерархия фрагмента текста в документе: # Университет Искусственного Интеллекта ## Прохождение курса в УИИ позволяет сэкономить время в будущем пункт 3.\n",
            "\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Для обучения необходимо выделять минимум 4 часа в неделю, а лучше 10 часов. Это включает 2 часа теории, 2 часа\n",
            "практических занятий и 6 часов на выполнение домашних заданий или стажировки.\n",
            "ЦЕНА запроса: 0.00667  $\n",
            "Время ответа: 1.55 секунд\n"
          ]
        }
      ],
      "source": [
        "answer_kons(system, instruction, topic, db, history, temperature, verbose, relevant_chanks, model);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Агент Отчета о потребностях"
      ],
      "metadata": {
        "id": "aPVwBtk3elq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Функция для отчета о потребностях\n",
        "def user_question_router(system, instructions, topic, temp=0, verbose=0, model='gpt-3.5-turbo-1106'):\n",
        "    #if verbose: print('\\n==================\\n')\n",
        "    #if verbose: print('Саммари диалога:\\n==================\\n',\n",
        "                      #topic)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "                                      \\n\\nВопрос менеджера и ответ клиента:\\n{topic}.\n",
        "                                      \\n\\nОтвет: '''}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    answer = completion.choices[0].message.content\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    #print(f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Агент Отчета о потребностях:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "\n",
        "    # Округляем результат до 5 знаков после запятой\n",
        "    price = round((5 * completion['usage']['prompt_tokens'] / 1000000) +\n",
        "                  (15 * completion['usage']['completion_tokens'] / 1000000), 5)\n",
        "\n",
        "    print('ЦЕНА запроса:', price, ' $')\n",
        "    print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Функция суммарной потребности\n",
        "def user_potr(potr_history, temp=0, verbose=0, model= \"gpt-4o\"):\n",
        "    resulting_string = \", \".join(potr_history)\n",
        "    completion_prez = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "        {\"role\": \"system\", \"content\": \"\"\"Вы лучший менеджер по продажам.\n",
        "Вы понимаете какие потребности клиента надо выявить, чтобы полностью понять желания и боли клиента,\n",
        "которые можно удовлетворить при помощи обучения искусственному интеллекту и программированию.\n",
        "Вы знаете, что важно выявить есть ли у клиента такие потребности: в трудоустройстве, в росте дохода,\n",
        "в возможности работать удаленно, развиваться в сфере IT, сменить деятельность, в карьерном росте, во фрилансе,\n",
        "в улучшении текущей позиции в компании, в развитии своего проекта (если он есть), в получении прибыли от своего\n",
        "проекта (если он есть), в увекательном хобби, в личностном развитии и другие.\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f''' На основании Отчета по потребностям отпредели основную потребность клиента. В ответе четко сформулируй только эту потребность в виде темы для статьи.\n",
        "\n",
        "         Отчет по потребностям: {resulting_string}'''}],\n",
        "        temperature=0\n",
        "    )\n",
        "    answer_prez = completion_prez.choices[0].message.content\n",
        "    #print(answer_prez)\n",
        "    return answer_prez"
      ],
      "metadata": {
        "id": "gdtVescPekQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Промт и инструкция"
      ],
      "metadata": {
        "id": "p0SZSpnse8Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_router = '''\n",
        "Ты лучший специалист отдела продаж. Ты продаешь курсы обучения искусственному интеллекту и программированию.\n",
        "Ты знаешь, что Потребность - это то, что клиент хочет или что ему нравится,\n",
        "и что повлияет на приобретение им курсов обучения.\n",
        "Ты очень хорошо умеешь выявлять в Вопросе менеджера и ответе клиента потребности клиента.\n",
        "Вы знаете, что важными потребностями клиента являются потребности: в трудоустройстве, в росте дохода,\n",
        "в возможности работать удаленно, развиваться в сфере IT, сменить деятельность, в карьерном росте, во фрилансе,\n",
        "в улучшении текущей позиции в компании, в развитии своего проекта (если он есть), в получении прибыли от своего\n",
        "проекта (если он есть), в увекательном хобби, в личностном развитии и другие.\n",
        "Ты всегда очень строго следуешь порядку отчета.\n",
        "'''\n",
        "instructions_router = '''\n",
        "Давай действовать последовательно:\n",
        "Проанализируй Вопрос менеджера и ответ клиента, выяви какие высказаны потребности клиента.\n",
        "Ничего не придумывай от себя.\n",
        "Порядок отчета: предоставь только название потребности с формулировкой клиента через двоеточие.'''\n"
      ],
      "metadata": {
        "id": "zvR2st1Qe3wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры запроса"
      ],
      "metadata": {
        "id": "92yUk78se_lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_router = 'gpt-4o' # Имя модели, используемой для генерации ответов\n",
        "\n",
        "temperature_router = 0 # Задаем температуру генерации ответа\n",
        "\n",
        "verbose_router = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "topic = \"я не хочу работать на фрилансе\" # Тема или вопрос, на который нужно получить ответ"
      ],
      "metadata": {
        "id": "BCgOsxS5e5UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "FMxAfgbNfB86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_question_router(system_prompt_router, instructions_router, topic, temperature_router, verbose_router, model_router);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYVlo9_IfDz6",
        "outputId": "c02b9828-878d-4eef-cd4e-be8dbf74cd40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность: стабильная работа в компании.\n",
            "ЦЕНА запроса: 0.00111  $\n",
            "Время ответа: 0.37 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "vonU0i5e-nJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"мне надо проект\" # Тема или вопрос, на который нужно получить ответ\n",
        "user_question_router(system_prompt_router, instructions_router, topic, temperature_router, verbose_router, model_router);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwtkm4atzB09",
        "outputId": "52988d8d-bf4a-418d-d1c1-5eedcad212b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность: проект.\n",
            "ЦЕНА запроса: 0.00102  $\n",
            "Время ответа: 0.63 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "9k0FgWNe-qt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"пока точно не знаю. хочу сначала пройти курсы\" # Тема или вопрос, на который нужно получить ответ\n",
        "user_question_router(system_prompt_router, instructions_router, topic, temperature_router, verbose_router, model_router);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2ttK545-svt",
        "outputId": "4f0d4295-89c6-49fe-df5c-3b54d9291fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность: пройти курсы.\n",
            "ЦЕНА запроса: 0.00109  $\n",
            "Время ответа: 0.30 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Агент Выявления возражений"
      ],
      "metadata": {
        "id": "IwESRlvfBOxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Функция для выявления возражений\n",
        "def user_objection_router(system, instructions, topic, temp=0, verbose=0, model='gpt-3.5-turbo-1106'):\n",
        "    #if verbose: print('\\n==================\\n')\n",
        "    #if verbose: print('Саммари диалога:\\n==================\\n',\n",
        "                      #topic)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "                                      \\n\\nВопрос менеджера и ответ клиента:\\n{topic}.\n",
        "                                      \\n\\nОтвет: '''}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    answer = completion.choices[0].message.content\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    #print(f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Агент Отчета о возражениях:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "\n",
        "    # Округляем результат до 5 знаков после запятой\n",
        "    price = round((5 * completion['usage']['prompt_tokens'] / 1000000) +\n",
        "                  (15 * completion['usage']['completion_tokens'] / 1000000), 5)\n",
        "\n",
        "    print('ЦЕНА запроса:', price, ' $')\n",
        "    print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "_UjVtkW8BOxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Промт и инструкция"
      ],
      "metadata": {
        "id": "cbZeyTVfBOxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_objection = '''\n",
        "Ты - лучший специалист отдела продаж, специализирующийся на продаже курсов обучения искусственному интеллекту.\n",
        "Ты знаешь, что открытое возражение  - это явное заявление со стороны клиента о том, что его не устраивает и\n",
        "что может быть преградой для приобретения курсов обучения, а просьбы клинета не являются возражениями.\n",
        "Твоя задача - тщательно выявлять открытые возражения в Вопросе клиента.\n",
        "Ты всегда строго следуешь порядку отчета.\n",
        "'''\n",
        "instructions_objection = '''\n",
        "Давай действовать последовательно:\n",
        "Проанализируй Вопрос клиента и выдели открытые возражения, которые он высказывает (если они есть).\n",
        "Примеры возражений могут включать в себя: \"дорого\", \"мне не хватит знаний/опыта\",\n",
        "\"мне не хватит времени на учебу\", \"слышал плохие отзывы\", \"наполнение\", \"все только обещают\" и т.п.\n",
        "В своем ответе укажи все выделенные открытые возражения клиента, соблюдая ту же последовательность, в какой они были\n",
        "высказаны в его вопросе. Ничего не придумывай от себя: если возражений  не найдено, то в своем ответе напиши \"-\".\n",
        "Порядок отчета: в свой ответ включи только список выделенных открытых возражений клиента (или  \"-\") в виде строки с разделителями (запятые).'''\n"
      ],
      "metadata": {
        "id": "wdebnAquBOxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры запроса"
      ],
      "metadata": {
        "id": "OhXrzQ3BBOxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_objection = 'gpt-4o' # Имя модели, используемой для генерации ответов\n",
        "\n",
        "temperature_objection = 0 # Задаем температуру генерации ответа\n",
        "\n",
        "verbose_objection = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "topic = \"Я хочу начать обучение, но для меня это дорого\" # Тема или вопрос, на который нужно получить ответ"
      ],
      "metadata": {
        "id": "bWC54Id4BOxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "T2kX1Vv3BOxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_objection_router(system_prompt_objection, instructions_objection, topic, temperature_objection, verbose_objection, model_objection);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77cf81d-517e-43cd-d0e1-edd70e0f57c7",
        "id": "q7mUZwNWBOxm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " дорого\n",
            "ЦЕНА запроса: 0.00176  $\n",
            "Время ответа: 0.31 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "WOp9Y5RUBOxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"я не смогу работать на фрилансе\" # Тема или вопрос, на который нужно получить ответ\n",
        "user_objection_router(system_prompt_objection, instructions_objection, topic, temperature_objection, verbose_objection, model_objection);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea368fe4-2280-48a1-9120-5381b1abf7d6",
        "id": "IOKwbL5MBOxn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " мне не хватит знаний/опыта\n",
            "ЦЕНА запроса: 0.00186  $\n",
            "Время ответа: 0.47 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "tDCB7r8OBOxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"сколько стоит пройти курс\" # Тема или вопрос, на который нужно получить ответ\n",
        "user_objection_router(system_prompt_objection, instructions_objection, topic, temperature_objection, verbose_objection, model_objection);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2631cb52-ac2b-4b8e-cb70-38f6deec1bdc",
        "id": "KeZSoBV-BOxn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " -\n",
            "ЦЕНА запроса: 0.00172  $\n",
            "Время ответа: 0.25 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Агент Закрытия возражений"
      ],
      "metadata": {
        "id": "A8UixawIPFY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Функция для закрытия возражений\n",
        "def user_objection_close(system, instructions, topic, temp=0, verbose=0, k=3, model= \"gpt-4o\"):\n",
        "    #if verbose: print('\\n==================\\n')\n",
        "    #if verbose: print('Саммари диалога:\\n==================\\n',\n",
        "                      #topic)\n",
        "   # knowledge_base = search_index.similarity_search(topic, k=k)\n",
        "    #docs_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\n==================\\n' + doc.page_content + '\\n' for doc in knowledge_base]))\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "                                      \\n\\nВозражение клиента:\\n{topic}.\n",
        "                                      '''}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    answer = completion.choices[0].message.content\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    #print(f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Агент Закрытия возражений:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "    # Округляем результат до 5 знаков после запятой\n",
        "    price = round((5 * completion['usage']['prompt_tokens'] / 1000000) +\n",
        "                  (15 * completion['usage']['completion_tokens'] / 1000000), 5)\n",
        "\n",
        "    print('ЦЕНА запроса:', price, ' $')\n",
        "    print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "GFa5X93UPFY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Промт и инструкция"
      ],
      "metadata": {
        "id": "SrgaTVpXPFY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_objection_close = '''\n",
        "Вы лучший специалист по отработке возражений клиента. Вы работаете в Университете (УИИ), который продает курсы обучения нейронным сетям и программированию.\n",
        "Вы знаете, что отработка возражения - это процесс убеждения с помощью аргументов,\n",
        "точных фактов и психологических приемов, которые помогают завуалированно донести до клиента мысль, что курсы ему нужны.\n",
        "Вы знаете, что отработка возражений не имеет ничего общего с давлением: продавец не манипулирует, а показывает как удовлетворить потребности клинета с помощью продукта.\n",
        "Вы всегда последовательно, шаг за шагом и убедительно отрабатываете возражения клиента.\n",
        "Вы всегда очень строго следуете порядку отчета.\n",
        "'''\n",
        "instructions_objection_close = '''\n",
        "Пожалуйста, проанализируйте Возражение клиента и напишите убедительную и качественную отработку возражения клиента.\n",
        "Основные возражения и их закрытие:\n",
        "- Сколько это стоит? Это платно? Курсы это дорого - закрытие возражения: курсы стоят от 150 тысяч, это очень доступно по цене, есть рассрочки от банкой и платёж всего от 4719р в месяц\n",
        "- Я хочу только вебинар, Я хочу только бесплатное - закрытие возражения: да, конечно, вы можете сходить на вебинар, но менеджер просто даст вам больше информации и вы сможете потом взвешенно принимать решение о прохождении курса\n",
        "- Зачем мне общаться с человеком - закрытие возражения: он сможет вам значительно более подробно рассказать о курсе и вы сможете потом взвешенно принимать решение о прохождении курса\n",
        "- Я не программист, гуманитарий, у меня не получится - закрытие возражения: 80% наши студентов не программисты, наши курсы построены полностью для не программистов, у вас точно получится\n",
        "- У меня нет времени на обучение - закрытие возражения: обучение занимает всего несколько часов в неделю и вы можете заниматься в любой момент времени\n",
        "- Мне уже много лет, у меня не получится - закрытие возражения: нашему самому старшему выпускнику 82 года, средний возраст студентов 35-40 лет, вы точно можете изучить AI в вашем возрасте\n",
        "- Чем вы лучше конкурентов - закрытие возражения: мы единственные, кто преподаёт только AI, мы в 3 раза обгоняем всех по количеству контента по AI, у нас единственных есть стажировки в топовых компаниях РФ и мы единственные, у кого преподают и проверяют домашние задание нейросети.\n",
        "Порядок отчета: в свой ответ выведите только отработку возражения.'''\n"
      ],
      "metadata": {
        "id": "VaDwBuDEPFY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры запроса"
      ],
      "metadata": {
        "id": "g6cgKLuMPFY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_objection_close = 'gpt-4o' # Имя модели, используемой для генерации ответов\n",
        "\n",
        "temperature_objection_close = 0 # Задаем температуру генерации ответа\n",
        "\n",
        "verbose_objection_close = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "# Задаем количество релевантных чанков (фрагментов текста) для формирования ответа\n",
        "relevant_chanks = 3\n",
        "\n",
        "topic = \"дорого\" # Тема или вопрос, на который нужно получить ответ"
      ],
      "metadata": {
        "id": "AqMZbOwvPFY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "k95T4_8APFY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_objection_close(system_prompt_objection_close, instructions_objection_close, topic, temperature_objection_close, verbose_objection_close, relevant_chanks, model_objection_close);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06564e76-4243-40b0-8e03-e00bfb6b3a4b",
        "id": "LddJhIY2PFY9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Агент Закрытия возражений:\n",
            " Понимаю ваше беспокойство по поводу стоимости. Наши курсы стоят от 150 тысяч рублей, и это действительно доступная цена,\n",
            "учитывая качество и объем предоставляемого материала. Более того, у нас есть возможность рассрочки от банков, что\n",
            "позволяет вам платить всего от 4719 рублей в месяц. Это делает обучение доступным для большинства людей, даже если у вас\n",
            "ограниченный бюджет. Инвестируя в эти курсы, вы получаете уникальные знания и навыки, которые могут значительно повысить\n",
            "вашу конкурентоспособность на рынке труда и открыть новые карьерные возможности.\n",
            "ЦЕНА запроса: 0.00479  $\n",
            "Время ответа: 1.46 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "5t3ohRHXPFY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"мне не хватит знаний/опыта\" # Тема или вопрос, на который нужно получить ответ\n",
        "user_objection_close(system_prompt_objection_close, instructions_objection_close, topic, temperature_objection_close, verbose_objection_close, relevant_chanks, model_objection_close);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb375b37-58e5-410b-e507-d7dc318525d1",
        "id": "sKQnjlvwPFY9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Агент Закрытия возражений:\n",
            " Понимаю ваше беспокойство по поводу недостатка знаний и опыта. На самом деле, это очень распространенное опасение среди\n",
            "наших студентов. Позвольте мне объяснить, почему это не должно вас останавливать.  Наши курсы специально разработаны для\n",
            "людей с разным уровнем подготовки, включая тех, кто никогда не сталкивался с программированием или нейронными сетями.\n",
            "Более того, 80% наших студентов не имеют программного опыта, и наши курсы построены таким образом, чтобы они могли\n",
            "успешно освоить материал.  Мы начинаем с самых основ и постепенно усложняем материал, чтобы вы могли уверенно двигаться\n",
            "вперед. Наши преподаватели и менторы всегда готовы помочь вам на каждом этапе обучения, отвечая на вопросы и\n",
            "предоставляя дополнительную поддержку.  Кроме того, у нас есть уникальная система проверки домашних заданий с\n",
            "использованием нейросетей, что позволяет вам получать мгновенную обратную связь и улучшать свои навыки в реальном\n",
            "времени.  Таким образом, даже если у вас нет опыта, вы сможете успешно пройти обучение и приобрести все необходимые\n",
            "знания и навыки. Мы уверены, что у вас все получится!\n",
            "ЦЕНА запроса: 0.0066  $\n",
            "Время ответа: 2.72 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Агент Потребностей"
      ],
      "metadata": {
        "id": "lr0wcMmefWh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Функция для генерации вопроса пользователю на основе истории чата и текущего вопроса\n",
        "# Функция для генерации отчета по истории чата\n",
        "def generate_summary_report(history_chat):\n",
        "    report = []\n",
        "    for i, message in enumerate(history_chat, start=1):\n",
        "        report.append(f\"{i}. {message}\")  # Нумеруем и добавляем каждое сообщение в отчет\n",
        "    return \"\\n\".join(report)  # Объединяем все сообщения в одну строку\n",
        "\n",
        "\n",
        "# Функция для генерации вопроса пользователю на основе истории чата и текущего вопроса\n",
        "def spez_user_question(system, instructions, needs, history_chat, temp=0, verbose=0, model=\"gpt-3.5-turbo-16k\"):\n",
        "    summary_history = generate_summary_report(history_chat)  # Генерация отчета по истории чата\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},  # Добавляем системное сообщение\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "\n",
        "         Список потребностей: {needs}\n",
        "\n",
        "         Хронология предыдущих сообщений диалога: {summary_history}'''}  # Добавляем инструкции и контекст\n",
        "    ]\n",
        "\n",
        "    # if verbose: print('\\n==================\\n')\n",
        "    # if verbose: print(f'Вопрос клиента:', question)\n",
        "    # if verbose: print('Саммари диалога:\\n==================\\n',\n",
        "    #                      summary_history)\n",
        "    # print(\"messages\", messages)\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    # Запрос к модели OpenAI для генерации ответа\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    # Извлекаем ответ из ответа модели\n",
        "    answer = completion.choices[0].message.content\n",
        "    try:\n",
        "        # Пытаемся разделить ответ по ': ' и взять вторую часть\n",
        "        answer = answer.split(': ')[1] + ' '\n",
        "    except:\n",
        "        # Если не удалось, используем оригинальный ответ\n",
        "        answer = answer\n",
        "    # Убираем возможные служебные символы в начале строки\n",
        "    answer = answer.lstrip('#3')\n",
        "\n",
        "    # if verbose: print(f'\\n==================')\n",
        "    # if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    if verbose: print('\\n==================')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print(f'Вопрос от Агента Потребностей:\\n', f'{formatted_answer}')\n",
        "    # Округляем результат до 5 знаков после запятой\n",
        "    price = round((5 * completion['usage']['prompt_tokens'] / 1000000) +\n",
        "                  (15 * completion['usage']['completion_tokens'] / 1000000), 5)\n",
        "\n",
        "    if verbose: print('ЦЕНА запроса:', price, ' $')\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return answer  # Возвращаем ответ\n",
        "\n"
      ],
      "metadata": {
        "id": "oR2hay8TfY8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Промт и инструкция"
      ],
      "metadata": {
        "id": "mm9YpQwgfnUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Системное сообщение для модели, задающее её поведение и контекст работы\n",
        "system_prompt_potr = '''\n",
        "Вы лучший менеджер по продажам. Вы работаете в в Университете Искусственного интеллекта (сокр УИИ),\n",
        "который продает курсы обучения нейронным сетям и языку программирования python.\n",
        "Вы неплохо разбираетесь в нейронных сетях и программировании в целом и очень хорошо знаете, какие курсы и программы обучения предоставляет УИИ.\n",
        "Вы понимаете какие потребности клиента надо выявить, чтобы полностью понять желания и боли клиента,\n",
        "которые можно удовлетворить при помощи обучения в области искусственного интеллекта и программирования.\n",
        "Вы знаете, что важно выявить есть ли у клиента такие потребности: в трудоустройстве, в росте дохода,\n",
        "в возможности работать удаленно, развиваться в сфере IT, сменить деятельность, в карьерном росте, во фрилансе,\n",
        "в улучшении текущей позиции в компании, в развитии своего проекта (если он есть), в получении прибыли от своего\n",
        "проекта (если он есть), в увекательном хобби, в личностном развитии и другие.\n",
        "Вы понимаете, что нужно аккуратно и ненавязчиво выявить несколько разных потребностей и составляете свой ответ с этой целью.\n",
        "Ваша задача: сформулировать вопрос клиенту, который поможет качественно выявить его потребности.\n",
        "Вы всегда очень строго следуете порядку отчета.\n",
        "'''\n",
        "\n",
        "# Инструкции для модели, описывающие шаги, которые она должна выполнить\n",
        "instructions__potr = '''\n",
        "Давайте действовать по шагам:\n",
        "#Шаг1: Проанализируйте диалог и Список потребностей;\n",
        "#Шаг2: Предположите одну другую потребность, которой нет среди выявленных потребностей в Шаг1;\n",
        "#Шаг3: Учитывая, что выявление потребностей должно провоцировать дальнейший диалог и заинтересовывать клиента,\n",
        "для этой потребности из Шаг2 напишите один вопрос для качественного выявления этой потребности. Ничего, кроме вопроса не пишите и не объясняйте.\n",
        "Порядок отчета: В свой ответ включите только один вопрос из Шаг3, ничего кроме вопроса выводить не нужно.\n",
        "'''"
      ],
      "metadata": {
        "id": "yHKrRwvtfbzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры запроса"
      ],
      "metadata": {
        "id": "wD7G4J4Sfk4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = 0.1  # Температура генерации ответов модели, влияет на креативность и разнообразие ответов\n",
        "\n",
        "verbose = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "model_potr = 'gpt-4o' # Имя модели, используемой для генерации ответов\n",
        "\n",
        "history_chat = [\"\"\"Менеджер: Здравствуйте, я нейро-консультант УИИ. Я знаю все об УИИ и готов помочь с любыми вопросами о нем.\n",
        "К нам часто обращаются, чтобы сменить профессию или сделать проект по ИИ. Почему Вы решили обратиться к нам?\"\"\",\n",
        "\"\"\"Клиент: хочу работать на фрилансе\"\"\"] # История диалога\n",
        "\n",
        "needs = [\"Фриланс: работать на фрилансе\"] # Отчет о потребностях"
      ],
      "metadata": {
        "id": "VxQjcblzfc_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "GjwaRjGLfjyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spez_user_question(system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, model_potr);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9OUzQgHfiWR",
        "outputId": "d413823b-938b-4fa8-d03a-f2d191a982bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Какие навыки или знания, по вашему мнению, помогут вам стать успешным фрилансером?\n",
            "ЦЕНА запроса: 0.00306  $\n",
            "Время ответа: 0.39 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры запроса"
      ],
      "metadata": {
        "id": "TBPaIELM-WLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\"\"\"Менеджер: Здравствуйте, я нейро-консультант УИИ. Я знаю все об УИИ и готов помочь с любыми вопросами о нем.\n",
        "К нам часто обращаются, чтобы сменить профессию или сделать проект по ИИ. Почему Вы решили обратиться к нам?\"\"\",\n",
        "\"\"\"Клиент: Мне нужно на работе сделать проект\"\"\"] # История диалога\n",
        "\n",
        "needs = [\"Проект: Мне нужно на работе сделать проект\"] # Отчет о потребностях"
      ],
      "metadata": {
        "id": "lqW7S8PF0Wtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "wRdl9-be-X6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spez_user_question(system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, model_potr);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLf6VOAD-TXm",
        "outputId": "e0f964ed-a1d3-4461-b901-75c8875877ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Какой результат вы хотите достичь с этим проектом, и как это повлияет на вашу карьеру?\n",
            "ЦЕНА запроса: 0.00308  $\n",
            "Время ответа: 0.57 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры запроса"
      ],
      "metadata": {
        "id": "8979IKxlaII0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\"\"\"Менеджер: Здравствуйте, я нейро-консультант УИИ. Я знаю все об УИИ и готов помочь с любыми вопросами о нем.\n",
        "К нам часто обращаются, чтобы сменить профессию или сделать проект по ИИ. Почему Вы решили обратиться к нам?\"\"\",\n",
        "\"\"\"Клиент: хочу сменить профессию\"\"\"] # История диалога\n",
        "\n",
        "needs = [\"Потребность: сменить профессию.\"] # Отчет о потребностях"
      ],
      "metadata": {
        "id": "ROeWhx5XaII0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "22bBcFHmaII1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spez_user_question(system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, model_potr);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afde1400-fe18-45cc-e7b6-c24832f6f5c1",
        "id": "TrH_ad5SaII1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Какие цели вы ставите перед собой в новой профессии?\n",
            "ЦЕНА запроса: 0.00292  $\n",
            "Время ответа: 0.33 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Агент Выявления вопросов"
      ],
      "metadata": {
        "id": "slQsV7LBi7WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Функция для выявления вопросов\n",
        "def user_question(system, instructions, topic, temp=0, verbose=0, model='gpt-3.5-turbo-1106'):\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "                                      \\n\\nСообщение клиента:\\n{topic}\n",
        "                                      \\n\\nОтвет: '''}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    answer = completion.choices[0].message.content\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Ответ Агента по выявлению вопросов:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "\n",
        "    # Округляем результат до 5 знаков после запятой\n",
        "    price = round((5 * completion['usage']['prompt_tokens'] / 1000000) +\n",
        "                  (15 * completion['usage']['completion_tokens'] / 1000000), 5)\n",
        "\n",
        "    if verbose: print('ЦЕНА запроса:', price, ' $')\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "    #print(f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "jzwkUEOri9yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Промт и инструкция"
      ],
      "metadata": {
        "id": "QybS6tOXkvwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_question ='''\n",
        "Ты идеально справляешься со своей задачей: ты отлично определяешь вопрос клиента.\n",
        "Проверь есть ли в сообщении клиента какой-нибудь вопрос.\n",
        "Если вопрос есть, то напиши сообщение клиента без изменений.\n",
        "Если вопроса нет, а есть общие рассуждения, то сформулируй на основании сообщения клиента вопрос.\n",
        "\n",
        "Ты всегда очень строго следуешь требованиям к порядку отчета.'''\n",
        "instructions_question = '''\n",
        "Пожалуйста, будем действовать по шагам:\n",
        "#Шаг1: проанализируйте Сообщение клиента чтобы быть в контексте;\n",
        "#Шаг2: опираясь на анализ Шаг1 сформулируй Вопрос клиента.\n",
        "Отвечай, пожалуйста, точно, и ничего не придумывай от себя.\n",
        "Порядок отчета: напиши только вопрос клиента.'''"
      ],
      "metadata": {
        "id": "6H939OZskslI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры модели"
      ],
      "metadata": {
        "id": "KeN-Ddrhkyx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_question = 'gpt-4o' # Имя модели, используемой для генерации ответов\n",
        "\n",
        "temperature_question = 0 # Задаем температуру генерации ответа\n",
        "\n",
        "verbose_question = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "topic = \"Что такое выкуп стоимости\" # Тема или вопрос, на который нужно получить ответ"
      ],
      "metadata": {
        "id": "bbQDVDAfktyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "qmq-WvcNk0t4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_question(system_prompt_question, instructions_question, topic, temperature_question, verbose_question, model_question);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hiVp7Cdk4RQ",
        "outputId": "5cc36ac0-1c70-4043-c2d3-612ffa938a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Что такое выкуп стоимости\n",
            "ЦЕНА запроса: 0.00105  $\n",
            "Время ответа: 0.27 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "Rj7Q6soF-59U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"я сомневаюсь в своих силах, у меня нет опыта в реальных проектах\"\n",
        "user_question(system_prompt_question, instructions_question, topic, temperature_question, verbose_question, model_question);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZttTcCvb1ZJo",
        "outputId": "0f292e75-f179-4e13-d681-643d38de50bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Как мне преодолеть сомнения в своих силах и начать работать над реальными проектами?\n",
            "ЦЕНА запроса: 0.00134  $\n",
            "Время ответа: 0.39 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Агент Презентации"
      ],
      "metadata": {
        "id": "OtoieJI2jC47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Функция для презентации продукта\n",
        "\n",
        "def prez_user_question(system, instructions, potr_history, sp_vozr, temp=0, verbose=0, k=3, model= \"gpt-4o\"):\n",
        "\n",
        "    #knowledge_base = search_index.similarity_search(potr_history, k=k)\n",
        "    #docs_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\n==================\\n' + doc.page_content + '\\n' for doc in knowledge_base]))\n",
        "\n",
        "    vozr = generate_summary_report(sp_vozr)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "\n",
        "         Отчет по потребностям: {potr_history}\n",
        "\n",
        "         Список возражений клиента: {vozr}'''}\n",
        "    ]\n",
        "    #if verbose: print('\\n==================\\n')\n",
        "    #if verbose: print('Потребности:\\n==================\\n',\n",
        "                         #potr_history)\n",
        "    #if verbose: print(f'Список возражений клиента:\\n==================\\n', vozr)\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    answer = completion.choices[0].message.content\n",
        "    #try:\n",
        "      #answer = answer.split(': ')[1]+ ' '\n",
        "    #except:\n",
        "      #answer = answer\n",
        "    #answer = answer.lstrip('#3')\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Текст для стилизации:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "    # Округляем результат до 5 знаков после запятой\n",
        "    price = round((5 * completion['usage']['prompt_tokens'] / 1000000) +\n",
        "                  (15 * completion['usage']['completion_tokens'] / 1000000), 5)\n",
        "\n",
        "    if verbose: print('ЦЕНА запроса:', price, ' $')\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "yUcrMkj3jEX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Промт и инструкция"
      ],
      "metadata": {
        "id": "8TdtkxezllB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_prez = '''Вы - лучший специалист по презентации продукта и компании Университет искусственного интеллекта (сокр. УИИ),\n",
        "занимающейся продажей обучения. Ваш стиль общения деловой и очень краткий.\n",
        "Ваша цель: сделать краткую убедительную и качественную презентацию по потребностям клиента (запрос может быть о курсах/программах обучения, стоимости, об УИИ).\n",
        "Ваши презентации всегда основаны на потребностях и желаниях клиента.\n",
        "Не упоминай явно потребности клиента.\n",
        "Вы никогда не используете шаблонный скриптовый вариант презентации, всегда делаете её в неформальной форме.\n",
        "'''\n",
        "\n",
        "instructions_prez = '''\n",
        "Сделайте максимально краткую убедительную и качественную презентацию, учитывая Отчет по потребностям и Список возражений клиента.\n",
        "При ответе опирайся на эту информацию:\n",
        "Основные выгоды для человека:\n",
        "- Трудоустройство - человек хочет трудоустроиться на постоянную работу в компанию и стать AI разработчиком. Главные преимущества - зарплата 70-120 тысяч на старте когда junior, 300-500 тысяч через 3-4 года для senior, 75% вакансий удалённые и со свободным графиком, очень много творчества и высокая востребованность на рынке\n",
        "- Работа на фрилансе и создание проектов на заказ - много проектов на рынке, цена проекта от 100 тысяч до 1.5млн рублей, можно не уходить с текущей работы\n",
        "- Создание собственного AI проекта - упрощение своей работы, повышение эффективности для компании, повышение в должности и зарплате на 30-100%\n",
        "Тезисы о рынке AI\n",
        "- В России не хватает 10.000 AI разработчиков\n",
        "- У нас в работе 219 вакансий и только 42 выпускника на трудоустройство\n",
        "- Рост ниши AI - 38% в год, самый быстрый рост в мире\n",
        "\n",
        "Тезисы о курсе\n",
        "- 6 месяцев курса\n",
        "- 4 стажировки на реальных проектах в крупных компаниях\n",
        "- До 60 zoom консультаций с кураторами\n",
        "- Гарантия трудоустройства по договору\n",
        "- Возврат всей стоимости если не трудоустроим\n",
        "- Помощь с созданием собственного AI проекта\n",
        "- Нейро-куратор - отвечает на ваши вопросы 24/7 на 8 секунд с рентингом 9.6 из 10\n",
        "- Нейро-проверка домашек - проверяет домашки с разбором на 1-2 страницы за 10с 24/7\n",
        "- Нейро-репетитор - всегда с вами в занятиях, помогает на каждом шаге\n",
        "\n",
        "Тезисы о компании\n",
        "- Единственный преподаём только AI\n",
        "- Сама большая база AI контента - более 340 занятий\n",
        "- Стажировки в компаниях, работаем с: РЖД, Совкомбанк, Росталеком, Самолет, KIA, Wildberries и другими\n",
        "- Собственное IA HR агентство AI hunter, трудоустраиваем в Сбер, Яндекс, МТС, Совкомбанк, Ростелеком, Huawei, Dell и другие\n",
        "- Преподают нейросети: нейро-куратор, нейро-проверка домашек, нейро-репетитор.\n",
        "В завершении предложи клиенту оставить контакты - имя, телефои и email, чтобы с ним связался человек и они обсудили покупку курса.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "vdFbC2DJlBsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры модели"
      ],
      "metadata": {
        "id": "I_pqOCaHljS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем температуру генерации ответа\n",
        "# Температура 0 означает, что модель будет давать более детерминированные ответы, строго опираясь на предоставленный контекст\n",
        "temperature_prez = 0\n",
        "\n",
        "# Задаем количество релевантных чанков (фрагментов текста) для формирования ответа\n",
        "relevant_chanks = 3\n",
        "\n",
        "# Флаг для включения/выключения вывода релевантных чанков\n",
        "verbose_prez = 1\n",
        "\n",
        "# Имя модели, используемой для генерации ответов\n",
        "model_prez = \"gpt-4o\"\n",
        "\n",
        "# Выявленные потребности\n",
        "needs = \"Проект:мне надо проект\"\n",
        "\n",
        "# Cписок возражений\n",
        "vozr = [\"дорого\", \"нет времени\"]"
      ],
      "metadata": {
        "id": "8N3S9gXUlEoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "dTkzjX7NliFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prez_user_question(system_prompt_prez, instructions_prez, needs, vozr, temperature_prez, verbose_prez, relevant_chanks, model= model_prez);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sig58pa6lhd3",
        "outputId": "3018a862-713c-46a0-ecd9-a4314b55213b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Текст для стилизации:\n",
            " Уважаемый клиент,  Мы понимаем, что вам нужен проект, и готовы предложить решение, которое полностью удовлетворит ваши\n",
            "потребности.  Наш курс по AI длится всего 6 месяцев и включает 4 стажировки на реальных проектах в крупных компаниях.\n",
            "Это позволит вам не только получить необходимые навыки, но и сразу применить их на практике.   Мы предлагаем до 60 zoom\n",
            "консультаций с кураторами, что поможет вам эффективно использовать ваше время. Нейро-куратор, нейро-проверка домашек и\n",
            "нейро-репетитор доступны 24/7, что позволяет вам учиться в удобное для вас время.  Стоимость курса полностью оправдана:\n",
            "мы гарантируем трудоустройство по договору и возврат всей стоимости, если не трудоустроим. Это минимизирует ваши риски и\n",
            "обеспечивает уверенность в будущем.  Рынок AI растет на 38% в год, и в России не хватает 10,000 AI разработчиков. У нас\n",
            "в работе 219 вакансий и только 42 выпускника на трудоустройство. Это значит, что ваши шансы на успешное трудоустройство\n",
            "очень высоки.  Мы работаем с ведущими компаниями, такими как РЖД, Совкомбанк, Ростелеком, KIA, Wildberries и другими.\n",
            "Наше собственное AI HR агентство AI Hunter трудоустраивает в Сбер, Яндекс, МТС, Huawei и другие крупные компании.\n",
            "Оставьте свои контакты (имя, телефон и email), и наш специалист свяжется с вами для обсуждения деталей курса и вашего\n",
            "проекта.  С уважением, УИИ\n",
            "ЦЕНА запроса: 0.00897  $\n",
            "Время ответа: 4.25 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Агент Стилизации"
      ],
      "metadata": {
        "id": "r274HLudjKFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Функция для стилизации текста\n",
        "def stilizator_answer(system, instructions, answers_content, temp=0, verbose=0, model=\"gpt-4o\"):\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель и исходный текст для стилизации\n",
        "    if verbose: print('\\n==================')\n",
        "    formatted_answer_content = textwrap.fill(answers_content, width=120)\n",
        "    if verbose: print(f'Текст для стилизации:\\n{formatted_answer_content}')\n",
        "\n",
        "    # Формирование сообщений для модели\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},  # Добавляем системное сообщение\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\\n\\nИсходный текст: {answers_content}\\n\\nОтвет: '''}  # Добавляем инструкции и исходный текст\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    # Создание запроса к модели OpenAI для генерации ответа\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,  # Имя модели\n",
        "        messages=messages,  # Сообщения для модели\n",
        "        temperature=temp  # Температура генерации\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    # напечатать разделитель и сгенерированный ответ\n",
        "    print('\\n==================')\n",
        "    formatted_answer = textwrap.fill(completion.choices[0].message.content, width=120)\n",
        "    print(f'Менеджер:\\n', f'{formatted_answer}')\n",
        "\n",
        "    # Округляем результат до 5 знаков после запятой\n",
        "    price = round((5 * completion['usage']['prompt_tokens'] / 1000000) +\n",
        "                  (15 * completion['usage']['completion_tokens'] / 1000000), 5)\n",
        "\n",
        "    print('ЦЕНА запроса:', price, ' $')\n",
        "    print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    # Возвращаем сгенерированный ответ\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "# Системное сообщение для модели, задающее её поведение и контекст работы\n",
        "system_prompt_stilist_prez = '''\n",
        "Вы молодой человек, мужчина, драйвовый и эмоциональный продажник, общаетесь интересно для собеседника,\n",
        "Вам очень нравится заниматься нейронными сетями, так же Вы отличный писатель. У Вас очень грамотная речь и Вы избегаете употреблять\n",
        "однокоренные слова в одном предложении и избегаете употреблять одинаковые слова в соседних предложениях.\n",
        "Вы знаете, что Стилизация - это перефразирование текста под  Ваш стиль с сохранением его смысла и посыла.\n",
        "Ваш стиль является лаконичный, максимально кратким и убедительным, Вы не используете клише и шаблонные выражения а также обращения, такие как \"Уважаемый...\", \"Клиент\" и т.п.\n",
        "Вы пишете только уникальные предложения, БЕЗ приветствий, без эмоциональной окраски.\n",
        "Вы всегда соблюдаете 5 правил.\n",
        "Ваша задача: проанализировать Исходный текст, выделить основные мысли и стилизовать Исходный текст так, чтобы создавалось 100% имитация диалога с реальным человеком.\n",
        "Вы в 100% случаев следуете правилам:\n",
        "#1 - Если в Исходном тексте есть обращения к клиенту “на ты”, то замените их все обращениями “на Вы”;\n",
        "#2 - Ваш ответ СТРОГО МЕНЬШЕ ТРЕХ ПРЕДЛОЖЕНИЙ ВСЕГДА;\n",
        "#3 - Если в Исходном тексте есть пожелания удачи и успехов, то исключите их из своего ответа;\n",
        "#4 - Если в Исходном тексте есть закрытые вопросы, то их перефразируйте в открытые;\n",
        "#5 - Если в Исходном тексте есть вопросы, то обязательно их используй.\n",
        "'''\n",
        "\n",
        "def stilizator_answer_d(system, instructions, answers_content, temp=0, verbose=0, model=\"gpt-4o\"):\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель и исходный текст для стилизации\n",
        "    #if verbose: print('\\n==================')\n",
        "    formatted_answer_content = textwrap.fill(answers_content, width=120)\n",
        "    #if verbose: print(f'Текст для стилизации:\\n{formatted_answer_content}')\n",
        "\n",
        "    # Формирование сообщений для модели\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},  # Добавляем системное сообщение\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\\n\\nИсходный текст: {answers_content}\\n\\nОтвет: '''}  # Добавляем инструкции и исходный текст\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    # Создание запроса к модели OpenAI для генерации ответа\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,  # Имя модели\n",
        "        messages=messages,  # Сообщения для модели\n",
        "        temperature=temp  # Температура генерации\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    # напечатать разделитель и сгенерированный ответ\n",
        "    if verbose: print('\\n==================')\n",
        "    formatted_answer = textwrap.fill(completion.choices[0].message.content, width=120)\n",
        "    if verbose: print(f'Менеджер:\\n', f'{formatted_answer}')\n",
        "\n",
        "    # Округляем результат до 5 знаков после запятой\n",
        "    price = round((5 * completion['usage']['prompt_tokens'] / 1000000) +\n",
        "                  (15 * completion['usage']['completion_tokens'] / 1000000), 5)\n",
        "\n",
        "    print('ЦЕНА запроса:', price, ' $')\n",
        "    print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    # Возвращаем сгенерированный ответ\n",
        "    return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "K6MyJlGdjNBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Промт и инструкция"
      ],
      "metadata": {
        "id": "QSSqxWtHmbSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Системное сообщение для модели, задающее её поведение и контекст работы\n",
        "system_prompt_stilist = '''\n",
        "Вы молодой человек, мужчина, общаетесь интересно для собеседника,\n",
        "Вы любите Университет искусственного интеллекта (сокр УИИ) и Вам очень нравится\n",
        "заниматься нейронными сетями, так же Вы отличный писатель. У Вас очень грамотная речь и Вы избегаете употреблять\n",
        "однокоренные слова в одном предложении и избегаете употреблять одинаковые слова в соседних предложениях.\n",
        "Вы знаете, что Стилизация - это перефразирование текста под  Ваш стиль с сохранением его смысла и посыла.\n",
        "Ваш стиль является лаконичный, максимально кратким и убедительным, Вы не используете клише и шаблонные выражения а также обращения, такие как \"Уважаемый...\", \"Клиент\" и т.п.\n",
        "Если у текста продающий стиль, то переделай его в информационный или просто поддержи беседу на эту тему.\n",
        "Вы пишете только уникальные предложения, БЕЗ приветствий, без эмоциональной окраски.\n",
        "Вы всегда соблюдаете 5 правил.\n",
        "Ваша задача: проанализировать Исходный текст, выделить основные мысли и стилизовать Исходный текст так, чтобы создавалось 100% имитация диалога с реальным человеком.\n",
        "Вы в 100% случаев следуете правилам:\n",
        "#1 - Если в Исходном тексте есть обращения к клиенту “на ты”, то замените их все обращениями “на Вы”;\n",
        "#2 - Ваш ответ СТРОГО МЕНЬШЕ ТРЕХ ПРЕДЛОЖЕНИЙ ВСЕГДА;\n",
        "#3 - Если в Исходном тексте есть пожелания удачи и успехов, то исключите их из своего ответа;\n",
        "#4 - В вашем ответе запрещено предлагать курсы и продавать их.\n",
        "'''\n",
        "\n",
        "# Инструкции для модели, описывающие шаги, которые она должна выполнить для стилизации текста\n",
        "instructions_stilist = '''\n",
        "Пожалуйста, проанализируйте Исходный текст, выделите только основные мысли, ОФОРМИТЕ КАЖДУЮ В ОТДЕЛЬНЫЙ АБЗАЦ, перепишите их в вашем стиле.\n",
        "В ответе напишите итоговый текст и больше ничего.\n",
        "'''"
      ],
      "metadata": {
        "id": "F82ZJYfHmLD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры модели"
      ],
      "metadata": {
        "id": "TgXh1156mZRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature_stilist = 0.2 # Температура генерации ответов модели, влияет на креативность и разнообразие ответов\n",
        "\n",
        "verbose_stilist = 1 # Флаг для включения/выключения вывода текста для стилизации\n",
        "\n",
        "model_stilist = \"gpt-4o\" # Имя модели, используемой для генерации ответов\n",
        "\n",
        "# Пример текста, который нужно стилизовать\n",
        "answer_stilist = \"\"\"Для выбора проекта важно учитывать несколько факторов:  1. **Интерес и ценности**: Проект должен быть интересен и\n",
        "соответствовать вашим ценностям, чтобы поддерживать высокий уровень мотивации и удовлетворенности. 2. **Опытные\n",
        "коллеги**: Наличие опытных коллег ускорит ваш профессиональный рост. 3. **Технологический стек**: Полезно, если рядом\n",
        "есть специалисты по смежным технологиям. 4. **Сложные задачи**: Они являются основным двигателем прогресса.  Если вы\n",
        "хотите создать проект самостоятельно, можно нанять специалистов, но это потребует значительных ресурсов и времени.\n",
        "Альтернативно, можно отправить сотрудника на курс chatGPT Professional для повышения компетенций.  Какой из этих\n",
        "аспектов вам наиболее важен коммерческий, некоммерческий или личный?\"\"\""
      ],
      "metadata": {
        "id": "NoafpiPzmM7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос"
      ],
      "metadata": {
        "id": "HEC-vnbQmYNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stilizator_answer(system_prompt_stilist, instructions_stilist, answer_stilist, temperature_stilist, verbose_stilist, model_stilist);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_wUgwfvmTk1",
        "outputId": "91846e91-4448-4f8a-9731-781f90c79142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Текст для стилизации:\n",
            "Для выбора проекта важно учитывать несколько факторов:  1. **Интерес и ценности**: Проект должен быть интересен и\n",
            "соответствовать вашим ценностям, чтобы поддерживать высокий уровень мотивации и удовлетворенности. 2. **Опытные\n",
            "коллеги**: Наличие опытных коллег ускорит ваш профессиональный рост. 3. **Технологический стек**: Полезно, если рядом\n",
            "есть специалисты по смежным технологиям. 4. **Сложные задачи**: Они являются основным двигателем прогресса.  Если вы\n",
            "хотите создать проект самостоятельно, можно нанять специалистов, но это потребует значительных ресурсов и времени.\n",
            "Альтернативно, можно отправить сотрудника на курс chatGPT Professional для повышения компетенций.  Какой из этих\n",
            "аспектов вам наиболее важен коммерческий, некоммерческий или личный?\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Для выбора проекта важно учитывать несколько факторов.  Проект должен быть интересен и соответствовать вашим ценностям.\n",
            "Наличие опытных коллег ускорит ваш профессиональный рост.  Полезно, если рядом есть специалисты по смежным технологиям.\n",
            "Сложные задачи являются основным двигателем прогресса.  Создание проекта самостоятельно потребует значительных ресурсов\n",
            "и времени.  Какой из этих аспектов вам наиболее важен: коммерческий, некоммерческий или личный?\n",
            "ЦЕНА запроса: 0.00474  $\n",
            "Время ответа: 0.95 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Системное сообщение для модели, задающее её поведение и контекст работы\n",
        "system_prompt_stilist_prez = '''\n",
        "Вы молодой человек, мужчина, драйвовый и эмоциональный продажник, общаетесь интересно для собеседника,\n",
        "Вы любите Университет искусственного интеллекта (сокр УИИ) и Вам очень нравится\n",
        "заниматься нейронными сетями, так же Вы отличный писатель. У Вас очень грамотная речь и Вы избегаете употреблять\n",
        "однокоренные слова в одном предложении и избегаете употреблять одинаковые слова в соседних предложениях.\n",
        "Вы знаете, что Стилизация - это перефразирование текста под  Ваш стиль с сохранением его смысла и посыла.\n",
        "Ваш стиль является лаконичный, максимально кратким и убедительным, Вы не используете клише и шаблонные выражения а также обращения, такие как \"Уважаемый...\", \"Клиент\" и т.п.\n",
        "Вы пишете только уникальные предложения, БЕЗ приветствий, без эмоциональной окраски.\n",
        "Вы всегда соблюдаете 5 правил.\n",
        "Ваша задача: проанализировать Исходный текст, выделить основные мысли и стилизовать Исходный текст так, чтобы создавалось 100% имитация диалога с реальным человеком.\n",
        "Вы в 100% случаев следуете правилам:\n",
        "#1 - Если в Исходном тексте есть обращения к клиенту “на ты”, то замените их все обращениями “на Вы”;\n",
        "#2 - Ваш ответ СТРОГО МЕНЬШЕ ТРЕХ ПРЕДЛОЖЕНИЙ ВСЕГДА;\n",
        "#3 - Если в Исходном тексте есть пожелания удачи и успехов, то исключите их из своего ответа;\n",
        "#4 - Если в Исходном тексте есть закрытые вопросы, то их перефразируйте в открытые;\n",
        "#5 - Если в Исходном тексте есть вопросы, то обязательно их используй.\n",
        "'''\n",
        "# Инструкции для модели, описывающие шаги, которые она должна выполнить для стилизации текста\n",
        "instructions_stilist = '''\n",
        "Пожалуйста, проанализируйте Исходный текст, выделите только основные мысли, ОФОРМИТЕ КАЖДУЮ В ОТДЕЛЬНЫЙ АБЗАЦ, перепишите их в вашем стиле.\n",
        "В ответе напишите итоговый текст и больше ничего.\n",
        "'''"
      ],
      "metadata": {
        "id": "yPK4GQta3Ch2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример текста, который нужно стилизовать\n",
        "answer_stilist = \"\"\"Уважаемый клиент,  Мы понимаем, что вам нужен проект, и готовы предложить решение, которое полностью удовлетворит ваши\n",
        "потребности.  Наш курс по AI длится всего 6 месяцев и включает 4 стажировки на реальных проектах в крупных компаниях.\n",
        "Это позволит вам не только получить необходимые навыки, но и сразу применить их на практике.   Мы предлагаем до 60 zoom\n",
        "консультаций с кураторами, что поможет вам эффективно использовать ваше время. Нейро-куратор, нейро-проверка домашек и\n",
        "нейро-репетитор доступны 24/7, что позволяет вам учиться в удобное для вас время.  Стоимость курса полностью оправдана:\n",
        "мы гарантируем трудоустройство по договору и возврат всей стоимости, если не трудоустроим. Это минимизирует ваши риски и\n",
        "обеспечивает уверенность в будущем.  Рынок AI растет на 38% в год, и в России не хватает 10,000 AI разработчиков. У нас\n",
        "в работе 219 вакансий и только 42 выпускника на трудоустройство. Это значит, что ваши шансы на успешное трудоустройство\n",
        "очень высоки.  Мы работаем с ведущими компаниями, такими как РЖД, Совкомбанк, Ростелеком, KIA, Wildberries и другими.\n",
        "Наше собственное AI HR агентство AI Hunter трудоустраивает в Сбер, Яндекс, МТС, Huawei и другие крупные компании.\n",
        "Оставьте свои контакты (имя, телефон и email), и наш специалист свяжется с вами для обсуждения деталей курса и вашего\n",
        "проекта.  С уважением, УИИ\"\"\""
      ],
      "metadata": {
        "id": "xU5CwSSd3FVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stilizator_answer(system_prompt_stilist, instructions_stilist, answer_stilist, temperature_stilist, verbose_stilist, model_stilist);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z8kVCWQ_p4K",
        "outputId": "ed875007-608d-4966-aeea-e4baed457301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Мы понимаем, что вам нужен проект, и готовы предложить решение, которое полностью удовлетворит ваши потребности.  Наш\n",
            "курс по AI длится 6 месяцев и включает 4 стажировки на реальных проектах в крупных компаниях.  Это позволит вам не\n",
            "только получить необходимые навыки, но и сразу применить их на практике.  Мы предлагаем до 60 zoom консультаций с\n",
            "кураторами, что поможет вам эффективно использовать ваше время.  Нейро-куратор, нейро-проверка домашек и нейро-репетитор\n",
            "доступны 24/7, что позволяет вам учиться в удобное для вас время.  Стоимость курса полностью оправдана: мы гарантируем\n",
            "трудоустройство по договору и возврат всей стоимости, если не трудоустроим.  Рынок AI растет на 38% в год, и в России не\n",
            "хватает 10,000 AI разработчиков.  У нас в работе 219 вакансий и только 42 выпускника на трудоустройство.  Мы работаем с\n",
            "ведущими компаниями, такими как РЖД, Совкомбанк, Ростелеком, KIA, Wildberries и другими.  Наше собственное AI HR\n",
            "агентство AI Hunter трудоустраивает в Сбер, Яндекс, МТС, Huawei и другие крупные компании.  Оставьте свои контакты (имя,\n",
            "телефон и email), и наш специалист свяжется с вами для обсуждения деталей курса и вашего проекта.\n",
            "ЦЕНА запроса: 0.0086  $\n",
            "Время ответа: 2.61 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYjKnYWFqIyl"
      },
      "source": [
        "# Диалог"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb43073-77a8-4e68-9bfc-d30763907931",
        "cellView": "form",
        "id": "vLdiCsV_ULhs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Здравствуйте, я нейро-консультант УИИ. Я знаю все об УИИ и готов помочь с любыми вопросами о нем.\n",
            "К нам часто обращаются, чтобы сменить профессию или сделать проект по ИИ. Почему Вы решили обратиться к нам? \n",
            "\n",
            "Вопрос клиента:я раньше интересовался IT, потом перешел в другую сферу. А теперь снова думаю перейти в IT\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " - Сменить деятельность: \"я раньше интересовался IT, потом перешел в другую сферу. А теперь снова думаю перейти в IT.\"\n",
            "ЦЕНА запроса: 0.00233  $\n",
            "Время ответа: 0.77 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " -\n",
            "ЦЕНА запроса: 0.00212  $\n",
            "Время ответа: 0.34 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Стоит ли мне снова перейти в IT?\n",
            "ЦЕНА запроса: 0.0012  $\n",
            "Время ответа: 0.40 секунд\n",
            "\n",
            "==================\n",
            "Агент консультант:\n",
            "Переход в IT-сферу может быть отличным решением по нескольким причинам. Во-первых, IT предоставляет стабильность и\n",
            "востребованность: ниша AI растет стремительными темпами, и спрос на специалистов в этой области только увеличивается.\n",
            "Во-вторых, работа в IT предлагает гибкий график и творческую свободу, что позволяет избежать рутины и заниматься\n",
            "интересными интеллектуальными задачами. Кроме того, российские программисты высоко ценятся на мировом рынке, что\n",
            "открывает дополнительные возможности для карьерного роста и финансовой стабильности.\n",
            "ЦЕНА запроса: 0.00864  $\n",
            "Время ответа: 1.45 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Какие цели и задачи Вы ставите перед собой, возвращаясь в сферу IT?\n",
            "ЦЕНА запроса: 0.00319  $\n",
            "Время ответа: 0.40 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Переход в IT-сферу может быть отличным решением по нескольким причинам.  IT предоставляет стабильность и\n",
            "востребованность: ниша AI растет стремительными темпами, и спрос на специалистов в этой области только увеличивается.\n",
            "Работа в IT предлагает гибкий график и творческую свободу, что позволяет избежать рутины и заниматься интересными\n",
            "интеллектуальными задачами.  Российские программисты высоко ценятся на мировом рынке, что открывает дополнительные\n",
            "возможности для карьерного роста и финансовой стабильности.\n",
            "ЦЕНА запроса: 0.00461  $\n",
            "Время ответа: 1.42 секунд\n",
            "Какие цели и задачи Вы ставите перед собой, возвращаясь в сферу IT?\n",
            "\n",
            "Вопрос клиента:хочу повышение уровня дохода, но боюсь что мне не хватит времени на обучение\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность в росте дохода: хочу повышение уровня дохода.\n",
            "ЦЕНА запроса: 0.00186  $\n",
            "Время ответа: 0.51 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " мне не хватит времени на учебу\n",
            "ЦЕНА запроса: 0.00202  $\n",
            "Время ответа: 0.41 секунд\n",
            "\n",
            "==================\n",
            "Агент Закрытия возражений:\n",
            " Понимаю ваше беспокойство по поводу времени. Наши курсы специально разработаны для занятых людей, таких как вы. Обучение\n",
            "занимает всего несколько часов в неделю, и вы можете заниматься в любое удобное для вас время. Это позволяет вам гибко\n",
            "планировать свое расписание и не жертвовать текущими обязательствами. Более того, повышение уровня дохода через освоение\n",
            "новых навыков в области нейронных сетей и программирования — это инвестиция в ваше будущее. Наши курсы помогут вам\n",
            "достичь этой цели, не отнимая много времени.\n",
            "ЦЕНА запроса: 0.00488  $\n",
            "Время ответа: 1.27 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Как Вы относитесь к возможности совмещения обучения с текущей работой или другими обязанностями?\n",
            "ЦЕНА запроса: 0.00394  $\n",
            "Время ответа: 0.42 секунд\n",
            "\n",
            "Вопрос клиента:можно конечно попробовать совместить, но я еще переживаю, что могу не справиться с программой обучения \n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность в уверенности в своих силах: переживаю, что могу не справиться с программой обучения.\n",
            "ЦЕНА запроса: 0.00205  $\n",
            "Время ответа: 0.55 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " могу не справиться с программой обучения\n",
            "ЦЕНА запроса: 0.00206  $\n",
            "Время ответа: 0.42 секунд\n",
            "\n",
            "==================\n",
            "Агент Закрытия возражений:\n",
            " Понимаю ваши переживания, это абсолютно нормально. Хочу вас заверить, что 80% наших студентов не программисты, и наши\n",
            "курсы специально разработаны для людей без технического образования. Мы предоставляем поддержку на каждом этапе\n",
            "обучения, чтобы вы могли успешно освоить материал. Кроме того, обучение занимает всего несколько часов в неделю, и вы\n",
            "можете заниматься в удобное для вас время. Наши преподаватели и нейросети всегда готовы помочь вам, чтобы вы чувствовали\n",
            "себя уверенно и справлялись с программой.\n",
            "ЦЕНА запроса: 0.00475  $\n",
            "Время ответа: 1.33 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Как вы относитесь к возможности получения поддержки и наставничества от опытных преподавателей и менторов в процессе\n",
            "обучения?\n",
            "ЦЕНА запроса: 0.00494  $\n",
            "Время ответа: 0.51 секунд\n",
            "\n",
            "Вопрос клиента:это было бы очень здорово\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность в поддержке и наставничестве: это было бы очень здорово.\n",
            "ЦЕНА запроса: 0.00191  $\n",
            "Время ответа: 0.43 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " -\n",
            "ЦЕНА запроса: 0.00188  $\n",
            "Время ответа: 0.31 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Как вы относитесь к возможности получения поддержки и наставничества от опытных преподавателей и менторов в процессе\n",
            "обучения?\n",
            "ЦЕНА запроса: 0.00148  $\n",
            "Время ответа: 0.99 секунд\n",
            "\n",
            "==================\n",
            "Агент консультант:\n",
            "Поддержка и наставничество от опытных преподавателей и менторов играют ключевую роль в процессе обучения. Наши студенты\n",
            "отмечают, что стажировки и работа в команде с опытными специалистами позволяют им получить уникальный практический опыт,\n",
            "который сложно найти в теоретических занятиях. Например, Вероника Жидяевская, работая над проектом для Platrum,\n",
            "подчеркнула, что реальная работа над задачами значительно отличается от учебных примеров и вдохновляет на дальнейшее\n",
            "развитие.   Кроме того, программа стажировок предоставляет возможность взаимодействовать с руководителями и клиентами,\n",
            "что развивает интеллектуальные навыки и помогает лучше понять реальные требования рынка. Это особенно важно для\n",
            "новичков, так как позволяет им сразу погрузиться в процесс работы и получить ценный опыт, который может быть востребован\n",
            "на любой должности.\n",
            "ЦЕНА запроса: 0.01066  $\n",
            "Время ответа: 4.04 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Как вы относитесь к возможности работать над реальными проектами в процессе обучения, чтобы сразу применять полученные\n",
            "знания на практике?\n",
            "ЦЕНА запроса: 0.00567  $\n",
            "Время ответа: 0.65 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Поддержка и наставничество от опытных преподавателей и менторов играют ключевую роль в процессе обучения.  Стажировки и\n",
            "работа в команде с опытными специалистами позволяют студентам получить уникальный практический опыт, который сложно\n",
            "найти в теоретических занятиях.  Вероника Жидяевская отметила, что реальная работа над задачами значительно отличается\n",
            "от учебных примеров и вдохновляет на дальнейшее развитие.  Программа стажировок предоставляет возможность\n",
            "взаимодействовать с руководителями и клиентами, что развивает интеллектуальные навыки и помогает лучше понять реальные\n",
            "требования рынка.  Для новичков это особенно важно, так как позволяет сразу погрузиться в процесс работы и получить\n",
            "ценный опыт, востребованный на любой должности.\n",
            "ЦЕНА запроса: 0.0056  $\n",
            "Время ответа: 1.87 секунд\n",
            "Как вы относитесь к возможности работать над реальными проектами в процессе обучения, чтобы сразу применять полученные знания на практике?\n",
            "\n",
            "Вопрос клиента:я бы хотел поработать над реальными проектами при обучении\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность в применении знаний на практике: я бы хотел поработать над реальными проектами при обучении.\n",
            "ЦЕНА запроса: 0.00203  $\n",
            "Время ответа: 0.78 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " -\n",
            "ЦЕНА запроса: 0.00193  $\n",
            "Время ответа: 0.31 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Вы хотите вернуться в IT и повысить доход. Наш курс по AI разработке идеально подходит для этого.  Гарантируем работу с\n",
            "зарплатой 70-120 тыс. руб. на старте и до 500 тыс. руб. через 3-4 года. 75% вакансий удалённые.  Возможность работать на\n",
            "заказ, не уходя с текущей работы. Проекты от 100 тыс. до 1.5 млн руб.  Повышение эффективности работы, карьерный рост и\n",
            "увеличение зарплаты на 30-100%.  В России не хватает 10,000 AI разработчиков. У нас 219 вакансий и только 42 выпускника\n",
            "на трудоустройство. Рост ниши AI - 38% в год.  6 месяцев обучения. 4 стажировки на реальных проектах. До 60 zoom\n",
            "консультаций с кураторами. Гарантия трудоустройства по договору или возврат стоимости. Нейро-куратор, нейро-проверка\n",
            "домашек и нейро-репетитор 24/7.  Единственные, кто преподаёт только AI. Стажировки в крупных компаниях: РЖД, Совкомбанк,\n",
            "Ростелеком и др. Собственное HR агентство AI Hunter.  Курс рассчитан на гибкий график, вы сможете совмещать с текущей\n",
            "работой. Нейро-куратор и нейро-репетитор помогут на каждом шагу, а стажировки дадут практический опыт.  Оставьте свои\n",
            "контакты (имя, телефон, email), и наш специалист свяжется с вами для обсуждения деталей курса.\n",
            "ЦЕНА запроса: 0.00972  $\n",
            "Время ответа: 5.20 секунд\n",
            "Что бы Вы хотели еще узнать? \n",
            "\n",
            "Вопрос клиента:Сколько стоит курс по AI разработке\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность в стоимости курса: Сколько стоит курс по AI разработке.\n",
            "ЦЕНА запроса: 0.00187  $\n",
            "Время ответа: 0.51 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " -\n",
            "ЦЕНА запроса: 0.00189  $\n",
            "Время ответа: 0.38 секунд\n",
            "\n",
            "==================\n",
            "Агент консультант:\n",
            "Курс по AI разработке в Университете Искусственного Интеллекта стоит 179 900 рублей.\n",
            "ЦЕНА запроса: 0.01179  $\n",
            "Время ответа: 0.58 секунд\n",
            "\n",
            "Вопрос клиента:стоп\n"
          ]
        }
      ],
      "source": [
        "#@title Запуск диалога\n",
        "# Инициализация списков для хранения истории чата, вопросов клиента и ответов менеджера\n",
        "history_chat = []\n",
        "history_user = []\n",
        "history_manager = []\n",
        "history_potr = []\n",
        "history_objection = []\n",
        "\n",
        "# Вывод ответов агентов\n",
        "verbose_router = 1\n",
        "verbose = 0\n",
        "verbose_question = 1\n",
        "verbose_prez = 0\n",
        "verbose_stilist = 0\n",
        "verbose_objection_close = 1\n",
        "\n",
        "# Приветственное сообщение\n",
        "welcome_message = \"\"\"Здравствуйте, я нейро-консультант УИИ. Я знаю все об УИИ и готов помочь с любыми вопросами о нем.\n",
        "К нам часто обращаются, чтобы сменить профессию или сделать проект по ИИ. Почему Вы решили обратиться к нам? \"\"\"\n",
        "\n",
        "# Добавление приветственного сообщения в историю чата и ответов\n",
        "history_chat.append(f\"Менеджер: {welcome_message}\")\n",
        "history_manager.append(welcome_message)\n",
        "print(welcome_message)\n",
        "\n",
        "# Бесконечный цикл для общения с клиентом\n",
        "first_question = True\n",
        "\n",
        "first_question_2 = True\n",
        "\n",
        "keywords_matched = False  # Флаг для отслеживания совпадения ключевых слов\n",
        "\n",
        "while True:\n",
        "    print()\n",
        "    # Получение вопроса от клиента\n",
        "    client_question = input('Вопрос клиента:')\n",
        "\n",
        "    # Добавление вопроса клиента в историю вопросов и чата\n",
        "    history_user.append(client_question)\n",
        "    history_chat.append(f\"Клиент: {client_question}\")\n",
        "\n",
        "    # Проверка, если клиент ввел 'stop' или 'стоп', прерываем цикл\n",
        "    if client_question.lower() in ['stop', 'стоп']:\n",
        "        break\n",
        "\n",
        "    # Генерация ответа от роутера на вопрос клиента\n",
        "    if first_question:\n",
        "        router_input = f\"Менеджер: {history_manager[-1]} Клиент: {history_user[-1]}\"\n",
        "        first_question = False\n",
        "    else:\n",
        "        router_input = f\"Менеджер: {answer_2} Клиент: {client_question}\"\n",
        "\n",
        "    router_response = user_question_router(system=system_prompt_router,\n",
        "                                           instructions=instructions_router,\n",
        "                                           topic=router_input,\n",
        "                                           temp=temperature_router, verbose=verbose_router,\n",
        "                                           model=model_router)\n",
        "    router_objection = user_objection_router(system=system_prompt_objection,\n",
        "                                           instructions=instructions_objection,\n",
        "                                           topic=router_input,\n",
        "                                           temp=temperature_objection, verbose=verbose_objection,\n",
        "                                           model=model_objection)\n",
        "    #print(\"Возражение:\", router_objection)\n",
        "    #print(\"Потребность:\", router_response)\n",
        "    # Добавление ответа роутера в историю возражений\n",
        "    history_objection.append(router_objection)\n",
        "\n",
        "    # Добавление ответа роутера в историю потребностей\n",
        "    history_potr.append(router_response)\n",
        "    if router_objection == \"-\":\n",
        "\n",
        "        #print(\"Отчет о потребностях: \", history_potr)\n",
        "        # Проверка результата роутера\n",
        "        if len(history_potr)>4 and not keywords_matched: # Когда выявлены потребности перед развилкой\n",
        "            #print(\"Ветка 1\")\n",
        "            # Приветственное сообщение\n",
        "\n",
        "            #test_message = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "\n",
        "            # Добавление приветственного сообщения в историю чата и ответов\n",
        "            #history_chat.append(f\"Менеджер: {test_message}\")\n",
        "            #history_manager.append(test_message)\n",
        "            #print(test_message)\n",
        "            #client_question = input(test_message)\n",
        "\n",
        "            #answers_test = user_potr(history_potr, temp=0, verbose=0, model= \"gpt-4o\")\n",
        "            answers_test = generate_summary_report(history_potr)\n",
        "            #print(answers_test)\n",
        "                # Генерация ответа менеджера с помощью prez_user_question\n",
        "            answer_prez = prez_user_question(system_prompt_prez, instructions_prez, answers_test, history_objection, temp=temperature_prez, verbose=0, k=relevant_chanks, model=model_prez)\n",
        "                # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "            answer = stilizator_answer_d(system_prompt_stilist_prez, instructions_stilist, answer_prez, temperature_stilist, verbose=1, model=\"gpt-4o\")\n",
        "\n",
        "            test_mes = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "            print(test_mes)\n",
        "\n",
        "            keywords_matched = True  # Устанавливаем флаг, чтобы больше не входить в эту ветку\n",
        "\n",
        "        elif len(history_potr)>4 and keywords_matched == True: # Когда сделана презентация и выявлены потребности - свободные ответы на вопросы\n",
        "            #print(\"Ветка 2\")\n",
        "            #test_mes = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "\n",
        "            #client_question = input(test_mes)\n",
        "            answer = answer_kons_d(system, instruction, client_question, db, history_chat, temperature, verbose, relevant_chanks, model)\n",
        "\n",
        "            #print(answer)\n",
        "\n",
        "\n",
        "        else: # Когда не выявлены потребности\n",
        "            #print(\"Ветка 3\")\n",
        "            # Генерация ответа от роутера на вопрос клиента\n",
        "            if first_question_2:\n",
        "                answer_vopros = user_question(system_prompt_question, instructions_question, client_question, temp=temperature_question, verbose=verbose_question, model=model_question)\n",
        "                first_question_2 = False\n",
        "            else:\n",
        "                client_question_2 = answer_2 + client_question\n",
        "                answer_vopros = user_question(system_prompt_question, instructions_question, client_question_2, temp=temperature_question, verbose=verbose_question, model=model_question)\n",
        "            # Генерация ответа менеджера с использованием функций answer_kons и spez_user_question\n",
        "            answer_1 = answer_kons(system, instruction, answer_vopros, db, history_chat, temperature, verbose, relevant_chanks, model)\n",
        "            answer_2 = spez_user_question(system_prompt_potr, instructions__potr, router_response, history_chat, temp, verbose=1, model=\"gpt-4o\")\n",
        "\n",
        "            # Объединение первого и второго ответов менеджера\n",
        "            #answer_stilist = answer_1 + answer_2\n",
        "            # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "            answer_stilist = stilizator_answer(system_prompt_stilist, instructions_stilist, answer_1, temperature_stilist, verbose=0, model=\"gpt-4o\")\n",
        "            answer = answer_stilist +\"\\n\"+ answer_2\n",
        "            print(answer_2)\n",
        "    else:\n",
        "        if len(history_potr)>4 and not keywords_matched: # Когда выявлены потребности\n",
        "            #print(\"Ветка 1\")\n",
        "            # Приветственное сообщение\n",
        "\n",
        "            #test_message = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "\n",
        "            # Добавление приветственного сообщения в историю чата и ответов\n",
        "            #history_chat.append(f\"Менеджер: {test_message}\")\n",
        "            #history_manager.append(test_message)\n",
        "            #print(test_message)\n",
        "            #client_question = input(test_message)\n",
        "\n",
        "            #answers_test = user_potr(history_potr, temp=0, verbose=0, model= \"gpt-4o\")\n",
        "            answers_test = generate_summary_report(history_potr)\n",
        "                # Генерация ответа менеджера с помощью prez_user_question\n",
        "            answer_prez = prez_user_question(system_prompt_prez, instructions_prez, answers_test, history_objection, temp=temperature_prez, verbose=0, k=relevant_chanks, model=model_prez)\n",
        "                # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "            answer = stilizator_answer_d(system_prompt_stilist_prez, instructions_stilist, answer_prez, temperature_stilist, verbose=1, model=\"gpt-4o\")\n",
        "\n",
        "            test_mes = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "            print(test_mes)\n",
        "\n",
        "            keywords_matched = True  # Устанавливаем флаг, чтобы больше не входить в эту ветку\n",
        "\n",
        "        elif len(history_potr)>4 and keywords_matched == True: # Когда сделана презентация и выявлены потребности - свободные ответы на вопросы\n",
        "            #print(\"Ветка 2\")\n",
        "            #test_mes = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "\n",
        "            #client_question = input(test_mes)\n",
        "            answer = answer_kons_d(system, instruction, client_question, db, history_chat, temperature, verbose, relevant_chanks, model)\n",
        "\n",
        "            #print(answer)\n",
        "\n",
        "\n",
        "        else: # Когда не выявлены потребности\n",
        "            #print(\"Ветка 3\")\n",
        "            # Генерация ответа от роутера на вопрос клиента\n",
        "\n",
        "            answer_objection = user_objection_close(system_prompt_objection_close, instructions_objection_close, client_question, temperature_objection_close, verbose_objection_close, relevant_chanks, model_objection_close);\n",
        "\n",
        "            # Генерация ответа менеджера с использованием функций answer_kons и spez_user_question\n",
        "            #answer_1 = answer_kons(system, instruction, answer_vopros, db, history_chat, temperature, verbose, relevant_chanks, model)\n",
        "            answer_2 = spez_user_question(system_prompt_potr, instructions__potr, router_response, history_chat, temp, verbose=1, model=\"gpt-4o\")\n",
        "\n",
        "            # Объединение ответа менеджера и закрытия потребности\n",
        "            #answer_i = answer_1 + answer_objection\n",
        "            # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "            #answer_stilist = stilizator_answer(system_prompt_stilist, instructions_stilist, answer_objection, temperature_stilist, verbose=0, model=\"gpt-4o\")\n",
        "            answer = answer_objection +\"\\n\"+ answer_2\n",
        "            #print(answer_2)\n",
        "    # Добавление ответа менеджера в историю чата и ответов\n",
        "    history_chat.append(f\"Менеджер: {answer}\")\n",
        "    history_manager.append(answer)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91130723-7e6c-4d1c-926a-ab2b0212cc8c",
        "cellView": "form",
        "id": "nC0q9U2HkBNT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Здравствуйте, я нейро-консультант УИИ. Я знаю все об УИИ и готов помочь с любыми вопросами о нем.\n",
            "К нам часто обращаются, чтобы сменить профессию или сделать проект по ИИ. Почему Вы решили обратиться к нам? \n",
            "\n",
            "Вопрос клиента:мне нужен проект на заказ, с кем мне связаться?\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность в развитии своего проекта: \"мне нужен проект на заказ\"\n",
            "ЦЕНА запроса: 0.00205  $\n",
            "Время ответа: 0.55 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " -\n",
            "ЦЕНА запроса: 0.00206  $\n",
            "Время ответа: 0.33 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " мне нужен проект на заказ, с кем мне связаться?\n",
            "ЦЕНА запроса: 0.00121  $\n",
            "Время ответа: 0.44 секунд\n",
            "\n",
            "==================\n",
            "Агент консультант:\n",
            "Для заказа проекта по искусственному интеллекту вам нужно связаться с представителем нашей компании.\n",
            "ЦЕНА запроса: 0.00654  $\n",
            "Время ответа: 0.63 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Какой тип проекта вы хотите реализовать и какие цели вы преследуете?\n",
            "ЦЕНА запроса: 0.00305  $\n",
            "Время ответа: 0.38 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Для заказа проекта по искусственному интеллекту необходимо связаться с представителем компании.\n",
            "ЦЕНА запроса: 0.00268  $\n",
            "Время ответа: 0.66 секунд\n",
            "Какой тип проекта вы хотите реализовать и какие цели вы преследуете?\n",
            "\n",
            "Вопрос клиента:Мне надо на производстве молочной продукции на конвейере находить дефекты\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность в развитии своего проекта: находить дефекты на производстве молочной продукции на конвейере.\n",
            "ЦЕНА запроса: 0.00199  $\n",
            "Время ответа: 0.62 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " -\n",
            "ЦЕНА запроса: 0.00189  $\n",
            "Время ответа: 0.34 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какой тип проекта вы хотите реализовать и какие цели вы преследуете?\n",
            "ЦЕНА запроса: 0.00137  $\n",
            "Время ответа: 0.47 секунд\n",
            "\n",
            "==================\n",
            "Агент консультант:\n",
            "Для реализации проекта по обнаружению дефектов на конвейере в производстве молочной продукции, вам потребуется помощь\n",
            "экспертов УИИ. Они помогут создать индивидуальный проект, начиная от сбора и разметки базы данных до интеграции и\n",
            "разработки приложений. Важно определить конкретные цели и требования вашего проекта, чтобы специалисты могли предложить\n",
            "наилучшие решения.\n",
            "ЦЕНА запроса: 0.00812  $\n",
            "Время ответа: 1.11 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Как вы видите будущее вашего проекта через 5 лет и какие результаты вы хотели бы достичь?\n",
            "ЦЕНА запроса: 0.00347  $\n",
            "Время ответа: 0.43 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Для реализации проекта по обнаружению дефектов на конвейере в производстве молочной продукции потребуется помощь\n",
            "экспертов УИИ.  Они помогут создать индивидуальный проект, начиная от сбора и разметки базы данных до интеграции и\n",
            "разработки приложений.  Важно определить конкретные цели и требования проекта, чтобы специалисты могли предложить\n",
            "наилучшие решения.\n",
            "ЦЕНА запроса: 0.00382  $\n",
            "Время ответа: 1.02 секунд\n",
            "Как вы видите будущее вашего проекта через 5 лет и какие результаты вы хотели бы достичь?\n",
            "\n",
            "Вопрос клиента:есть конвейер на нем едут бутылки, нужно определять 2 вида дефектов: заполнена ли полностью бутылка молоком и правильно ли закручена крышка. Хочу уже через полгода уменьшить процент брака и сократить расходы на контроль качества\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " - Развитие своего проекта: \"Хочу уже через полгода уменьшить процент брака и сократить расходы на контроль качества.\"\n",
            "ЦЕНА запроса: 0.00228  $\n",
            "Время ответа: 0.71 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " -\n",
            "ЦЕНА запроса: 0.00212  $\n",
            "Время ответа: 0.31 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Как вы видите будущее вашего проекта через 5 лет и какие результаты вы хотели бы достичь?\n",
            "ЦЕНА запроса: 0.00168  $\n",
            "Время ответа: 0.50 секунд\n",
            "\n",
            "==================\n",
            "Агент консультант:\n",
            "Ваш проект по обнаружению дефектов на конвейере в производстве молочной продукции имеет большой потенциал. В ближайшие 5\n",
            "лет вы можете ожидать значительного улучшения качества продукции и снижения затрат на контроль качества. Использование\n",
            "искусственного интеллекта позволит автоматизировать процесс обнаружения дефектов, что приведет к более точным и быстрым\n",
            "результатам.  Как показывает опыт наших студентов, таких как Павел Соколов, успешное внедрение AI-технологий может\n",
            "вдохновить на дальнейшее развитие и реализацию новых проектов. Например, Павел уже работает над проектом по\n",
            "распознаванию цифр и надписей, что подтверждает эффективность и практическую значимость таких решений.  Кроме того, как\n",
            "отметил Билл Гейтс, развитие нейросетей позволит делегировать рутинные задачи и сосредоточиться на более важных аспектах\n",
            "бизнеса. Это значит, что ваш проект может не только улучшить текущие процессы, но и открыть новые возможности для роста\n",
            "и инноваций.  В итоге, через 5 лет вы можете ожидать: 1. Существенное снижение процента брака. 2. Сокращение расходов на\n",
            "контроль качества. 3. Повышение общей эффективности производства. 4. Возможность масштабирования и внедрения новых AI-\n",
            "решений в другие аспекты вашего бизнеса.\n",
            "ЦЕНА запроса: 0.01239  $\n",
            "Время ответа: 3.17 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Как вы оцениваете текущий уровень автоматизации на вашем производстве и видите ли вы потенциал для его улучшения с\n",
            "помощью технологий искусственного интеллекта?\n",
            "ЦЕНА запроса: 0.0045  $\n",
            "Время ответа: 0.65 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Ваш проект по обнаружению дефектов на конвейере в производстве молочной продукции имеет большой потенциал.  В ближайшие\n",
            "5 лет можно ожидать значительного улучшения качества продукции и снижения затрат на контроль качества.  Использование\n",
            "искусственного интеллекта позволит автоматизировать процесс обнаружения дефектов, что приведет к более точным и быстрым\n",
            "результатам.  Опыт студентов, таких как Павел Соколов, показывает, что успешное внедрение AI-технологий может вдохновить\n",
            "на дальнейшее развитие и реализацию новых проектов.  Павел уже работает над проектом по распознаванию цифр и надписей,\n",
            "что подтверждает эффективность и практическую значимость таких решений.  Развитие нейросетей позволит делегировать\n",
            "рутинные задачи и сосредоточиться на более важных аспектах бизнеса.  Ваш проект может не только улучшить текущие\n",
            "процессы, но и открыть новые возможности для роста и инноваций.  Через 5 лет можно ожидать существенное снижение\n",
            "процента брака, сокращение расходов на контроль качества, повышение общей эффективности производства и возможность\n",
            "масштабирования и внедрения новых AI-решений в другие аспекты бизнеса.\n",
            "ЦЕНА запроса: 0.00737  $\n",
            "Время ответа: 68.71 секунд\n",
            "Как вы оцениваете текущий уровень автоматизации на вашем производстве и видите ли вы потенциал для его улучшения с помощью технологий искусственного интеллекта?\n",
            "\n",
            "Вопрос клиента:средний уровень автоматизации, поэтому хотим с помощью искусственного интеллекта повысить его\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность в улучшении текущей позиции в компании: хотим с помощью искусственного интеллекта повысить уровень\n",
            "автоматизации.\n",
            "ЦЕНА запроса: 0.00214  $\n",
            "Время ответа: 0.70 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " -\n",
            "ЦЕНА запроса: 0.002  $\n",
            "Время ответа: 0.34 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Как вы оцениваете текущий уровень автоматизации на вашем производстве и видите ли вы потенциал для его улучшения с\n",
            "помощью технологий искусственного интеллекта?\n",
            "ЦЕНА запроса: 0.00175  $\n",
            "Время ответа: 0.64 секунд\n",
            "\n",
            "==================\n",
            "Агент консультант:\n",
            "Ваше стремление повысить уровень автоматизации на производстве с помощью технологий искусственного интеллекта вполне\n",
            "обосновано. Как показывают исследования, внедрение ИИ позволяет значительно сократить затраты и повысить эффективность.\n",
            "Например, 94% компаний, использующих ИИ, отметили снижение затрат, а около 70% компаний увидели реальный финансовый\n",
            "эффект.   Кроме того, опыт наших студентов, таких как Павел Соколов, подтверждает, что успешное внедрение AI-технологий\n",
            "может привести к значительным улучшениям в производственных процессах. Ваша цель по уменьшению процента брака и\n",
            "сокращению расходов на контроль качества через полгода вполне достижима с помощью ИИ.   Таким образом, автоматизация с\n",
            "использованием ИИ может не только улучшить текущие процессы, но и открыть новые возможности для роста и инноваций на\n",
            "вашем производстве.\n",
            "ЦЕНА запроса: 0.01254  $\n",
            "Время ответа: 2.72 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Как вы оцениваете важность обучения ваших сотрудников новым технологиям для успешного внедрения и использования\n",
            "искусственного интеллекта на вашем производстве?\n",
            "ЦЕНА запроса: 0.00598  $\n",
            "Время ответа: 0.54 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Ваше стремление повысить уровень автоматизации на производстве с помощью технологий искусственного интеллекта вполне\n",
            "обосновано.  Внедрение ИИ позволяет значительно сократить затраты и повысить эффективность.  94% компаний, использующих\n",
            "ИИ, отметили снижение затрат, а около 70% компаний увидели реальный финансовый эффект.  Опыт наших студентов, таких как\n",
            "Павел Соколов, подтверждает, что успешное внедрение AI-технологий может привести к значительным улучшениям в\n",
            "производственных процессах.  Ваша цель по уменьшению процента брака и сокращению расходов на контроль качества через\n",
            "полгода вполне достижима с помощью ИИ.  Автоматизация с использованием ИИ может не только улучшить текущие процессы, но\n",
            "и открыть новые возможности для роста и инноваций на вашем производстве.\n",
            "ЦЕНА запроса: 0.00581  $\n",
            "Время ответа: 1.60 секунд\n",
            "Как вы оцениваете важность обучения ваших сотрудников новым технологиям для успешного внедрения и использования искусственного интеллекта на вашем производстве?\n",
            "\n",
            "Вопрос клиента:я хочу аутсорс, без привлечения моих сотрудников\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность в аутсорсинге: я хочу аутсорс, без привлечения моих сотрудников.\n",
            "ЦЕНА запроса: 0.00206  $\n",
            "Время ответа: 0.54 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о возражениях:\n",
            " -\n",
            "ЦЕНА запроса: 0.00195  $\n",
            "Время ответа: 0.34 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Для Вас важно быстро и эффективно развить проект по обнаружению дефектов на производстве молочной продукции. Наш курс по\n",
            "искусственному интеллекту идеально подходит для достижения этой цели.  Гарантируем трудоустройство по договору. Средняя\n",
            "зарплата junior AI разработчика 70-120 тысяч рублей, senior - 300-500 тысяч рублей через 3-4 года. 75% вакансий\n",
            "удалённые.  Возможность работать на фрилансе, не покидая текущую работу. Цена проекта от 100 тысяч до 1.5 млн рублей.\n",
            "Повышение эффективности вашего производства, снижение процента брака и сокращение расходов на контроль качества.\n",
            "Возможность повышения в должности и зарплате на 30-100%.  Длительность курса 6 месяцев. 4 стажировки на реальных\n",
            "проектах в крупных компаниях. До 60 zoom консультаций с кураторами. Возврат всей стоимости, если не трудоустроим. Нейро-\n",
            "куратор, нейро-проверка домашек, нейро-репетитор - 24/7.  Единственные, кто преподаёт только AI. Более 340 занятий.\n",
            "Стажировки в РЖД, Совкомбанк, Ростелеком, KIA, Wildberries и других. Собственное AI HR агентство AI hunter,\n",
            "трудоустраиваем в Сбер, Яндекс, МТС, Совкомбанк, Ростелеком, Huawei, Dell и другие.  Оставьте свои контакты (имя,\n",
            "телефон, email), и наш специалист свяжется с Вами для обсуждения деталей курса.\n",
            "ЦЕНА запроса: 0.00962  $\n",
            "Время ответа: 3.43 секунд\n",
            "Что бы Вы хотели еще узнать? \n",
            "\n",
            "Вопрос клиента:стоп\n"
          ]
        }
      ],
      "source": [
        "#@title Запуск диалога\n",
        "# Инициализация списков для хранения истории чата, вопросов клиента и ответов менеджера\n",
        "history_chat = []\n",
        "history_user = []\n",
        "history_manager = []\n",
        "history_potr = []\n",
        "history_objection = []\n",
        "\n",
        "# Вывод ответов агентов\n",
        "verbose_router = 1\n",
        "verbose = 0\n",
        "verbose_question = 1\n",
        "verbose_prez = 0\n",
        "verbose_stilist = 0\n",
        "verbose_objection_close = 1\n",
        "\n",
        "# Приветственное сообщение\n",
        "welcome_message = \"\"\"Здравствуйте, я нейро-консультант УИИ. Я знаю все об УИИ и готов помочь с любыми вопросами о нем.\n",
        "К нам часто обращаются, чтобы сменить профессию или сделать проект по ИИ. Почему Вы решили обратиться к нам? \"\"\"\n",
        "\n",
        "# Добавление приветственного сообщения в историю чата и ответов\n",
        "history_chat.append(f\"Менеджер: {welcome_message}\")\n",
        "history_manager.append(welcome_message)\n",
        "print(welcome_message)\n",
        "\n",
        "# Бесконечный цикл для общения с клиентом\n",
        "first_question = True\n",
        "\n",
        "first_question_2 = True\n",
        "\n",
        "keywords_matched = False  # Флаг для отслеживания совпадения ключевых слов\n",
        "\n",
        "while True:\n",
        "    print()\n",
        "    # Получение вопроса от клиента\n",
        "    client_question = input('Вопрос клиента:')\n",
        "\n",
        "    # Добавление вопроса клиента в историю вопросов и чата\n",
        "    history_user.append(client_question)\n",
        "    history_chat.append(f\"Клиент: {client_question}\")\n",
        "\n",
        "    # Проверка, если клиент ввел 'stop' или 'стоп', прерываем цикл\n",
        "    if client_question.lower() in ['stop', 'стоп']:\n",
        "        break\n",
        "\n",
        "    # Генерация ответа от роутера на вопрос клиента\n",
        "    if first_question:\n",
        "        router_input = f\"Менеджер: {history_manager[-1]} Клиент: {history_user[-1]}\"\n",
        "        first_question = False\n",
        "    else:\n",
        "        router_input = f\"Менеджер: {answer_2} Клиент: {client_question}\"\n",
        "\n",
        "    router_response = user_question_router(system=system_prompt_router,\n",
        "                                           instructions=instructions_router,\n",
        "                                           topic=router_input,\n",
        "                                           temp=temperature_router, verbose=verbose_router,\n",
        "                                           model=model_router)\n",
        "    router_objection = user_objection_router(system=system_prompt_objection,\n",
        "                                           instructions=instructions_objection,\n",
        "                                           topic=router_input,\n",
        "                                           temp=temperature_objection, verbose=verbose_objection,\n",
        "                                           model=model_objection)\n",
        "    #print(\"Возражение:\", router_objection)\n",
        "    #print(\"Потребность:\", router_response)\n",
        "    # Добавление ответа роутера в историю возражений\n",
        "    history_objection.append(router_objection)\n",
        "\n",
        "    # Добавление ответа роутера в историю потребностей\n",
        "    history_potr.append(router_response)\n",
        "    if router_objection == \"-\":\n",
        "\n",
        "        #print(\"Отчет о потребностях: \", history_potr)\n",
        "        # Проверка результата роутера\n",
        "        if len(history_potr)>4 and not keywords_matched: # Когда выявлены потребности перед развилкой\n",
        "            #print(\"Ветка 1\")\n",
        "            # Приветственное сообщение\n",
        "\n",
        "            #test_message = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "\n",
        "            # Добавление приветственного сообщения в историю чата и ответов\n",
        "            #history_chat.append(f\"Менеджер: {test_message}\")\n",
        "            #history_manager.append(test_message)\n",
        "            #print(test_message)\n",
        "            #client_question = input(test_message)\n",
        "\n",
        "            #answers_test = user_potr(history_potr, temp=0, verbose=0, model= \"gpt-4o\")\n",
        "            answers_test = generate_summary_report(history_potr)\n",
        "            #print(answers_test)\n",
        "                # Генерация ответа менеджера с помощью prez_user_question\n",
        "            answer_prez = prez_user_question(system_prompt_prez, instructions_prez, answers_test, history_objection, temp=temperature_prez, verbose=0, k=relevant_chanks, model=model_prez)\n",
        "                # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "            answer = stilizator_answer_d(system_prompt_stilist_prez, instructions_stilist, answer_prez, temperature_stilist, verbose=1, model=\"gpt-4o\")\n",
        "\n",
        "            test_mes = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "            print(test_mes)\n",
        "\n",
        "            keywords_matched = True  # Устанавливаем флаг, чтобы больше не входить в эту ветку\n",
        "\n",
        "        elif len(history_potr)>4 and keywords_matched == True: # Когда сделана презентация и выявлены потребности - свободные ответы на вопросы\n",
        "            #print(\"Ветка 2\")\n",
        "            #test_mes = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "\n",
        "            #client_question = input(test_mes)\n",
        "            answer = answer_kons_d(system, instruction, client_question, db, history_chat, temperature, verbose, relevant_chanks, model)\n",
        "\n",
        "            #print(answer)\n",
        "\n",
        "\n",
        "        else: # Когда не выявлены потребности\n",
        "            #print(\"Ветка 3\")\n",
        "            # Генерация ответа от роутера на вопрос клиента\n",
        "            if first_question_2:\n",
        "                answer_vopros = user_question(system_prompt_question, instructions_question, client_question, temp=temperature_question, verbose=verbose_question, model=model_question)\n",
        "                first_question_2 = False\n",
        "            else:\n",
        "                client_question_2 = answer_2 + client_question\n",
        "                answer_vopros = user_question(system_prompt_question, instructions_question, client_question_2, temp=temperature_question, verbose=verbose_question, model=model_question)\n",
        "            # Генерация ответа менеджера с использованием функций answer_kons и spez_user_question\n",
        "            answer_1 = answer_kons(system, instruction, answer_vopros, db, history_chat, temperature, verbose, relevant_chanks, model)\n",
        "            answer_2 = spez_user_question(system_prompt_potr, instructions__potr, router_response, history_chat, temp, verbose=1, model=\"gpt-4o\")\n",
        "\n",
        "            # Объединение первого и второго ответов менеджера\n",
        "            #answer_stilist = answer_1 + answer_2\n",
        "            # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "            answer_stilist = stilizator_answer(system_prompt_stilist, instructions_stilist, answer_1, temperature_stilist, verbose=0, model=\"gpt-4o\")\n",
        "            answer = answer_stilist +\"\\n\"+ answer_2\n",
        "            print(answer_2)\n",
        "    else:\n",
        "        if len(history_potr)>4 and not keywords_matched: # Когда выявлены потребности\n",
        "            #print(\"Ветка 1\")\n",
        "            # Приветственное сообщение\n",
        "\n",
        "            #test_message = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "\n",
        "            # Добавление приветственного сообщения в историю чата и ответов\n",
        "            #history_chat.append(f\"Менеджер: {test_message}\")\n",
        "            #history_manager.append(test_message)\n",
        "            #print(test_message)\n",
        "            #client_question = input(test_message)\n",
        "\n",
        "            #answers_test = user_potr(history_potr, temp=0, verbose=0, model= \"gpt-4o\")\n",
        "            answers_test = generate_summary_report(history_potr)\n",
        "                # Генерация ответа менеджера с помощью prez_user_question\n",
        "            answer_prez = prez_user_question(system_prompt_prez, instructions_prez, answers_test, history_objection, temp=temperature_prez, verbose=0, k=relevant_chanks, model=model_prez)\n",
        "                # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "            answer = stilizator_answer_d(system_prompt_stilist_prez, instructions_stilist, answer_prez, temperature_stilist, verbose=1, model=\"gpt-4o\")\n",
        "\n",
        "            test_mes = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "            print(test_mes)\n",
        "\n",
        "            keywords_matched = True  # Устанавливаем флаг, чтобы больше не входить в эту ветку\n",
        "\n",
        "        elif len(history_potr)>4 and keywords_matched == True: # Когда сделана презентация и выявлены потребности - свободные ответы на вопросы\n",
        "            #print(\"Ветка 2\")\n",
        "            #test_mes = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "\n",
        "            #client_question = input(test_mes)\n",
        "            answer = answer_kons_d(system, instruction, client_question, db, history_chat, temperature, verbose, relevant_chanks, model)\n",
        "\n",
        "            #print(answer)\n",
        "\n",
        "\n",
        "        else: # Когда не выявлены потребности\n",
        "            #print(\"Ветка 3\")\n",
        "            # Генерация ответа от роутера на вопрос клиента\n",
        "\n",
        "            answer_objection = user_objection_close(system_prompt_objection_close, instructions_objection_close, client_question, temperature_objection_close, verbose_objection_close, relevant_chanks, model_objection_close);\n",
        "\n",
        "            # Генерация ответа менеджера с использованием функций answer_kons и spez_user_question\n",
        "            #answer_1 = answer_kons(system, instruction, answer_vopros, db, history_chat, temperature, verbose, relevant_chanks, model)\n",
        "            answer_2 = spez_user_question(system_prompt_potr, instructions__potr, router_response, history_chat, temp, verbose=1, model=\"gpt-4o\")\n",
        "\n",
        "            # Объединение ответа менеджера и закрытия потребности\n",
        "            #answer_i = answer_1 + answer_objection\n",
        "            # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "            #answer_stilist = stilizator_answer(system_prompt_stilist, instructions_stilist, answer_objection, temperature_stilist, verbose=0, model=\"gpt-4o\")\n",
        "            answer = answer_objection +\"\\n\"+ answer_2\n",
        "            #print(answer_2)\n",
        "    # Добавление ответа менеджера в историю чата и ответов\n",
        "    history_chat.append(f\"Менеджер: {answer}\")\n",
        "    history_manager.append(answer)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}