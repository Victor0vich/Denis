{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victor0vich/Denis/blob/main/%D0%92%D0%B5%D0%B1%D0%B8%D0%BD%D0%B0%D1%80_3_%D0%B4%D0%B5%D0%BA%D0%B0%D0%B1%D1%80%D1%8F_%D0%9D%D0%B5%D0%B9%D1%80%D0%BE_%D0%BA%D0%BE%D0%BD%D1%81%D1%83%D0%BB%D1%8C%D1%82%D0%B0%D0%BD%D1%82_%D0%BD%D0%B0_Llama_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4eK4jE272Nv"
      },
      "source": [
        "> Примечание!!! В этом колабе используется база знаний, созданная на основе информации, взятой с сайта https://skyeng.ru/  (Школа английского языка Skyeng)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I12fie2F8lAE"
      },
      "source": [
        "## Бaза знаний\n",
        "\n",
        ">Размер базы - 94 страницы\n",
        "\n",
        "Ссылка на базу:\n",
        "\n",
        "https://docs.google.com/document/d/1aNcrmTAok2PCV5r6xPGswY8s7NKNlgC-mxyosEipjfo/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekCriGf1FFbx"
      },
      "source": [
        "# Схема агентов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w260Of6uQCIe"
      },
      "source": [
        "                    \n",
        "\n",
        "```\n",
        "\n",
        "                       |Агент Отчета о потребностях|\n",
        "                      ______________|_________________________\n",
        "                     |                                        |\n",
        "                    /\\                                |Агент Презентации|\n",
        "                   /  \\                                       |        \n",
        "                  /    \\                              |Агент Стилизации 2|\n",
        "|Агент Потребностей|  |Агент Выявления вопросов|              |\n",
        "         |                         |                  |Агент Консультант|\n",
        "         |                |Агент Консультант|                 \n",
        "         |_________________________|                  \n",
        "                    |                                         \n",
        "           |Агент Стилизации 1|                       \n",
        "                                                             \n",
        "                                                      \n",
        "                        \n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml1ktWx6pneN"
      },
      "source": [
        "* `Агент Отчета о потребностях` - этот агент создает отчет о потребностях\n",
        "\n",
        "\n",
        "* `Агент Потребностей` - этот агент формулирует вопросы для выявления потребностей клиента\n",
        "\n",
        "* `Агент Выявления вопросов` - этот агент определяет клиент размышляет/отвечает или задает вопрос. Если размышляет/отвечает, то эти размышления переделываются в форму вопроса перед подачей в `Агент Консультант`. Если клиент задает вопрос, то этот вопрос без изменений подается в `Агент Консультант`\n",
        "\n",
        "* `Агент Консультант` - этот агент формирует ответы на основании базы знаний УИИ\n",
        "\n",
        "* `Агент Презентации` - этот агент формирует презентацию опираясь на отчет по потребностям\n",
        "\n",
        "* `Агент Стилизации 1` - этот агент \"причесывает\" итоговый ответ после `Агент Консультант`, убирая лишнее\n",
        "\n",
        "* `Агент Стилизации 2` - этот агент \"причесывает\" итоговый ответ в стиле продажи после `Агент Презентации`, убирая лишнее\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RayCjCyvv2FR",
        "outputId": "d8002c84-a7cf-44f3-db05-508f4acc651d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain==0.0.330\n",
            "  Downloading langchain-0.0.330-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting faiss-cpu==1.7.3\n",
            "  Downloading faiss_cpu-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (3.11.2)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.330)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (1.33)\n",
            "Collecting langsmith<0.1.0,>=0.0.52 (from langchain==0.0.330)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.330) (2.32.3)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.330)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.330) (1.17.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.330) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.330) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.330) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.330)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.330)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.330) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.330) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.330) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.330) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.330) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.330) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.330) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.330) (3.1.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.330) (24.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.330)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.0.330-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: faiss-cpu, tenacity, mypy-extensions, marshmallow, typing-inspect, tiktoken, langsmith, dataclasses-json, openai, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.1.143\n",
            "    Uninstalling langsmith-0.1.143:\n",
            "      Successfully uninstalled langsmith-0.1.143\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.4\n",
            "    Uninstalling openai-1.54.4:\n",
            "      Successfully uninstalled openai-1.54.4\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-core 0.3.19 requires langsmith<0.2.0,>=0.1.125, but you have langsmith 0.0.92 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.7.3 langchain-0.0.330 langsmith-0.0.92 marshmallow-3.23.1 mypy-extensions-1.0.0 openai-0.28.1 tenacity-8.5.0 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "#@title Установка и импорт библиотек\n",
        "\n",
        "!pip install tiktoken langchain==0.0.330 openai==0.28.1 faiss-cpu==1.7.3\n",
        "\n",
        "import textwrap\n",
        "\n",
        "# Модуль для работы с функциями, связанными с паролями\n",
        "import getpass\n",
        "\n",
        "# Модуль для загрузки файлов из Google Drive\n",
        "import gdown\n",
        "\n",
        "\n",
        "# Модуль для работы с файловой системой и операционной системой\n",
        "import os\n",
        "\n",
        "# Модуль для работы с регулярными выражениями\n",
        "import re\n",
        "\n",
        "# Библиотека для работы с API OpenAI\n",
        "import openai\n",
        "\n",
        "# Модуль для создания глубоких копий объектов\n",
        "import copy\n",
        "\n",
        "# Импортируем стандартный модуль time, который предоставляет функции для работы с временем\n",
        "import time\n",
        "\n",
        "# Модуль для работы с токенизацией текста\n",
        "import tiktoken\n",
        "\n",
        "# Импортируем загрузчик текстовых документов из langchain\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# Импортируем прогресс-бар для Jupyter Notebook\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "# Модуль для работы с сериализацией и десериализацией объектов\n",
        "import pickle\n",
        "\n",
        "# Импортируем модель OpenAI из langchain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Импортируем класс Document из langchain для работы с документами\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# Библиотека для выполнения HTTP-запросов\n",
        "import requests\n",
        "\n",
        "# Импортируем класс для создания эмбеддингов с помощью OpenAI из langchain\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "# Импортируем класс FAISS для работы с векторными индексами из langchain\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Импортируем класс для рекурсивного разделения текста на фрагменты из langchain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Игнорирование предупреждений\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Настройка логирования для модуля text_splitter из langchain\n",
        "import logging\n",
        "logging.getLogger(\"langchain.text_splitter\").setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r4c1yT1v4jO",
        "outputId": "de58dacd-e18e-414d-ebbd-c1a647d4c977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ],
      "source": [
        "# Получение ключа API OpenAI от пользователя\n",
        "# Функция getpass.getpass() запрашивает ввод пароля или ключа без отображения ввода на экране\n",
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "\n",
        "# Установка ключа API в переменную окружения\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "\n",
        "# Установка ключа API для использования библиотекой openai\n",
        "openai.api_key = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbMXDINyppmG",
        "outputId": "c39f793f-2d90-4a53-df3b-9e0864ebf436",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XpnLrKLJSnH7gC_kBltSsaezP0ti4F55\n",
            "To: /content/faiss_index.pkl\n",
            "100%|██████████| 1.01M/1.01M [00:00<00:00, 155MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title Загружаем базу знаний\n",
        "\n",
        "# Скачиваем файл с Google Drive по указанной ссылке и сохраняем его под именем 'faiss_index.pkl'\n",
        "gdown.download('https://drive.google.com/uc?id=1XpnLrKLJSnH7gC_kBltSsaezP0ti4F55', 'faiss_index.pkl', quiet=False)\n",
        "\n",
        "def load_db_from_file(filename):\n",
        "    with open(filename, 'rb') as f:  # Открываем файл для чтения в бинарном режиме\n",
        "        db_loaded = pickle.load(f)   # Загружаем объект из файла с помощью pickle\n",
        "        print(\"FAISS index loaded from faiss_index.pkl\")  # Выводим сообщение о успешной загрузке\n",
        "    return db_loaded  # Возвращаем загруженный объект\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzsxyxJZkpDt",
        "outputId": "97e971de-c2b7-4601-ea0b-1858b27a18ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index loaded from faiss_index.pkl\n"
          ]
        }
      ],
      "source": [
        "# Загрузка объекта db в переменную\n",
        "db = load_db_from_file('faiss_index.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO5ptaQfB3E4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459eba66-cbbf-453d-b1ba-2d9ad879abb9",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "=========== GPU подключен! ===========\n",
            "Collecting llama-cpp-python==0.2.85 (from llama-cpp-python[server]==0.2.85)\n",
            "  Downloading llama_cpp_python-0.2.85.tar.gz (49.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.85->llama-cpp-python[server]==0.2.85) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.85->llama-cpp-python[server]==0.2.85) (1.26.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.85->llama-cpp-python[server]==0.2.85)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.85->llama-cpp-python[server]==0.2.85) (3.1.4)\n",
            "Collecting uvicorn>=0.22.0 (from llama-cpp-python[server]==0.2.85)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastapi>=0.100.0 (from llama-cpp-python[server]==0.2.85)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting pydantic-settings>=2.0.1 (from llama-cpp-python[server]==0.2.85)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting sse-starlette>=1.6.1 (from llama-cpp-python[server]==0.2.85)\n",
            "  Downloading sse_starlette-2.1.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting starlette-context<0.4,>=0.3.6 (from llama-cpp-python[server]==0.2.85)\n",
            "  Downloading starlette_context-0.3.6-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python[server]==0.2.85) (6.0.2)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.100.0->llama-cpp-python[server]==0.2.85)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.100.0->llama-cpp-python[server]==0.2.85) (2.9.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.85->llama-cpp-python[server]==0.2.85) (3.0.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.0.1->llama-cpp-python[server]==0.2.85)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from sse-starlette>=1.6.1->llama-cpp-python[server]==0.2.85) (3.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.22.0->llama-cpp-python[server]==0.2.85) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.22.0->llama-cpp-python[server]==0.2.85) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100.0->llama-cpp-python[server]==0.2.85) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100.0->llama-cpp-python[server]==0.2.85) (2.23.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio->sse-starlette>=1.6.1->llama-cpp-python[server]==0.2.85) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->sse-starlette>=1.6.1->llama-cpp-python[server]==0.2.85) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->sse-starlette>=1.6.1->llama-cpp-python[server]==0.2.85) (1.2.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading sse_starlette-2.1.3-py3-none-any.whl (9.4 kB)\n",
            "Downloading starlette_context-0.3.6-py3-none-any.whl (12 kB)\n",
            "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.85-cp310-cp310-linux_x86_64.whl size=255061975 sha256=77a443a3102919c8399aaffd341f1c6b35b4da4bac16070bb8f6525f41ae98f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e8/4e/29a754f9175ef52b6481cd75e3af4de38bf6dfa9c2972f75d4\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: uvicorn, python-dotenv, diskcache, starlette, llama-cpp-python, starlette-context, sse-starlette, pydantic-settings, fastapi\n",
            "Successfully installed diskcache-5.6.3 fastapi-0.115.5 llama-cpp-python-0.2.85 pydantic-settings-2.6.1 python-dotenv-1.0.1 sse-starlette-2.1.3 starlette-0.41.3 starlette-context-0.3.6 uvicorn-0.32.1\n"
          ]
        }
      ],
      "source": [
        "# @title Установка и импорт библиотеки Llama\n",
        "!pip install tqdm requests\n",
        "\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('=========== GPU подключен! ===========')\n",
        "    # !CMAKE_ARGS=\"-DGGML_CUDA=on\" pip install llama-cpp-python==0.2.85\n",
        "    !CMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python[server]==0.2.85\n",
        "\n",
        "else:\n",
        "    print('=========== CPU подключен! ===========')\n",
        "    !pip install -q --upgrade --force-reinstall llama-cpp-python==0.2.85 --no-cache-dir\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Конфигурация модели Llama-3.1-70B\n",
        "model_config = {\n",
        "    \"url\": 'https://huggingface.co/lmstudio-community/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q4_K_M.gguf',\n",
        "    \"chat_format\": None,  # Формат сообщений (None означает стандартный формат)\n",
        "    \"n_ctx\": 8192,  # Максимальная длина контекста для модели\n",
        "    \"n_gpu_layers\": 65  # Количество слоев, которые будут выполняться на GPU\n",
        "}"
      ],
      "metadata": {
        "id": "wrvKZJcQWSV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Конфигурация модели Llama-3.1-8B\n",
        "model_config =  {\n",
        "      \"url\":'https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf',\n",
        "      \"chat_format\": None,  # Формат сообщений (None означает стандартный формат)\n",
        "      \"n_ctx\": 4096,  # Максимальная длина контекста для модели\n",
        "      \"n_gpu_layers\": 41  # Количество слоев, которые будут выполняться на GPU\n",
        "}"
      ],
      "metadata": {
        "id": "dcRx2jS1WSJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7PQjVrODnTm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Функции для загрузки модели\n",
        "import os  # Модуль для работы с файловой системой\n",
        "from llama_cpp import Llama  # Импортируем класс для работы с Llama\n",
        "from tqdm import tqdm  # Удобная библиотека для отображения прогресс-баров\n",
        "import requests  # Библиотека для выполнения HTTP-запросов\n",
        "\n",
        "\n",
        "# 1. Функция загрузки файла модели\n",
        "def download_model(model_config):\n",
        "    \"\"\"\n",
        "    Загружает файл модели, если он отсутствует на локальной машине.\n",
        "    \"\"\"\n",
        "    url = model_config.get('url')  # Извлекаем URL для скачивания модели\n",
        "    filename = url.split('/')[-1]  # Имя файла берется из последней части URL\n",
        "\n",
        "    if not os.path.exists(filename):  # Проверяем, существует ли файл на диске\n",
        "        response = requests.get(url, stream=True)  # Отправляем HTTP-запрос для скачивания файла\n",
        "        total_size = int(response.headers.get('content-length', 0))  # Определяем общий размер файла\n",
        "        block_size = 1024  # Размер блока (1 КБ) для чтения файла по частям\n",
        "        t = tqdm(total=total_size, unit='iB', unit_scale=True)  # Инициализируем прогресс-бар\n",
        "        with open(filename, 'wb') as file:  # Открываем файл для записи в бинарном режиме\n",
        "            for data in response.iter_content(block_size):  # Считываем файл блоками\n",
        "                t.update(len(data))  # Обновляем прогресс-бар\n",
        "                file.write(data)  # Пишем данные в файл\n",
        "        t.close()  # Закрываем прогресс-бар\n",
        "        if total_size != 0 and t.n != total_size:  # Проверяем, полностью ли скачан файл\n",
        "            raise ValueError(\"Ошибка при загрузке файла модели.\")  # Если нет, выбрасываем исключение\n",
        "    else:\n",
        "        print(f\"Файл модели {filename} уже существует.\")  # Уведомляем, что файл уже есть\n",
        "    return filename  # Возвращаем имя файла\n",
        "\n",
        "# 2. Функция загрузки модели\n",
        "def load_llama_model(filename, model_config):\n",
        "    \"\"\"\n",
        "    Загружает модель Llama из указанного файла конфигурации.\n",
        "    \"\"\"\n",
        "    llm = Llama(  # Инициализируем объект модели Llama\n",
        "        model_path=filename,  # Путь к файлу модели\n",
        "        chat_format=model_config['chat_format'],  # Формат сообщений\n",
        "        n_ctx=model_config['n_ctx'],  # Максимальная длина контекста\n",
        "        n_threads=16,  # Количество потоков для обработки (зависит от ресурсов системы)\n",
        "        n_gpu_layers=model_config['n_gpu_layers'],  # Слои для выполнения на GPU\n",
        "        f16_kv=True,  # Использование 16-битных ключей/значений для экономии памяти\n",
        "        verbose=False  # Убираем лишнюю информацию из вывода\n",
        "    )\n",
        "    return llm  # Возвращаем загруженную модель\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ce4045-7a34-4f6c-dd8d-dd98c8314cd3",
        "id": "TMzjMms3XUIW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42.5G/42.5G [16:53<00:00, 42.0MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# Скачиваем модель, если она еще не существует\n",
        "filename = download_model(model_config)  # Загружаем модель"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем модель с помощью Llama\n",
        "llm = load_llama_model(filename, model_config)  # Загружаем модель"
      ],
      "metadata": {
        "id": "ABJvf1XyXahe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhMx1N6X1nLd"
      },
      "source": [
        "## Агент Консультант для ответов на вопросы по базе знаний"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77Odbcz57gX8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Функция для получения ответа на вопрос на основе заданной темы и поискового индекса\n",
        "def answer_kons(system, instruction, topic, search_index, summary_history, temp=1, verbose=0, k=8, model=\"gpt-3.5-turbo-16k\"):\n",
        "    \"\"\"\n",
        "    Функция для получения ответа на вопрос на основе заданной темы и поискового индекса.\n",
        "\n",
        "    Параметры:\n",
        "    system (str): Промт.\n",
        "    instruction (str): Инструкция для пользователя.\n",
        "    topic (str): Тема или вопрос, на который нужно ответить.\n",
        "    search_index (object): Векторная база.\n",
        "    temp (float): Температура для генерации ответов модели (по умолчанию 1).\n",
        "    verbose (int): Флаг для включения/выключения подробного вывода (по умолчанию 0).\n",
        "    k (int): Количество похожих документов для поиска (по умолчанию 8).\n",
        "    model (str): Имя модели, используемой для генерации ответов (по умолчанию \"gpt-3.5-turbo-16k\").\n",
        "    \"\"\"\n",
        "\n",
        "    # Поиск документов, похожих на заданную тему/вопрос\n",
        "    docs = search_index.similarity_search(topic, k=k)\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель\n",
        "    #if verbose: print('\\n ========\\n')\n",
        "\n",
        "    # Создание содержимого сообщения, объединяя текст найденных документов\n",
        "    message_content = re.sub(r'\\r\\n', ' ', '\\n '.join([f'\\n--------------------\\n' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
        "\n",
        "    # Если включен подробный вывод, напечатать содержимое сообщения\n",
        "    if verbose: print('Чанки :\\n ======================================== \\n', message_content)\n",
        "\n",
        "    # Формирование сообщений для модели\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f\"{instruction}.\\n{message_content}.\\n\\nВопрос:\\n{topic}\\n\\nХронология предыдущих сообщений диалога: {summary_history}\\n\\nОтвет:\"}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    # Создание запроса к модели OpenAI\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,  # Имя модели\n",
        "        messages=messages,  # Сообщения для модели\n",
        "        temperature=temp  # Температура генерации\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель\n",
        "    #if verbose: print('\\n =========================================== ')\n",
        "\n",
        "\n",
        "    # Получение ответа от модели\n",
        "    answer = completion.choices[0].message.content\n",
        "    #print()\n",
        "    #print()\n",
        "    #print(\"Полный ответ от GPT:\")\n",
        "    #print(completion)\n",
        "    print('\\n==================')\n",
        "    print(\"Менеджер:\")\n",
        "    # Форматирование ответа для удобства чтения\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    print(formatted_answer)\n",
        "    #print(f\"Количество использованных токенов на запрос: {completion['usage']['prompt_tokens']}\")\n",
        "    #print(f\"Количество использованных токенов на ответ: {completion['usage']['completion_tokens']}\")\n",
        "    #print(f\"Общее количество использованных токенов (вопрос-ответ): {completion['usage']['total_tokens']}\")\n",
        "    #print()\n",
        "    #print('ЦЕНА запроса:', (3 * completion['usage']['prompt_tokens'] / 1000000) + (4 * completion['usage']['completion_tokens']/ 1000000), ' $')  # Вычисляем стоимость запроса\n",
        "    print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "def answer_kons_d(system, instruction, topic, search_index, summary_history, temp=1, verbose=0, k=8, model=\"gpt-3.5-turbo-16k\"):\n",
        "    \"\"\"\n",
        "    Функция для получения ответа на вопрос на основе заданной темы и поискового индекса.\n",
        "\n",
        "    Параметры:\n",
        "    system (str): Промт.\n",
        "    instruction (str): Инструкция для пользователя.\n",
        "    topic (str): Тема или вопрос, на который нужно ответить.\n",
        "    search_index (object): Векторная база.\n",
        "    temp (float): Температура для генерации ответов модели (по умолчанию 1).\n",
        "    verbose (int): Флаг для включения/выключения подробного вывода (по умолчанию 0).\n",
        "    k (int): Количество похожих документов для поиска (по умолчанию 8).\n",
        "    model (str): Имя модели, используемой для генерации ответов (по умолчанию \"gpt-3.5-turbo-16k\").\n",
        "    \"\"\"\n",
        "\n",
        "    # Поиск документов, похожих на заданную тему/вопрос\n",
        "    docs = search_index.similarity_search(topic, k=k)\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель\n",
        "    #if verbose: print('\\n ========\\n')\n",
        "\n",
        "    # Создание содержимого сообщения, объединяя текст найденных документов\n",
        "    message_content = re.sub(r'\\r\\n', ' ', '\\n '.join([f'\\n--------------------\\n' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
        "\n",
        "    # Если включен подробный вывод, напечатать содержимое сообщения\n",
        "    if verbose: print('Чанки :\\n ======================================== \\n', message_content)\n",
        "\n",
        "    # Формирование сообщений для модели\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f\"{instruction}.\\n{message_content}.\\n\\nВопрос:\\n{topic}\\n\\nХронология предыдущих сообщений диалога: {summary_history}\\n\\nОтвет:\"}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    # Создание запроса к модели OpenAI\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,  # Имя модели\n",
        "        messages=messages,  # Сообщения для модели\n",
        "        temperature=temp  # Температура генерации\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель\n",
        "    #if verbose: print('\\n =========================================== ')\n",
        "\n",
        "\n",
        "    # Получение ответа от модели\n",
        "    answer = completion.choices[0].message.content\n",
        "    #print()\n",
        "    #print()\n",
        "    #print(\"Полный ответ от GPT:\")\n",
        "    #print(completion)\n",
        "    print('\\n==================')\n",
        "    print(\"Менеджер:\")\n",
        "    # Форматирование ответа для удобства чтения\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print(formatted_answer)\n",
        "    #print(f\"Количество использованных токенов на запрос: {completion['usage']['prompt_tokens']}\")\n",
        "    #print(f\"Количество использованных токенов на ответ: {completion['usage']['completion_tokens']}\")\n",
        "    #print(f\"Общее количество использованных токенов (вопрос-ответ): {completion['usage']['total_tokens']}\")\n",
        "    #print()\n",
        "    #print('ЦЕНА запроса:', (3 * completion['usage']['prompt_tokens'] / 1000000) + (4 * completion['usage']['completion_tokens']/ 1000000), ' $')  # Вычисляем стоимость запроса\n",
        "    #print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "def answer_kons_d_llama(model, system, instruction, topic, search_index, summary_history, temp=1, verbose=0, k=8, max_tokens=1000):\n",
        "\n",
        "\n",
        "    # Поиск документов, похожих на заданную тему/вопрос\n",
        "    docs = search_index.similarity_search(topic, k=k)\n",
        "\n",
        "\n",
        "    # Создание содержимого сообщения, объединяя текст найденных документов\n",
        "    message_content = re.sub(r'\\r\\n', ' ', '\\n '.join([f'\\n--------------------\\n' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
        "\n",
        "    # Если включен подробный вывод, напечатать содержимое сообщения\n",
        "    if verbose: print('Чанки :\\n ======================================== \\n', message_content)\n",
        "\n",
        "    # Формирование сообщений для модели\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f\"{instruction}.\\n{message_content}.\\n\\nВопрос:\\n{topic}\\n\\nХронология предыдущих сообщений диалога: {summary_history}\\n\\nОтвет:\"}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    # Создание запроса к модели OpenAI\n",
        "    completion = model.create_chat_completion(  # Вызываем метод для генерации ответа\n",
        "            max_tokens=max_tokens,  # Максимальное количество токенов в ответе\n",
        "            temperature=temp,  # Температура генерации (0 = детерминированный ответ)\n",
        "            messages=messages # Сообщения для модели\n",
        "        )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель\n",
        "    #if verbose: print('\\n =========================================== ')\n",
        "\n",
        "\n",
        "    # Получение ответа от модели\n",
        "    answer = completion['choices'][0]['message']['content']\n",
        "    #print()\n",
        "    #print()\n",
        "    #print(\"Полный ответ от GPT:\")\n",
        "    #print(completion)\n",
        "    print('\\n==================')\n",
        "    print(\"Менеджер:\")\n",
        "    # Форматирование ответа для удобства чтения\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print(formatted_answer)\n",
        "    #print(f\"Количество использованных токенов на запрос: {completion['usage']['prompt_tokens']}\")\n",
        "    #print(f\"Количество использованных токенов на ответ: {completion['usage']['completion_tokens']}\")\n",
        "    #print(f\"Общее количество использованных токенов (вопрос-ответ): {completion['usage']['total_tokens']}\")\n",
        "    #print()\n",
        "    #print('ЦЕНА запроса:', (3 * completion['usage']['prompt_tokens'] / 1000000) + (4 * completion['usage']['completion_tokens']/ 1000000), ' $')  # Вычисляем стоимость запроса\n",
        "    #print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "def answer_kons_llama(model, system, instruction, topic, search_index, summary_history, temp=1, verbose=0, k=8, max_tokens=1000):\n",
        "\n",
        "    # Поиск документов, похожих на заданную тему/вопрос\n",
        "    docs = search_index.similarity_search(topic, k=k)\n",
        "\n",
        "    # Если включен подробный вывод, напечатать разделитель\n",
        "    #if verbose: print('\\n ========\\n')\n",
        "\n",
        "    # Создание содержимого сообщения, объединяя текст найденных документов\n",
        "    message_content = re.sub(r'\\r\\n', ' ', '\\n '.join([f'\\n--------------------\\n' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
        "\n",
        "    # Если включен подробный вывод, напечатать содержимое сообщения\n",
        "    if verbose: print('Чанки :\\n ======================================== \\n', message_content)\n",
        "\n",
        "        # Формирование сообщений для модели\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f\"{instruction}.\\n{message_content}.\\n\\nВопрос:\\n{topic}\\n\\nХронология предыдущих сообщений диалога: {summary_history}\\n\\nОтвет:\"}\n",
        "    ]\n",
        "\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = model.create_chat_completion(  # Вызываем метод для генерации ответа\n",
        "            max_tokens=max_tokens,  # Максимальное количество токенов в ответе\n",
        "            temperature=temp,  # Температура генерации (0 = детерминированный ответ)\n",
        "            messages=messages # Сообщения для модели\n",
        "        )\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    answer = completion['choices'][0]['message']['content']\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "\n",
        "    print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    return formatted_answer  # Возвращаем текст ответа"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG0kBtc57gX-"
      },
      "source": [
        "Промт и инструкция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBUhXrh17gX-"
      },
      "outputs": [],
      "source": [
        "# Подгружаем промт\n",
        "system = ''' # Ты профессиональный помощник в чате компании\n",
        "\n",
        "\n",
        "## 1. Общие обязанности и цели - Компания продает курсы по английскому языку. У компании есть большой документ со всеми материалами\n",
        "о продуктах компании. - Твоя обязанность: Дать Клиенту краткий корректный ответ на русском языке в чате, опираясь на отрывки\n",
        "из этого документа. - Твоя цель: Отвечать максимально кратко и точно по документу, не придумывать ничего от себя.\n",
        "\n",
        "\n",
        "## 2. Ограничения в общении - Запрещено общаться на стороннюю тему. Если Клиент задает стороннюю тему, спрашивает не\n",
        "по теме английского языка, не по материалам и продуктам Компании, ты категорически отказываешься\n",
        "отвечать.\n",
        "\n",
        "\n",
        "## 3. Секретность документа\n",
        "- Запрещено упоминать в ответе, что ты анализировал отрывки документов и брал оттуда информацию.\n",
        "\n",
        "'''\n",
        "\n",
        "# Инструкция для модели о том, как использовать контекст для ответа на вопрос\n",
        "instruction = '''Проанализируй предыдущий диалог чтобы написать свой ответ последовательным и логичным.\n",
        "Категорически запрещено повторяться и здороваться.\n",
        "Используйте следующие фрагменты контекста, чтобы ответить на вопрос в конце.\n",
        "Стилистика ответа должна быть поддерживающей беседу в контексте важности и полезности изучения английского языка.\n",
        "Если вы не знаете ответа, просто скажите, что не знаете, не пытайтесь придумывать ответ.\n",
        "Тебе запрещено продавать, предлагать курсы. Запрещено спрашивать клиента что его еще интересует.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель llama-3.1-8b"
      ],
      "metadata": {
        "id": "woEv5hLga5si"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ9jqLnua5si"
      },
      "source": [
        "Параметры для запроса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZAUV_NSa5sj"
      },
      "outputs": [],
      "source": [
        "# Задаем температуру генерации ответа\n",
        "# Температура 0 означает, что модель будет давать более детерминированные ответы, строго опираясь на предоставленный контекст\n",
        "temperature = 0\n",
        "\n",
        "# Задаем количество релевантных чанков (фрагментов текста) для формирования ответа\n",
        "relevant_chanks = 3\n",
        "\n",
        "# Флаг для включения/выключения вывода релевантных чанков\n",
        "verbose = 0\n",
        "\n",
        "# Имя модели, используемой для генерации ответов\n",
        "model = llm\n",
        "\n",
        "max_tokens=1000 # Количество токенов на ответ\n",
        "\n",
        "# История диалога\n",
        "history = [\"\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос с чанками"
      ],
      "metadata": {
        "id": "g72hz8mwa5sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Есть ли пробные уроки?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51fc7982-f06a-4029-9613-ef58afa11b3d",
        "id": "1ghbaYuZa5sj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Чанки :\n",
            " ======================================== \n",
            " \n",
            "--------------------\n",
            "2. 96 + 3 урока  \n",
            "1 350 ₽ за урок  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3. 64 + 3 урока  \n",
            "1 550 ₽ за урок  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4. 32 + 3 урока  \n",
            "1 850 ₽ за урок  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "5. 16 + 2 урока  \n",
            "1 990 ₽ за урок  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "6. 8 + 1 урок  \n",
            "2 350 ₽ за урок  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "7. 4 + 1 урок  \n",
            "2 690 ₽ за урок  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "## Что такое пробный урок?\n",
            "\n",
            "\n",
            "Это бесплатное занятие, которое позволит вам освоиться. Первая часть проходит индивидуально: можно «пощупать» платформу, пройти небольшой тест, определить уровень языка и подобрать программу. После к вам подключится методист, чтобы ответить на все вопросы, рассказать о процессе обучения и помочь сформировать расписание.\n",
            "\n",
            "\n",
            "## Я могу получить бесплатный пробный урок только после оплаты?\n",
            "\n",
            "\n",
            "## Что нужно, чтобы начать обучение онлайн?\n",
            "\n",
            "\n",
            "## Не получается прийти на урок, что делать?\n",
            "\n",
            "\n",
            "## Мало свободного времени, боюсь, не буду успевать заниматься\n",
            "\n",
            "\n",
            "## Нужно ли что-то из канцелярии для пробного урока?\n",
            "\n",
            "\n",
            "## Сколько длится один урок?\n",
            "\n",
            "\n",
            "## Экспресс-курсы — это не вредно?\n",
            "\n",
            "\n",
            "## Что еще входит в цену курса, кроме самого курса? \n",
            "Иерархия фрагмента текста в документе: # Чувствуйте себя уверенно в общении с коллегами, партнерами и клиентами на английском языке ## Что еще входит в цену курса, кроме самого курса? пункт 1.\n",
            "\n",
            " \n",
            "--------------------\n",
            "Есть и второй вариант. Расскажите нам о том, что вы цените в учителе, и мы сами найдем подходящего по вашим критериям. А если что-то пойдет не так, его можно будет заменить. Это легко сделать в личном кабинете.\n",
            "\n",
            "\n",
            "## Что еще входит в цену курса, кроме самого курса?\n",
            "\n",
            "\n",
            "Вместе с курсами уроков каждый студент может бесплатно практиковать английский в разговорном клубе. Также у нас есть бесплатное приложение. В нем можно просматривать материалы уроков, учить слова на тренажере, проходить видеопрактику и делать много других полезностей. Все это доступно в любое время 24/7.\n",
            "\n",
            "\n",
            "## Я уже начинал учить английский язык и бросил, потому что было скучно. На курсе будут те же задания, что и в старых учебниках? \n",
            "Иерархия фрагмента текста в документе: # Курсы английского языка с нуля ## Я уже начинал учить английский язык и бросил, потому что было скучно. На курсе будут те же задания, что и в старых учебниках?\n",
            "\n",
            " \n",
            "--------------------\n",
            "Есть и второй вариант. Расскажите нам о том, что вы цените в учителе, и мы сами найдем подходящего по вашим критериям. А если что-то пойдет не так, его можно будет заменить. Это легко сделать в личном кабинете.\n",
            "\n",
            "\n",
            "## Что еще входит в цену курса, кроме самого курса?\n",
            "\n",
            "\n",
            "Вместе с курсами уроков каждый студент может бесплатно практиковать английский в разговорном клубе. Также у нас есть бесплатное приложение. В нем можно просматривать материалы уроков, учить слова на тренажере, проходить видеопрактику и делать много других полезностей. Все это доступно в любое время 24/7.\n",
            "\n",
            "\n",
            "## Я уже начинал учить английский язык и бросил, потому что было скучно. На курсе будут те же задания, что и в старых учебниках? \n",
            "Иерархия фрагмента текста в документе: # Курсы английского языка для начинающих ## Я уже начинал учить английский язык и бросил, потому что было скучно. На курсе будут те же задания, что и в старых учебниках?\n",
            "\n",
            "Время ответа: 2.63 секунд\n",
            "Ответ: Да, есть пробные уроки. Они бесплатные и позволяют вам освоиться с платформой, пройти небольшой тест, определить уровень\n",
            "языка и подобрать программу.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsOlVwzpa5sk"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Что нужно, чтобы начать изучение английского онлайн с Skyeng?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1cc3b6-2a7a-49a7-b3d8-ff597385e1a2",
        "id": "Dk0bbUCxa5sk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 1.69 секунд\n",
            "Ответ: Чтобы начать изучение английского онлайн с Skyeng, вам не нужно ничего, кроме устройства с микрофоном, камерой и\n",
            "доступом к сайту Skyeng.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mosUVJbka5sl"
      },
      "source": [
        "Запрос 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0357f75e-451d-414a-b8a1-014ccac99a53",
        "id": "00o7oq-xa5sl"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 1.64 секунд\n",
            "Ответ: Одно занятие в Skyeng длится 50 минут.\n"
          ]
        }
      ],
      "source": [
        "topic = \"Какова продолжительность урока английского в Skyeng?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j4Wk532a5sl"
      },
      "source": [
        "Запрос 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77921c94-3c35-46fb-dfad-a0805a2b9613",
        "id": "4KQZdzk8a5sl"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 7.80 секунд\n",
            "Ответ: Давайте разберемся в вопросе. Вы хотите узнать, как проходит индивидуальное занятие с репетитором.   В нашем курсе\n",
            "каждый студент получает индивидуальную стратегию изучения английского, разработанную нашими методистами. Это означает,\n",
            "что репетитор подберет для вас подходящую программу и учебные пособия, исходя из ваших ресурсов, целей и графика.\n",
            "Также вы сможете участвовать в разговорных клубах и получать методические рекомендации от специалиста, который\n",
            "отслеживает ваш учебный процесс.   Это все, что я могу сказать на этот вопрос.\n"
          ]
        }
      ],
      "source": [
        "topic = \"Как проходит индивидуальное занятие с репетитором?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlZrUwrca5sm"
      },
      "source": [
        "Запрос 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c93b8ff9-3a01-4587-fd81-5a302e9375c2",
        "id": "Uym8xwdAa5sm"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 4.19 секунд\n",
            "Ответ: В Skyeng вы сможете изучать английский язык с помощью коммуникативной методики, которая позволяет вам начать говорить на\n",
            "английском уже с первого занятия и практиковаться в разговорной речи большую часть времени. Это поможет вам получить\n",
            "реальные навыки общения и переступить языковой барьер.\n"
          ]
        }
      ],
      "source": [
        "topic = \"В чем преимущество изучения английского именно в Skyeng?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXejBtrta5sn"
      },
      "source": [
        "Запрос 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ed338e-4475-4dd4-92c4-60a7ab393977",
        "id": "ByQIt6Fwa5sn"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 3.88 секунд\n",
            "Ответ: Да, смысл начинать учить английский язык, даже если вы не знаете его совсем. Это поможет вам свободно общаться с людьми,\n",
            "читать и писать на английском, что может быть полезно в личной и профессиональной жизни.\n"
          ]
        }
      ],
      "source": [
        "topic = \"Если я вообще не знаю английского, есть смысл начинать его учить?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель llama-3.1-70b"
      ],
      "metadata": {
        "id": "Xkd4p6D2NB7J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGhkftt_7gX_"
      },
      "source": [
        "Параметры для запроса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHCyMGhw7gX_"
      },
      "outputs": [],
      "source": [
        "# Задаем температуру генерации ответа\n",
        "# Температура 0 означает, что модель будет давать более детерминированные ответы, строго опираясь на предоставленный контекст\n",
        "temperature = 0\n",
        "\n",
        "# Задаем количество релевантных чанков (фрагментов текста) для формирования ответа\n",
        "relevant_chanks = 3\n",
        "\n",
        "# Флаг для включения/выключения вывода релевантных чанков\n",
        "verbose = 0\n",
        "\n",
        "# Имя модели, используемой для генерации ответов\n",
        "model = llm\n",
        "\n",
        "max_tokens=1000 # Количество токенов на ответ\n",
        "\n",
        "# История диалога\n",
        "history = [\"\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C2Nnd657gX_"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Что нужно, чтобы начать изучение английского онлайн с Skyeng?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qsjfuUATTgP",
        "outputId": "272a53ac-54a6-4b4d-cb45-ec6dc7876351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 15.60 секунд\n",
            "Ответ: Чтобы начать обучение, вам понадобится устройство с микрофоном, камерой и доступом к сайту Skyeng.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "972onJZBNKCL"
      },
      "source": [
        "Запрос 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0191e88c-6b30-46fa-f3a1-f3e115d1a887",
        "id": "fAQ8wRKDNKCL"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 8.75 секунд\n",
            "Ответ: Одно занятие в Skyeng длится 50 минут.\n"
          ]
        }
      ],
      "source": [
        "topic = \"Какова продолжительность урока английского в Skyeng?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pkQlKevNKb6"
      },
      "source": [
        "Запрос 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffcddc54-db53-4577-af53-dc5eaa00d381",
        "id": "FDS6xmL7NKb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 16.65 секунд\n",
            "Ответ: Для эффективного обучения наши методисты составят программу и подберут учебные пособия, исходя из ваших ресурсов, целей\n",
            "и графика.\n"
          ]
        }
      ],
      "source": [
        "topic = \"Как проходит индивидуальное занятие с репетитором?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNsEeVHpNK9b"
      },
      "source": [
        "Запрос 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea267d26-fd10-46ec-f0db-6750e27c5781",
        "id": "MSHqqMhqNK9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 22.29 секунд\n",
            "Ответ: В Skyeng вы будете изучать правила только 20% времени, а остальную часть урока посвятите разговорной практике. Это\n",
            "поможет привыкнуть к общению, живой речи и научиться разговаривать свободно и без стеснения.\n"
          ]
        }
      ],
      "source": [
        "topic = \"В чем преимущество изучения английского именно в Skyeng?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K2Ik_URNLI7"
      },
      "source": [
        "Запрос 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ee59e6-91da-4ca3-b024-207996269aa9",
        "id": "8hiNVR26NLI8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 34.65 секунд\n",
            "Ответ: Да, есть смысл начинать учить английский, даже если вы не знаете его совсем. Мы предлагаем программу обучения\n",
            "английскому с нуля, которая включает 44 онлайн-урока и 9 тематических модулей. Вы сможете начать читать и писать на\n",
            "английском, общаться с иностранцами на простые темы и познакомиться с основами языка.\n"
          ]
        }
      ],
      "source": [
        "topic = \"Если я вообще не знаю английского, есть смысл начинать его учить?\"\n",
        "answer = answer_kons_llama(model, system, instruction, topic, db, history, temperature, verbose, relevant_chanks, max_tokens)\n",
        "print(\"Ответ:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель GPT-4o-mini"
      ],
      "metadata": {
        "id": "g1gTmyg1Njkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры запроса"
      ],
      "metadata": {
        "id": "-poo6oZcNlL7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfmbDe8_7gYD"
      },
      "outputs": [],
      "source": [
        "# Задаем температуру генерации ответа\n",
        "# Температура 0 означает, что модель будет давать более детерминированные ответы, строго опираясь на предоставленный контекст\n",
        "temperature = 0\n",
        "\n",
        "# Задаем количество релевантных чанков (фрагментов текста) для формирования ответа\n",
        "relevant_chanks = 3\n",
        "\n",
        "# Флаг для включения/выключения вывода релевантных чанков\n",
        "verbose = 0\n",
        "\n",
        "# Имя модели, используемой для генерации ответов\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "# История диалога\n",
        "\n",
        "history = [\"\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 1"
      ],
      "metadata": {
        "id": "u4w58njFNqG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Что нужно, чтобы начать изучение английского онлайн с Skyeng?\"\n",
        "answer_kons(system, instruction, topic, db, history, temperature, verbose, relevant_chanks, model);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TRSVmPUhE5f",
        "outputId": "46e65b15-1fff-437b-b194-530c9e27b4fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Чтобы начать изучение английского онлайн с Skyeng, вам нужно лишь устройство с микрофоном, камерой и доступом к сайту.\n",
            "Это достаточно для начала обучения.\n",
            "Время ответа: 0.95 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25ngjFwE7gYE"
      },
      "source": [
        "Запрос 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7224ee70-f3f2-4f25-c0df-910b466054a0",
        "id": "6nFO8YJe7gYE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Одно занятие в Skyeng длится 50 минут.\n",
            "Время ответа: 0.73 секунд\n"
          ]
        }
      ],
      "source": [
        "topic = \"Какова продолжительность урока английского в Skyeng?\"\n",
        "answer_kons(system, instruction, topic, db, history, temperature, verbose, relevant_chanks, model);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "1QecHIrzN3vJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c41bd4c-897e-4468-fc47-694760ddcf24",
        "id": "rxapf2ne7gYF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Индивидуальное занятие с репетитором проходит в комфортном для вас темпе. Преподаватели, прошедшие дополнительное\n",
            "обучение, помогут построить программу, учитывая ваши материалы и цели. Вы можете общаться с преподавателем вне занятий,\n",
            "а также вносить изменения в расписание по мере необходимости.\n",
            "Время ответа: 1.64 секунд\n"
          ]
        }
      ],
      "source": [
        "topic = \"Как проходит индивидуальное занятие с репетитором?\"\n",
        "answer_kons(system, instruction, topic, db, history, temperature, verbose, relevant_chanks, model);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZC3JVspOGQe"
      },
      "source": [
        "Запрос 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224e98eb-a95c-4166-f8f5-365d9f1255fb",
        "id": "wGDGofjQOGQe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Преимущество изучения английского в Skyeng заключается в использовании коммуникативной методики, которая позволяет\n",
            "студентам говорить на английском уже с первого занятия. 80% времени на уроках посвящено разговорной практике, что\n",
            "помогает преодолеть языковой барьер и развить реальные навыки общения. Кроме того, опытные преподаватели, прошедшие\n",
            "строгий отбор, обеспечивают качественное обучение, а гибкая структура курсов позволяет адаптировать программу под\n",
            "индивидуальные цели ученика.\n",
            "Время ответа: 2.66 секунд\n"
          ]
        }
      ],
      "source": [
        "topic = \"В чем преимущество изучения английского именно в Skyeng?\"\n",
        "answer_kons(system, instruction, topic, db, history, temperature, verbose, relevant_chanks, model);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Atk4Be4OGQf"
      },
      "source": [
        "Запрос 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2f6166-3aaf-4761-f64e-111ee12a56e7",
        "id": "eO8M6N6GOGQf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Да, есть смысл начинать учить английский язык с нуля. Это поможет вам расширить словарный запас, разобраться в\n",
            "грамматике и научиться понимать живую речь на слух. Вы сможете свободно общаться с людьми, читать и писать на\n",
            "английском. Начать изучение проще, чем кажется, и можно делать это в удобном для вас темпе.\n",
            "Время ответа: 2.11 секунд\n"
          ]
        }
      ],
      "source": [
        "topic = \"Если я вообще не знаю английского, есть смысл начинать его учить?\"\n",
        "answer_kons(system, instruction, topic, db, history, temperature, verbose, relevant_chanks, model);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOmYdlJp7gYG"
      },
      "source": [
        "## Агент Отчета о потребностях"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l8CwytA7gYG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Функция для маршрутизации вопроса пользователя\n",
        "def user_question_router(system, instructions, topic, temp=0, verbose=0, model='gpt-3.5-turbo-1106'):\n",
        "    #if verbose: print('\\n==================\\n')\n",
        "    #if verbose: print('Саммари диалога:\\n==================\\n',\n",
        "                      #topic)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "                                      \\n\\nВопрос менеджера и ответ клиента:\\n{topic}.\n",
        "                                      \\n\\nОтвет: '''}\n",
        "    ]\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    answer = completion.choices[0].message.content\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    #print(f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Агент Отчета о потребностях:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "    return answer\n",
        "\n",
        "# Функция суммарной потребности\n",
        "def user_potr(potr_history, temp=0, verbose=0, model= \"gpt-4o\"):\n",
        "    resulting_string = \", \".join(potr_history)\n",
        "    completion_prez = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "        {\"role\": \"system\", \"content\": \"\"\"Вы лучший менеджер по продажам.\n",
        "Вы понимаете какие потребности клиента надо выявить, чтобы полностью понять желания и боли клиента,\n",
        "которые можно удовлетворить при помощи обучения английскому языку.\n",
        "Вы знаете, что важно выявить есть ли у клиента такие потребности: для работы, учебы, путешествий, личного развития и т.д.\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f''' На основании Отчета по потребностям отпредели основную потребность клиента. В ответе четко сформулируй только эту потребность в виде темы для статьи.\n",
        "\n",
        "         Отчет по потребностям: {resulting_string}'''}],\n",
        "        temperature=0\n",
        "    )\n",
        "    answer_prez = completion_prez.choices[0].message.content\n",
        "    #print(answer_prez)\n",
        "    return answer_prez\n",
        "\n",
        "\n",
        "\n",
        "def user_question_router_llama(model, system, instructions, topic, temp=0, verbose=0, max_tokens=1000):\n",
        "    #if verbose: print('\\n==================\\n')\n",
        "    #if verbose: print('Саммари диалога:\\n==================\\n',\n",
        "                      #topic)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "                                      \\n\\nВопрос менеджера и ответ клиента:\\n{topic}.\n",
        "                                      \\n\\nОтвет: '''}\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = model.create_chat_completion(  # Вызываем метод для генерации ответа\n",
        "            max_tokens=max_tokens,  # Максимальное количество токенов в ответе\n",
        "            temperature=temp,  # Температура генерации (0 = детерминированный ответ)\n",
        "            messages=messages # Сообщения для модели\n",
        "        )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    answer = completion['choices'][0]['message']['content']\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    #print(f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Агент Отчета о потребностях:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "    return answer\n",
        "\n",
        "# Функция суммарной потребности\n",
        "def user_potr_llama(model, potr_history, temp=0, verbose=0, max_tokens=1000):\n",
        "    resulting_string = \", \".join(potr_history)\n",
        "\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"\"\"Вы лучший менеджер по продажам.\n",
        "Вы понимаете какие потребности клиента надо выявить, чтобы полностью понять желания и боли клиента,\n",
        "которые можно удовлетворить при помощи обучения английскому языку.\n",
        "Вы знаете, что важно выявить есть ли у клиента такие потребности: для работы, учебы, путешествий, личного развития и т.д.\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f''' На основании Отчета по потребностям отпредели основную потребность клиента. В ответе четко сформулируй только эту потребность в виде темы для статьи.\n",
        "\n",
        "         Отчет по потребностям: {resulting_string}'''}]\n",
        "\n",
        "    completion_prez = model.create_chat_completion(  # Вызываем метод для генерации ответа\n",
        "            max_tokens=max_tokens,  # Максимальное количество токенов в ответе\n",
        "            temperature=temp,  # Температура генерации (0 = детерминированный ответ)\n",
        "            messages=messages # Сообщения для модели\n",
        "        )\n",
        "\n",
        "\n",
        "    answer_prez = completion_prez['choices'][0]['message']['content']\n",
        "    #print(answer_prez)\n",
        "    return answer_prez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2t2uLel7gYH"
      },
      "source": [
        "Промт и инструкция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmCOkuZo7gYI"
      },
      "outputs": [],
      "source": [
        "system_prompt_router = '''\n",
        "Ты лучший специалист отдела продаж. Ты продаешь курсы обучения английскому языку.\n",
        "Ты знаешь, что Потребность - это то, что клиент хочет или что ему нравится,\n",
        "и что повлияет на приобретение им курсов обучения.\n",
        "Ты очень хорошо умеешь выявлять в Вопросе менеджера и ответе клиента потребности клиента.\n",
        "Ты всегда очень строго следуешь порядку отчета.\n",
        "'''\n",
        "instructions_router = '''\n",
        "Давай действовать последовательно:\n",
        "Проанализируй Вопрос менеджера и ответ клиента, выяви какие высказаны потребности клиента.\n",
        "Ничего не придумывай от себя.\n",
        "Порядок отчета: предоставь только название потребности с формулировкой клиента через двоеточие.'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель llama-3.1-8b"
      ],
      "metadata": {
        "id": "mLPzLldybFoW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkSwj0bqbFoX"
      },
      "source": [
        "Параметры запроса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvgtL6j9bFoX"
      },
      "outputs": [],
      "source": [
        "model_router = llm # Имя модели, используемой для генерации ответов\n",
        "\n",
        "temperature_router = 0 # Задаем температуру генерации ответа\n",
        "\n",
        "verbose_router = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "max_tokens=1000 # Количество токенов на ответ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1MZMlVsbFoX"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8489f968-24b2-4715-a01b-447c231296e6",
        "id": "fhZsuQArbFoX"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.94 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Уроки для детей: есть уроки для детей от 5 лет.\n"
          ]
        }
      ],
      "source": [
        "topic = \"Какие есть уроки для детей\"\n",
        "user_question_router_llama(model_router, system_prompt_router, instructions_router, topic, temperature_router, verbose_router, max_tokens);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "eG0hymxjbFoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Я хочу уехать за границу\"\n",
        "user_question_router_llama(model_router, system_prompt_router, instructions_router, topic, temperature_router, verbose_router, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ecd6d2c-65f7-47dc-acb1-4662b4f7f50d",
        "id": "bIz4SUIqbFoY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.49 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Я хочу уехать за границу.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "AxyTJBthbFoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Мне нужно выучить английский за год\"\n",
        "user_question_router_llama(model_router, system_prompt_router, instructions_router, topic, temperature_router, verbose_router, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db538e69-fa20-48ef-8704-b258d56cdaa9",
        "id": "Hp1IY-c2bFoZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.47 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Выучить английский за год.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "uq2ch_SFbFoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Я что-то хочу, но не знаю что\"\n",
        "user_question_router_llama(model_router, system_prompt_router, instructions_router, topic, temperature_router, verbose_router, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708b3a33-8a5e-43fc-df18-72cb55467fac",
        "id": "hAQiMIrpbFoZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.81 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Навык обучения английскому языку для улучшения общения.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "DE-mmH-nbFoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Не хочу платить деньги за обучение\"\n",
        "user_question_router_llama(model_router, system_prompt_router, instructions_router, topic, temperature_router, verbose_router, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168c9b59-07c2-4815-f731-e870bc666f87",
        "id": "LBq_i1FkbFoa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.37 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Нет денег на обучение.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель llama-3.1-70b"
      ],
      "metadata": {
        "id": "6xQhzO9ISOw2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq5Z1ADhSOw3"
      },
      "source": [
        "Параметры запроса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "405IKYOOSOw3"
      },
      "outputs": [],
      "source": [
        "model_router = llm # Имя модели, используемой для генерации ответов\n",
        "\n",
        "temperature_router = 0 # Задаем температуру генерации ответа\n",
        "\n",
        "verbose_router = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "max_tokens=1000 # Количество токенов на ответ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAdAVlp8SOw4"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f95da3-98b1-4398-ed9c-804eca689692",
        "id": "gURWEdiRSOw4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 4.50 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Уроки для детей: для детей.\n"
          ]
        }
      ],
      "source": [
        "topic = \"Какие есть уроки для детей\"\n",
        "user_question_router_llama(model_router, system_prompt_router, instructions_router, topic, temperature_router, verbose_router, max_tokens);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "eczpmiFCSOw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Я хочу уехать за границу\"\n",
        "user_question_router_llama(model_router, system_prompt_router, instructions_router, topic, temperature_router, verbose_router, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fd5c61-7809-4ef4-c5bc-cba8839b0fb8",
        "id": "OlnEAvHCSOw5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 11.42 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность: Уехать за границу: Я хочу уехать за границу.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "fL5jyo4ESOw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Мне нужно выучить английский за год\"\n",
        "user_question_router_llama(model_router, system_prompt_router, instructions_router, topic, temperature_router, verbose_router, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d5a0ee-ed24-444c-9554-de325e2037be",
        "id": "hqnJL_H_SOw6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 6.25 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Срочность: выучить английский за год.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "ndNo38ErSOw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Я что-то хочу, но не знаю что\"\n",
        "user_question_router_llama(model_router, system_prompt_router, instructions_router, topic, temperature_router, verbose_router, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbdb691a-3676-4a3b-ea07-27c1eb49ead4",
        "id": "BOWItPNmSOw6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 8.34 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Нежелание тратить время на поиск информации: \"Я что-то хочу, но не знаю что.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "4AKFPjjWSOw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Не хочу платить деньги за обучение\"\n",
        "user_question_router_llama(model_router, system_prompt_router, instructions_router, topic, temperature_router, verbose_router, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb4857a-ca5c-4d11-aba1-3aabae48180d",
        "id": "JLP-5C3eSOw7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 6.61 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Экономия средств: не хочу платить деньги за обучение.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель GPT-4o-mini"
      ],
      "metadata": {
        "id": "gzYUtDYXRWQO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX_Ogm2B7gYM"
      },
      "source": [
        "Параметры запроса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgSwNAPQ7gYM"
      },
      "outputs": [],
      "source": [
        "model_router = 'gpt-4o-mini' # Имя модели, используемой для генерации ответов\n",
        "\n",
        "temperature_router = 0 # Задаем температуру генерации ответа\n",
        "\n",
        "verbose_router = 1 # Флаг для включения/выключения вывода ответа модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1WowfyO7gYN"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c51ddc1-0163-423a-f796-1bcd3f16f7f7",
        "id": "ju_ApS8-7gYN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 1.59 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность: Уроки для детей: \"Какие есть уроки для детей?\"\n"
          ]
        }
      ],
      "source": [
        "topic = \"Какие есть уроки для детей\"\n",
        "user_question_router(system_prompt_router, instructions_router, topic, temperature_router, verbose_router, model_router);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "KPKQLuMPeJlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Я хочу уехать за границу\"\n",
        "user_question_router(system_prompt_router, instructions_router, topic, temperature_router, verbose_router, model_router);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77nLFzfeeRm4",
        "outputId": "c063d4cb-cae2-4270-f589-6bef28f29a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.54 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность: Желание эмигрировать: \"Я хочу уехать за границу.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "Nj18WbIkeKCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Мне нужно выучить английский за год\"\n",
        "user_question_router(system_prompt_router, instructions_router, topic, temperature_router, verbose_router, model_router);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKS1rBakeSLj",
        "outputId": "75275389-6243-4127-e0e9-3ecf9cbbf081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.65 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность: \"Мне нужно выучить английский за год.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "mxhQ1gnMeKhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Я что-то хочу, но не знаю что\"\n",
        "user_question_router(system_prompt_router, instructions_router, topic, temperature_router, verbose_router, model_router);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-V_khaJeSvE",
        "outputId": "54e20f6b-b892-4a6a-e163-024b3c03c063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.58 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Неопределенность в потребностях: \"Я что-то хочу, но не знаю что.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "RTAttVT2eLAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Не хочу платить деньги за обучение\"\n",
        "user_question_router(system_prompt_router, instructions_router, topic, temperature_router, verbose_router, model_router);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I502C63yeTPj",
        "outputId": "8ab8401f-1549-4ada-9fc5-03534f6cfd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.47 секунд\n",
            "\n",
            "==================\n",
            "Агент Отчета о потребностях:\n",
            " Потребность: Необходимость в бесплатном обучении.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRFpPVmu7gYQ"
      },
      "source": [
        "## Агент Потребностей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39EpPADE7gYQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Функция для генерации вопроса пользователю на основе истории чата и текущего вопроса\n",
        "# Функция для генерации отчета по истории чата\n",
        "def generate_summary_report(history_chat):\n",
        "    report = []\n",
        "    for i, message in enumerate(history_chat, start=1):\n",
        "        report.append(f\"{i}. {message}\")  # Нумеруем и добавляем каждое сообщение в отчет\n",
        "    return \"\\n\".join(report)  # Объединяем все сообщения в одну строку\n",
        "\n",
        "\n",
        "# Функция для генерации вопроса пользователю на основе истории чата и текущего вопроса\n",
        "def spez_user_question(system, instructions, needs, history_chat, temp=0, verbose=0, model=\"gpt-3.5-turbo-16k\"):\n",
        "    summary_history = generate_summary_report(history_chat)  # Генерация отчета по истории чата\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},  # Добавляем системное сообщение\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "\n",
        "         Список потребностей: {needs}\n",
        "\n",
        "         Хронология предыдущих сообщений диалога: {summary_history}'''}  # Добавляем инструкции и контекст\n",
        "    ]\n",
        "\n",
        "    # if verbose: print('\\n==================\\n')\n",
        "    # if verbose: print(f'Вопрос клиента:', question)\n",
        "    # if verbose: print('Саммари диалога:\\n==================\\n',\n",
        "    #                      summary_history)\n",
        "    # print(\"messages\", messages)\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    # Запрос к модели OpenAI для генерации ответа\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    # Извлекаем ответ из ответа модели\n",
        "    answer = completion.choices[0].message.content\n",
        "    try:\n",
        "        # Пытаемся разделить ответ по ': ' и взять вторую часть\n",
        "        answer = answer.split(': ')[1] + ' '\n",
        "    except:\n",
        "        # Если не удалось, используем оригинальный ответ\n",
        "        answer = answer\n",
        "    # Убираем возможные служебные символы в начале строки\n",
        "    answer = answer.lstrip('#3')\n",
        "\n",
        "    # if verbose: print(f'\\n==================')\n",
        "    # if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "    if verbose: print('\\n==================')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print(f'Вопрос от Агента Потребностей:\\n', f'{formatted_answer}')\n",
        "\n",
        "    return answer  # Возвращаем ответ\n",
        "\n",
        "\n",
        "def spez_user_question_llama(model, system, instructions, needs, history_chat, temp=0, verbose=0, max_tokens=1000):\n",
        "    summary_history = generate_summary_report(history_chat)  # Генерация отчета по истории чата\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},  # Добавляем системное сообщение\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "\n",
        "         Список потребностей: {needs}\n",
        "\n",
        "         Хронология предыдущих сообщений диалога: {summary_history}'''}  # Добавляем инструкции и контекст\n",
        "    ]\n",
        "\n",
        "    # if verbose: print('\\n==================\\n')\n",
        "    # if verbose: print(f'Вопрос клиента:', question)\n",
        "    # if verbose: print('Саммари диалога:\\n==================\\n',\n",
        "    #                      summary_history)\n",
        "    # print(\"messages\", messages)\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = model.create_chat_completion(  # Вызываем метод для генерации ответа\n",
        "            max_tokens=max_tokens,  # Максимальное количество токенов в ответе\n",
        "            temperature=temp,  # Температура генерации (0 = детерминированный ответ)\n",
        "            messages=messages # Сообщения для модели\n",
        "        )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "\n",
        "    # Извлекаем ответ из ответа модели\n",
        "    answer = completion['choices'][0]['message']['content']\n",
        "    #try:\n",
        "        # Пытаемся разделить ответ по ': ' и взять вторую часть\n",
        "        #answer = answer.split(': ')[1] + ' '\n",
        "    #except:\n",
        "        # Если не удалось, используем оригинальный ответ\n",
        "        #answer = answer\n",
        "    # Убираем возможные служебные символы в начале строки\n",
        "    #answer = answer.lstrip('#3')\n",
        "\n",
        "    # Удаляем переносы строк и лишние пробелы\n",
        "    #answer0 = answer.replace('\\n', ' ').strip()\n",
        "\n",
        "    # Извлечение текста после последнего символа :\n",
        "    #answer1 = answer0.rpartition(':')[-1].strip()\n",
        "\n",
        "    # Убираем кавычки в начале и конце, если они есть\n",
        "    #answer1 = answer1.strip('\"')\n",
        "\n",
        "    # Удаляем переносы строк и лишние пробелы\n",
        "    text1 = answer.replace('\\n', ' ').strip()\n",
        "\n",
        "    # Извлекаем последнее предложение\n",
        "    last_sentence1 = re.findall(r'([^.!?]*[.!?])', text1)[-1].strip()\n",
        "\n",
        "    # Проверяем наличие двоеточия\n",
        "    if ':' in last_sentence1:\n",
        "        # Берём только часть после двоеточия и удаляем кавычки\n",
        "        answer1 = last_sentence1.split(':', 1)[-1].strip().strip('\"')\n",
        "    else:\n",
        "        # Если двоеточия нет, удаляем кавычки из всего предложения\n",
        "        answer1 = last_sentence1.strip('\"')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "\n",
        "    # if verbose: print(f'\\n==================')\n",
        "    # if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    if verbose: print('\\n==================')\n",
        "    formatted_answer = textwrap.fill(answer1, width=120)\n",
        "    if verbose: print(f'Вопрос от Агента Потребностей:\\n', f'{formatted_answer}')\n",
        "\n",
        "    return answer1  # Возвращаем ответ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9nOSdmT7gYS"
      },
      "source": [
        "Промт и инструкция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJmW5spX7gYS"
      },
      "outputs": [],
      "source": [
        "# Системное сообщение для модели, задающее её поведение и контекст работы\n",
        "system_prompt_potr = '''\n",
        "Вы лучший менеджер по продажам. Вы работаете в компании,\n",
        "которая продает курсы обучения английскому языку.\n",
        "Вы очень хорошо знаете, какие курсы и программы обучения предоставляет компания.\n",
        "Вы понимаете какие потребности клиента надо выявить, чтобы полностью понять желания и боли клиента,\n",
        "которые можно удовлетворить при помощи обучения английскому языку.\n",
        "Вы знаете, что важно выявить есть ли у клиента такие потребности: в повышении уровня знаний, для работы, для собеседований, для переезда,\n",
        "для учебы, для подготовки к ЕГЭ, для детей, для путешествий, личного развития и т.д.\n",
        "Вы понимаете, что нужно аккуратно и ненавязчиво выявить несколько разных потребностей и составляете свой ответ с этой целью.\n",
        "Ваша задача: сформулировать вопрос клиенту, который поможет качественно выявить его потребности.\n",
        "Вы всегда очень строго следуете порядку отчета.\n",
        "'''\n",
        "\n",
        "# Инструкции для модели, описывающие шаги, которые она должна выполнить\n",
        "instructions__potr = '''\n",
        "Давайте действовать по шагам:\n",
        "#Шаг1: Проанализируйте диалог и Список потребностей;\n",
        "#Шаг2: Предположите одну другую потребность, которой нет среди выявленных потребностей в Шаг1;\n",
        "#Шаг3: Учитывая, что выявление потребностей должно провоцировать дальнейший диалог и заинтересовывать клиента,\n",
        "для этой потребности из Шаг2 напишите один вопрос для качественного выявления этой потребности. Ничего, кроме вопроса не пишите и не объясняйте.\n",
        "Порядок отчета: В свой ответ включите только один вопрос из Шаг3, ничего кроме вопроса выводить не нужно.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель llama-3.1-8b"
      ],
      "metadata": {
        "id": "Tjqu55JabNOo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3XeUAr9bNOp"
      },
      "source": [
        "Параметры запроса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxZbTZMwbNOp"
      },
      "outputs": [],
      "source": [
        "temp = 0.1  # Температура генерации ответов модели, влияет на креативность и разнообразие ответов\n",
        "\n",
        "verbose = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "model_potr = llm # Имя модели, используемой для генерации ответов\n",
        "\n",
        "max_tokens=1000 # Количество токенов на ответ\n",
        "\n",
        "needs = [\"\"] # Отчет о потребностях"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTg7DaYKbNOq"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68743d8-9733-4702-a779-b8d049a987a2",
        "id": "r8XjDHbEbNOq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 8.89 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Вы планируете использовать английский язык в конкретной профессии или сфере деятельности?\n"
          ]
        }
      ],
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Здравствуйте, я нейро-консультант компании по изучению английского языка. Чем я могу Вам помочь?\",\n",
        "    \"Клиент: Мне нужно изучить английский язык для работы.\"\n",
        "]\n",
        "spez_user_question_llama(model_potr, system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, max_tokens);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "K93R8YyobNOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Здравствуйте, я нейро-консультант компании по изучению английского языка. Чем я могу Вам помочь?\",\n",
        "    \"Клиент: Я хочу подтянуть свой уровень английского для путешествий.\"\n",
        "]\n",
        "spez_user_question_llama(model_potr, system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4701fdb9-898b-41c3-9d43-a676c5c8bb65",
        "id": "Xa_7cTxIbNOr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 9.03 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Вы планируете использовать английский язык в своей профессиональной деятельности в ближайшем будущем?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "QioKH60LbNOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Добрый день! Чем я могу помочь Вам в изучении английского языка?\",\n",
        "    \"Клиент: Мне нужно подготовиться к ЕГЭ по английскому.\"\n",
        "]\n",
        "spez_user_question_llama(model_potr, system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb21448-740f-4e98-8384-430bfeae8b1a",
        "id": "72a37vhxbNOr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 7.80 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Как вы видите свою будущую роль в международном сообществе, и как вы думаете, может помочь вам английский язык?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "a07H5i0hbNOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Здравствуйте! Какой цели Вы хотите достичь, изучая английский язык?\",\n",
        "    \"Клиент: Хочу изучить английский для работы в международной компании.\"\n",
        "]\n",
        "spez_user_question_llama(model_potr, system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60661324-13af-4c59-90a2-a78ac5152e74",
        "id": "PsZrmXOGbNOs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 7.67 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Вы когда-нибудь думали о путешествии в страну, где английский язык является официальным или широко распространенным?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "Tz8cxsQFbNOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Добрый день! Расскажите, для каких целей Вы планируете изучать английский язык?\",\n",
        "    \"Клиент: Мне нужен английский для переезда в другую страну.\"\n",
        "]\n",
        "spez_user_question_llama(model_potr, system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67123832-377f-46c1-ad61-0c66aa19b383",
        "id": "v3u8cW0ubNOt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 1.46 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Для переезда в другую страну, Вы планируете занимать какую-либо конкретную профессию или работать на себя?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель llama-3.1-70b"
      ],
      "metadata": {
        "id": "3KciSClcXVxh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kezKZyf9XVxi"
      },
      "source": [
        "Параметры запроса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE9CrZxiXVxi"
      },
      "outputs": [],
      "source": [
        "temp = 0.1  # Температура генерации ответов модели, влияет на креативность и разнообразие ответов\n",
        "\n",
        "verbose = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "model_potr = llm # Имя модели, используемой для генерации ответов\n",
        "\n",
        "max_tokens=1000 # Количество токенов на ответ\n",
        "\n",
        "needs = [\"\"] # Отчет о потребностях"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKEGb3GOXVxi"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e924c57-f613-4895-dbf0-00c841e7acbd",
        "id": "cWzkjZ1HXVxi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 12.16 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Вас интересует возможность применения английского языка в конкретной отрасли или профессии, или же Вам важен общий\n",
            "деловой английский?\n"
          ]
        }
      ],
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Здравствуйте, я нейро-консультант компании по изучению английского языка. Чем я могу Вам помочь?\",\n",
        "    \"Клиент: Мне нужно изучить английский язык для работы.\"\n",
        "]\n",
        "spez_user_question_llama(model_potr, system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, max_tokens);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "10i-Gq0eXVxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Здравствуйте, я нейро-консультант компании по изучению английского языка. Чем я могу Вам помочь?\",\n",
        "    \"Клиент: Я хочу подтянуть свой уровень английского для путешествий.\"\n",
        "]\n",
        "spez_user_question_llama(model_potr, system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ed2f96-1753-4e30-a16b-3b1a9606c9f5",
        "id": "VRUjGeYzXVxj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 9.67 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Вы планируете часто путешествовать за границу или это скорее разовая поездка?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "MB7N8kjYXVxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Добрый день! Чем я могу помочь Вам в изучении английского языка?\",\n",
        "    \"Клиент: Мне нужно подготовиться к ЕГЭ по английскому.\"\n",
        "]\n",
        "spez_user_question_llama(model_potr, system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c106c738-241b-4ae6-98c6-5abfb044781f",
        "id": "9HXROMJvXVxk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 6.78 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Вам нужно улучшить только устный или письменный английский, или оба?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "9CfIs4ZEXVxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Здравствуйте! Какой цели Вы хотите достичь, изучая английский язык?\",\n",
        "    \"Клиент: Хочу изучить английский для работы в международной компании.\"\n",
        "]\n",
        "spez_user_question_llama(model_potr, system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4f35bf-66e3-4c2a-ae14-079e845649c3",
        "id": "bODMF-prXVxk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 13.42 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Планируете ли Вы в ближайшее время участвовать в международных бизнес-встречах или переговорах, где свободное владение\n",
            "английским языком будет иметь решающее значение?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "d0IOeNB0XVxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Добрый день! Расскажите, для каких целей Вы планируете изучать английский язык?\",\n",
        "    \"Клиент: Мне нужен английский для переезда в другую страну.\"\n",
        "]\n",
        "spez_user_question_llama(model_potr, system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9d94e8-294a-40f8-cf65-4eb2390dad56",
        "id": "WhknFP43XVxl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 14.14 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Планируете ли Вы работать в стране, куда собираетесь переехать, и если да, то насколько важен для Вас английский язык\n",
            "для карьерного роста?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель GPT-4o-mini"
      ],
      "metadata": {
        "id": "x0kRQto9VI8H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TocP2_YQ7gYX"
      },
      "source": [
        "Параметры запроса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xziDudye7gYX"
      },
      "outputs": [],
      "source": [
        "temp = 0.1  # Температура генерации ответов модели, влияет на креативность и разнообразие ответов\n",
        "\n",
        "verbose = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "model_potr = 'gpt-4o-mini' # Имя модели, используемой для генерации ответов\n",
        "\n",
        "needs = [\"\"] # Отчет о потребностях"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTY0FWNs7gYY"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7ec275-ca80-49cd-f441-1c50000cabb9",
        "id": "nVdfj8pf7gYZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.50 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Как вы планируете использовать английский язык в своей работе?\n"
          ]
        }
      ],
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Здравствуйте, я нейро-консультант компании по изучению английского языка. Чем я могу Вам помочь?\",\n",
        "    \"Клиент: Мне нужно изучить английский язык для работы.\"\n",
        "]\n",
        "spez_user_question(system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, model_potr);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "SZoRshzAfkNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Здравствуйте, я нейро-консультант компании по изучению английского языка. Чем я могу Вам помочь?\",\n",
        "    \"Клиент: Я хочу подтянуть свой уровень английского для путешествий.\"\n",
        "]\n",
        "spez_user_question(system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, model_potr);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzfy-Op0gohB",
        "outputId": "1244d304-099b-49a2-f9f6-abba97534834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.60 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Как часто вы планируете путешествовать, и какие страны вас интересуют для изучения английского в контексте общения с\n",
            "местными жителями?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "JDEcUYRifk1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Добрый день! Чем я могу помочь Вам в изучении английского языка?\",\n",
        "    \"Клиент: Мне нужно подготовиться к ЕГЭ по английскому.\"\n",
        "]\n",
        "spez_user_question(system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, model_potr);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szqrWc7SgpQ4",
        "outputId": "98d746a4-f8bc-4a1e-ac85-ab6bee15a189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.49 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Как вы планируете использовать свои знания английского языка после успешной сдачи ЕГЭ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "ddboWqRYflNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Здравствуйте! Какой цели Вы хотите достичь, изучая английский язык?\",\n",
        "    \"Клиент: Хочу изучить английский для работы в международной компании.\"\n",
        "]\n",
        "spez_user_question(system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, model_potr);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_svC1t9gp13",
        "outputId": "a6cba759-d31f-4885-d205-bc96eb566e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.67 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Какой именно аспект работы в международной компании требует от вас знания английского языка?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "AJjiJjb7fmBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\n",
        "    \"Менеджер: Добрый день! Расскажите, для каких целей Вы планируете изучать английский язык?\",\n",
        "    \"Клиент: Мне нужен английский для переезда в другую страну.\"\n",
        "]\n",
        "spez_user_question(system_prompt_potr, instructions__potr, needs, history_chat, temp, verbose, model_potr);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la1cINQCgqUY",
        "outputId": "fca2233a-5d9e-4c28-c2c9-2fbc65ecb046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.60 секунд\n",
            "\n",
            "==================\n",
            "Вопрос от Агента Потребностей:\n",
            " Какой именно аспект жизни за границей вас больше всего беспокоит, и как знание английского языка может помочь вам в\n",
            "этом?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khFcFbjD7gYc"
      },
      "source": [
        "## Агент Выявления вопросов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABpnUYNa7gYd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Функция для выявления вопросов\n",
        "def user_question(system, instructions, topic, temp=0, verbose=0, model='gpt-3.5-turbo-1106'):\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "                                      \\n\\nСообщение клиента:\\n{topic}\n",
        "                                      \\n\\nОтвет: '''}\n",
        "    ]\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    answer = completion.choices[0].message.content\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Ответ Агента по выявлению вопросов:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "    #print(f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    return answer\n",
        "\n",
        "\n",
        "def user_question_llama(model, system, instructions, topic, temp=0, verbose=0, max_tokens=1000):\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "                                      \\n\\nСообщение клиента:\\n{topic}\n",
        "                                      \\n\\nОтвет: '''}\n",
        "    ]\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = model.create_chat_completion(  # Вызываем метод для генерации ответа\n",
        "            max_tokens=max_tokens,  # Максимальное количество токенов в ответе\n",
        "            temperature=temp,  # Температура генерации (0 = детерминированный ответ)\n",
        "            messages=messages # Сообщения для модели\n",
        "        )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "\n",
        "    # Извлекаем ответ из ответа модели\n",
        "    answer = completion['choices'][0]['message']['content']\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Ответ Агента по выявлению вопросов:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "    #print(f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvRCiT697gYd"
      },
      "source": [
        "Промт и инструкция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnRO-Xyr7gYd"
      },
      "outputs": [],
      "source": [
        "system_prompt_question ='''\n",
        "Ты идеально справляешься со своей задачей: ты отлично определяешь вопрос клиента.\n",
        "Проверь есть ли в сообщении клиента какой-нибудь вопрос.\n",
        "Если вопрос есть, то напиши сообщение клиента без изменений.\n",
        "Если вопроса нет, а есть общие рассуждения, то сформулируй на основании сообщения клиента вопрос.\n",
        "\n",
        "Ты всегда очень строго следуешь требованиям к порядку отчета.'''\n",
        "instructions_question = '''\n",
        "Пожалуйста, будем действовать по шагам:\n",
        "#Шаг1: проанализируйте Сообщение клиента чтобы быть в контексте;\n",
        "#Шаг2: опираясь на анализ Шаг1 сформулируй Вопрос клиента.\n",
        "Отвечай, пожалуйста, точно, и ничего не придумывай от себя.\n",
        "Порядок отчета: напиши только вопрос клиента.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель llama-3.1-8b"
      ],
      "metadata": {
        "id": "eqyQldA7bXAL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNQDI235bXAM"
      },
      "source": [
        "Параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cirjjaubXAM"
      },
      "outputs": [],
      "source": [
        "model_question = llm # Имя модели, используемой для генерации ответов\n",
        "\n",
        "temperature_question = 0 # Задаем температуру генерации ответа\n",
        "\n",
        "verbose_question = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "max_tokens=1000 # Количество токенов на ответ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8S0VbBEbXAM"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9679a3-9f24-4cad-9a93-5d7bad8bf0c6",
        "id": "yOQxiSyjbXAN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 1.00 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Когда вы готовитесь к работе, нужен ли вам английский язык?\n"
          ]
        }
      ],
      "source": [
        "topic = \"мне нужен английский язык для работы\"\n",
        "user_question_llama(model_question, system_prompt_question, instructions_question, topic, temperature_question, verbose_question, max_tokens);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "gERxphLzbXAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Какой именно язык можно изучить\"\n",
        "user_question_llama(model_question, system_prompt_question, instructions_question, topic, temperature_question, verbose_question, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2285c9-841a-4808-c62b-b91e140a7d58",
        "id": "oHg16UcibXAN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.48 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какой именно язык можно изучить?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "KZUgWTFzbXAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Хочу уехать за границу летом\"\n",
        "user_question_llama(model_question, system_prompt_question, instructions_question, topic, temperature_question, verbose_question, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a78e8d-136a-46ab-a6ae-1169befced16",
        "id": "_rAiWix9bXAO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.71 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Хотите ли вы уехать за границу летом?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "wB1DXPGDbXAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Обучение проходит онлайн\"\n",
        "user_question_llama(model_question, system_prompt_question, instructions_question, topic, temperature_question, verbose_question, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef980bd-997d-4927-94ab-3741c71b162a",
        "id": "p0ok04CgbXAP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.52 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Обучение проходит онлайн.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "8zDHkA5ubXAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Какова длительность одного занятия?\"\n",
        "user_question_llama(model_question, system_prompt_question, instructions_question, topic, temperature_question, verbose_question, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262ce3ef-7e51-4fff-ce65-d6b54075e9ad",
        "id": "nRrxafFIbXAQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.44 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какова длительность одного занятия?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель llama-3.1-70b"
      ],
      "metadata": {
        "id": "zzrlYl0WbIND"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJM40p0IbIND"
      },
      "source": [
        "Параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bVXICwjbIND"
      },
      "outputs": [],
      "source": [
        "model_question = llm # Имя модели, используемой для генерации ответов\n",
        "\n",
        "temperature_question = 0 # Задаем температуру генерации ответа\n",
        "\n",
        "verbose_question = 1 # Флаг для включения/выключения вывода ответа модели\n",
        "\n",
        "max_tokens=1000 # Количество токенов на ответ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1j0fZcLbINE"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e5f56e-b696-4705-e383-c1c57c1a6ad0",
        "id": "0dHwkXb5bINE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 5.36 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какой уровень английского языка необходим для работы?\n"
          ]
        }
      ],
      "source": [
        "topic = \"мне нужен английский язык для работы\"\n",
        "user_question_llama(model_question, system_prompt_question, instructions_question, topic, temperature_question, verbose_question, max_tokens);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "V6aeYKIabINE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Какой именно язык можно изучить\"\n",
        "user_question_llama(model_question, system_prompt_question, instructions_question, topic, temperature_question, verbose_question, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f3876d-e577-4816-e06e-e42ccd68b204",
        "id": "5DJjlhuGbINF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 4.67 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какой именно язык можно изучить?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "MlUniux9bINF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Хочу уехать за границу летом\"\n",
        "user_question_llama(model_question, system_prompt_question, instructions_question, topic, temperature_question, verbose_question, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286162b9-e7d1-4ee4-ccf0-997470c1065b",
        "id": "ZNXcbFA9bINF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 7.56 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какие страны можно посетить летом?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "libcG8zIbING"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Обучение проходит онлайн\"\n",
        "user_question_llama(model_question, system_prompt_question, instructions_question, topic, temperature_question, verbose_question, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1192cc4c-37aa-49d9-9c15-aec4f2e3ab3b",
        "id": "b0R9ni9abING"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 6.72 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какие преимущества онлайн-обучения?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "xLUPa-gibING"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Какова длительность одного занятия?\"\n",
        "user_question_llama(model_question, system_prompt_question, instructions_question, topic, temperature_question, verbose_question, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0454046d-b1e0-4376-929c-22bb2b8be1c6",
        "id": "a7SgJO1JbING"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 4.33 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какова длительность одного занятия?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель GPT-4o-mini"
      ],
      "metadata": {
        "id": "sva8njDmagMo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2g_Rrs07gYh"
      },
      "source": [
        "Параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_xIrZXm7gYi"
      },
      "outputs": [],
      "source": [
        "model_question = 'gpt-4o-mini' # Имя модели, используемой для генерации ответов\n",
        "\n",
        "temperature_question = 0 # Задаем температуру генерации ответа\n",
        "\n",
        "verbose_question = 1 # Флаг для включения/выключения вывода ответа модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6ic8tSH7gYi"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60beed6d-f3f2-4aa8-ef90-6b9762ae378e",
        "id": "OD1d9ZF37gYi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.53 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Как мне улучшить свои знания английского языка для работы?\n"
          ]
        }
      ],
      "source": [
        "topic = \"мне нужен английский язык для работы\"\n",
        "user_question(system_prompt_question, instructions_question, topic, temperature_question, verbose_question, model_question);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "B9vNogUKlO7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Какой именно язык можно изучить\"\n",
        "user_question(system_prompt_question, instructions_question, topic, temperature_question, verbose_question, model_question);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32r1cBmFluCf",
        "outputId": "e02ea651-9731-425b-fc43-7bf635a735e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.39 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какой именно язык можно изучить?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "ih_kRnrnlPSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Хочу уехать за границу летом\"\n",
        "user_question(system_prompt_question, instructions_question, topic, temperature_question, verbose_question, model_question);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUo1e_Rsluok",
        "outputId": "de547604-64af-4a0c-f9c3-654b25e71467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.49 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какую страну вы планируете посетить за границей летом?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "Y1sHFXSplPqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Обучение проходит онлайн\"\n",
        "user_question(system_prompt_question, instructions_question, topic, temperature_question, verbose_question, model_question);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LZqcm0dlvZq",
        "outputId": "0762c379-5cb7-4ca9-a500-30c54ec70922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.37 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Как проходит обучение?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "2V-pXYVFlQeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Какова длительность одного занятия?\"\n",
        "user_question(system_prompt_question, instructions_question, topic, temperature_question, verbose_question, model_question);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJgW_gd9lv1u",
        "outputId": "ff539595-e5c6-4fed-de1f-fffdb296d03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 0.47 секунд\n",
            "\n",
            "==================\n",
            "Ответ Агента по выявлению вопросов:\n",
            " Какова длительность одного занятия?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjnOwqHO7gYl"
      },
      "source": [
        "## Агент Презентации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foU-oSYl7gYl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Функция для презентации продукта\n",
        "\n",
        "def prez_user_question(system, instructions, potr_history, search_index, temp=0, verbose=0, k=3, model= \"gpt-4o\"):\n",
        "\n",
        "    knowledge_base = search_index.similarity_search(potr_history, k=k)\n",
        "    docs_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\n==================\\n' + doc.page_content + '\\n' for doc in knowledge_base]))\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "\n",
        "         Отчет по потребностям: {potr_history}\n",
        "\n",
        "         База Знаний: {docs_content}'''}\n",
        "    ]\n",
        "    #if verbose: print('\\n==================\\n')\n",
        "    #if verbose: print('Потребности:\\n==================\\n',\n",
        "                         #potr_history)\n",
        "    #if verbose: print(f'База знаний:\\n==================\\n', docs_content)\n",
        "    start_time = time.time()\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "    answer = completion.choices[0].message.content\n",
        "    #try:\n",
        "      #answer = answer.split(': ')[1]+ ' '\n",
        "    #except:\n",
        "      #answer = answer\n",
        "    #answer = answer.lstrip('#3')\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Менеджер:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "    return answer\n",
        "\n",
        "def prez_user_question_llama(model, system, instructions, potr_history, search_index, temp=0, verbose=0, k=3, max_tokens=1000):\n",
        "\n",
        "    knowledge_base = search_index.similarity_search(potr_history, k=k)\n",
        "    docs_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\n==================\\n' + doc.page_content + '\\n' for doc in knowledge_base]))\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "\n",
        "         Отчет по потребностям: {potr_history}\n",
        "\n",
        "         База Знаний: {docs_content}'''}\n",
        "    ]\n",
        "    #if verbose: print('\\n==================\\n')\n",
        "    #if verbose: print('Потребности:\\n==================\\n',\n",
        "                         #potr_history)\n",
        "    #if verbose: print(f'База знаний:\\n==================\\n', docs_content)\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = model.create_chat_completion(  # Вызываем метод для генерации ответа\n",
        "            max_tokens=max_tokens,  # Максимальное количество токенов в ответе\n",
        "            temperature=temp,  # Температура генерации (0 = детерминированный ответ)\n",
        "            messages=messages # Сообщения для модели\n",
        "        )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "\n",
        "    # Извлекаем ответ из ответа модели\n",
        "    answer = completion['choices'][0]['message']['content']\n",
        "    #try:\n",
        "      #answer = answer.split(': ')[1]+ ' '\n",
        "    #except:\n",
        "      #answer = answer\n",
        "    #answer = answer.lstrip('#3')\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print(f\"Время ответа: {elapsed_time2:.2f} секунд\")\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Менеджер:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "    return answer\n",
        "\n",
        "# Функция для презентации продукта с учетом теста\n",
        "\n",
        "def prez_user_question_test(system, instructions, potr_history, search_index, otv_prov, temp=0, verbose=0, k=3, model= \"gpt-4o\"):\n",
        "\n",
        "    knowledge_base = search_index.similarity_search(potr_history, k=k)\n",
        "    docs_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\n==================\\n' + doc.page_content + '\\n' for doc in knowledge_base]))\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "\n",
        "         Отчет по потребностям: {potr_history}\n",
        "\n",
        "         Оценка уровня знаний клиента: {otv_prov}\n",
        "\n",
        "         База Знаний компании: {docs_content}'''}\n",
        "    ]\n",
        "    #if verbose: print('\\n==================\\n')\n",
        "    #if verbose: print('Потребности:\\n==================\\n',\n",
        "                         #potr_history)\n",
        "    #if verbose: print(f'База знаний:\\n==================\\n', docs_content)\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "    answer = completion.choices[0].message.content\n",
        "    #try:\n",
        "      #answer = answer.split(': ')[1]+ ' '\n",
        "    #except:\n",
        "      #answer = answer\n",
        "    #answer = answer.lstrip('#3')\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'Менеджер:\\n',\n",
        "                      f'{formatted_answer}')\n",
        "    return answer\n",
        "\n",
        "system_prompt_prez_test = '''Вы - лучший специалист по презентации продукта и компании,\n",
        "занимающейся продажей курсов по английскому языку. Ваш стиль общения деловой и очень краткий.\n",
        "Ваша цель: сделать краткую убедительную и качественную презентацию по потребностям клиента (запрос может быть о курсах/программах обучения, стоимости).\n",
        "Ваши презентации всегда основаны на потребностях, желаниях клиента и оценке уровня знаний клиента.\n",
        "Не упоминай явно потребности клиента.\n",
        "При ответе используй Базу знаний компании.\n",
        "Вы никогда не используете шаблонный скриптовый вариант презентации, всегда делаете её в неформальной форме.\n",
        "'''\n",
        "\n",
        "instructions_prez_test = '''\n",
        "Сделайте максимально краткую убедительную и качественную презентацию, учитывая Отчет по потребностям и Оценку уровня знаний клиента. В завершении предложи оставить предзаказ на сайте.\n",
        "'''\n",
        "# Задаем температуру генерации ответа\n",
        "# Температура 0 означает, что модель будет давать более детерминированные ответы, строго опираясь на предоставленный контекст\n",
        "temperature_prez_test = 0\n",
        "\n",
        "# Задаем количество релевантных чанков (фрагментов текста) для формирования ответа\n",
        "relevant_chanks_test = 3\n",
        "\n",
        "# Флаг для включения/выключения вывода релевантных чанков\n",
        "verbose_prez_test = 0\n",
        "\n",
        "# Имя модели, используемой для генерации ответов\n",
        "model_prez_test = \"gpt-4o\"\n",
        "\n",
        "def prez_user_question_d_llama(model, system, instructions, potr_history, search_index, temp=0, verbose=0, k=3, max_tokens=1000):\n",
        "\n",
        "    knowledge_base = search_index.similarity_search(potr_history, k=k)\n",
        "    docs_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\n==================\\n' + doc.page_content + '\\n' for doc in knowledge_base]))\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "\n",
        "         Отчет по потребностям: {potr_history}\n",
        "\n",
        "         База Знаний: {docs_content}'''}\n",
        "    ]\n",
        "    #if verbose: print('\\n==================\\n')\n",
        "    #if verbose: print('Потребности:\\n==================\\n',\n",
        "                         #potr_history)\n",
        "    #if verbose: print(f'База знаний:\\n==================\\n', docs_content)\n",
        "\n",
        "    start_time = time.time()  # Начало отсчета времени\n",
        "\n",
        "    completion = model.create_chat_completion(  # Вызываем метод для генерации ответа\n",
        "            max_tokens=max_tokens,  # Максимальное количество токенов в ответе\n",
        "            temperature=temp,  # Температура генерации (0 = детерминированный ответ)\n",
        "            messages=messages # Сообщения для модели\n",
        "        )\n",
        "\n",
        "    end_time = time.time()  # Конец отсчета времени\n",
        "    elapsed_time2 = end_time - start_time  # Подсчет затраченного времени\n",
        "\n",
        "\n",
        "    # Извлекаем ответ из ответа модели\n",
        "    answer = completion['choices'][0]['message']['content']\n",
        "    #try:\n",
        "      #answer = answer.split(': ')[1]+ ' '\n",
        "    #except:\n",
        "      #answer = answer\n",
        "    #answer = answer.lstrip('#3')\n",
        "    #if verbose: print(f'\\n==================')\n",
        "    #if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    formatted_answer = textwrap.fill(answer, width=120)\n",
        "    print('\\n==================')\n",
        "    print(f'Менеджер:\\n',\n",
        "                      f'{answer}')\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HThOp_sV7gYm"
      },
      "source": [
        "Промт и инструкция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzcCb4Cc7gYm"
      },
      "outputs": [],
      "source": [
        "system_prompt_prez = '''Вы - лучший специалист по презентации продукта и компании,\n",
        "занимающейся продажей курсов по английскому языку. Ваш стиль общения деловой и очень краткий.\n",
        "Ваша цель: сделать краткую убедительную и качественную презентацию по потребностям клиента (запрос может быть о курсах/программах обучения, стоимости).\n",
        "Ваши презентации всегда основаны на потребностях и желаниях клиента.\n",
        "Не упоминай явно потребности клиента.\n",
        "Вы никогда не используете шаблонный скриптовый вариант презентации, всегда делаете её в неформальной форме.\n",
        "'''\n",
        "\n",
        "instructions_prez = '''\n",
        "Сделайте максимально краткую убедительную и качественную презентацию, учитывая Отчет по потребностям. В завершении предложи оставить предзаказ на сайте.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель llama-3.1-8b"
      ],
      "metadata": {
        "id": "kkqzL1y0blwD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn4WJNBdblwE"
      },
      "source": [
        "Параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUc9lIfKblwE"
      },
      "outputs": [],
      "source": [
        "# Задаем температуру генерации ответа\n",
        "# Температура 0 означает, что модель будет давать более детерминированные ответы, строго опираясь на предоставленный контекст\n",
        "temperature_prez = 0\n",
        "\n",
        "# Задаем количество релевантных чанков (фрагментов текста) для формирования ответа\n",
        "relevant_chanks = 3\n",
        "\n",
        "# Флаг для включения/выключения вывода релевантных чанков\n",
        "verbose_prez = 1\n",
        "\n",
        "# Имя модели, используемой для генерации ответов\n",
        "model_prez = llm\n",
        "\n",
        "max_tokens=1000 # Количество токенов на ответ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jImdhBRXblwE"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee85cbc9-7cb0-4950-d221-7893ac86b537",
        "id": "uc10Q8dvblwF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 12.46 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Здравствуйте!   Я знаю, что вы готовитесь к путешествию и хотите улучшить свои навыки английского языка.   Наша\n",
            "программа \"Take your first steps in the USA\" - идеальный выбор для вас! В ней вы узнаете, как ориентироваться в\n",
            "аэропорту, общаться с персоналом, справляться с таможенным досмотром и многое другое.  Курс состоит из 5 уроков, каждый\n",
            "из которых поможет вам чувствовать себя комфортно в США. Вы узнаете, как снять квартиру или дом, как пользоваться\n",
            "психологическими тестами, как описывать вещи и товары и многое другое.  Начните с первого урока бесплатно и проверьте\n",
            "свой уровень языка. Если вы хотите продолжить обучение, мы предлагаем бонусы при оплате нескольких занятий.  Наша\n",
            "программа поможет вам чувствовать себя уверенно в США и наслаждаться путешествием.   Оставьте предзаказ на сайте и\n",
            "начните свой путь к совершенству! [Ссылка на сайт]\n"
          ]
        }
      ],
      "source": [
        "# Список выявленных потребностей\n",
        "needs = \"Цель:путешествие\"\n",
        "prez_user_question_llama(model_prez, system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, max_tokens);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "Kg7v7jRNblwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: жить за границей\"\n",
        "prez_user_question_llama(model_prez, system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c35efe-ac3a-43fd-94ff-b0b38a4d39dd",
        "id": "8GZxXB9jblwF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 15.97 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Здравствуйте! Я рада представить вам нашу программу обучения английскому языку, которая поможет вам достичь своих целей\n",
            "и реализовать мечты.  Вы хотите жить за границей, и мы понимаем, что это требует не только языковых навыков, но и знаний\n",
            "о культуре, обычалях и жизни в другой стране. Наш курс \"Английский для эмиграции\" поможет вам подготовиться к переезду,\n",
            "ответив на все ваши вопросы и предоставив вам реальный опыт эмиграции наших учителей.  Кроме того, мы предлагаем\n",
            "бесплатный курс \"Самоучитель от Skyeng\", который поможет вам улучшить свои языковые навыки в удобном для вас формате и в\n",
            "любое время.  Наша программа обучения включает в себя:  * Созванивания с преподавателем на нашей платформе * Общение на\n",
            "английском и выполнение упражнений * Домашку и следование за своим прогрессом  Мы также предлагаем бонусы при покупке\n",
            "нескольких занятий и различные форматы обучения, включая ситуации, аудиокниги, видеопрактику и словарь.  Уже 103 000\n",
            "учеников прокачивают английский с нашего сайта, и мы уверены, что вы тоже сможете достичь своих целей.  Оставьте\n",
            "предзаказ на нашем сайте и получите доступ к нашим курсам и бонусам!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "nodgSXzwblwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: работа в международной компании\"\n",
        "prez_user_question_llama(model_prez, system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b49fa7a-669d-43eb-9191-2a4cb684a935",
        "id": "44w7YFZEblwG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 17.26 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Здравствуйте!   Я знаю, что вы стремитесь к карьере в международной компании, и для этого вам нужно улучшить свои навыки\n",
            "английского языка.   Наша программа курсов делового английского включает в себя 31 онлайн-урок и 5 тематических модулей,\n",
            "которые помогут вам развить языковые навыки делового общения, такие как составление резюме, ведение переписки и участие\n",
            "в переговорах.   Курс делового английского будет полезен профессионалам, желающим получить работу в международной\n",
            "компании.   Вы можете выбрать цель, которая вам подходит и будет вдохновлять на изучение английского. А если\n",
            "сформулировать ее пока не получается, запишитесь на бесплатный вводный урок. Наш методист поможет найти подходящую цель\n",
            "и настроить курс под уровень языка так, чтобы достичь ее самым эффективным путем.   Наша программа курсов делового\n",
            "английского включает в себя:  * 31 онлайн-урок * 5 тематических модулей * Разработку навыков делового общения *\n",
            "Улучшение навыков составления резюме, ведения переписки и участия в переговорах  Вы можете выбрать цель, которая вам\n",
            "подходит и будет вдохновлять на изучение английского.   Если вы хотите улучшить свои навыки английского языка и достичь\n",
            "своих целей, запишитесь на наш курс делового английского прямо сейчас.   [Предложить оставить предзаказ на сайте]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "zYEO8nBGblwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: Лучше всех знать английский язык\"\n",
        "prez_user_question_llama(model_prez, system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7387e80-31aa-4de7-9494-e2751dbeeb22",
        "id": "HZHMHXi5blwH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 14.82 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Здравствуйте!   Я рад представить вам нашу систему обучения английскому языку, которая поможет вам достичь своих целей и\n",
            "улучшить навыки общения.  Наша система включает в себя:  *   Ситуации, аудиокниги, видеопрактику и словарь для изучения\n",
            "языка в удобном формате. *   Тренировку произношения с голосовым вводом ответов и анализом произношения. *   Возможность\n",
            "изучать английский в браузере или через мобильное приложение. *   Открытый бесплатный курс для глухих и слабослышащих от\n",
            "Skyeng и Центра внимания.  Наша система подойдет тем, кто хочет:  *   Проводить встречи с иностранными партнерами и\n",
            "общаться с людьми по всему миру. *   Получить повышение на работе, поступить в университет или открыть доступ к контенту\n",
            "на языке оригинала. *   Находить единомышленников, ездить на тематические мероприятия и развивать навыки.  Наш методист\n",
            "поможет вам найти подходящую цель и настроить курс под уровень языка так, чтобы достичь ее самым эффективным путем.\n",
            "Хотите попробовать нашу систему? Оставьте предзаказ на нашем сайте и получите доступ к бесплатному вводному уроку!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "yUvbYd11blwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: Общение с иностранными друзьями\"\n",
        "prez_user_question_llama(model_prez, system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c4a1c1d-0ed5-4293-87c7-90be3d80a6c3",
        "id": "XuiTCoPyblwH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 16.77 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Здравствуйте!   Я рада представить вам нашу программу курсов по английскому языку для делового общения. Это 31-урочная\n",
            "онлайн-программа, разделенная на 5 тематических модулей: Networking, Customer Care, Project Management, Leadership и\n",
            "Career ladder.  Этот курс идеально подходит для профессионалов, желающих получить работу в международной компании или\n",
            "улучшить свои навыки делового общения. Вы узнаете, как составлять резюме, вести переписку, участвовать в переговорах и\n",
            "многое другое.  Наша программа курса включает в себя:  * 31 онлайн-урок * 5 тематических модулей * Уроки, которые\n",
            "помогут вам начать разговор, знакомиться, находить нужные темы для беседы и многое другое  Вы также можете выбрать наш\n",
            "бесплатный курс английского языка, который подойдет тем, кто хочет прокачать язык самостоятельно и реально улучшить свои\n",
            "навыки.  Наше обучение доступно в различных форматах:  * Ситуации * Аудиокниги * Тренажёр слов * Видеопрактика  И уже\n",
            "103 000 учеников прокачивают английский с нашего сайта!  Если вы хотите улучшить свои навыки делового общения и получить\n",
            "работу в международной компании, то наш курс идеально подходит для вас.  Оставьте предзаказ на нашем сайте и получите\n",
            "доступ к нашим курсам!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель llama-3.1-70b"
      ],
      "metadata": {
        "id": "LXVA0y26d8W5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lun9dscgd8W6"
      },
      "source": [
        "Параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnMfj2BCd8W6"
      },
      "outputs": [],
      "source": [
        "# Задаем температуру генерации ответа\n",
        "# Температура 0 означает, что модель будет давать более детерминированные ответы, строго опираясь на предоставленный контекст\n",
        "temperature_prez = 0\n",
        "\n",
        "# Задаем количество релевантных чанков (фрагментов текста) для формирования ответа\n",
        "relevant_chanks = 3\n",
        "\n",
        "# Флаг для включения/выключения вывода релевантных чанков\n",
        "verbose_prez = 1\n",
        "\n",
        "# Имя модели, используемой для генерации ответов\n",
        "model_prez = llm\n",
        "\n",
        "max_tokens=1000 # Количество токенов на ответ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE-_RzfBd8W6"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359bef71-7c71-40b3-8a04-835675926b8d",
        "id": "P7-bRiuad8W7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 80.29 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Добрый день!  Если вы планируете путешествие за границу, важно чувствовать себя уверенно в общении с местными жителями.\n",
            "Наш бесплатный курс английского языка поможет вам улучшить свои навыки и комфортно чувствовать себя за границей.  На\n",
            "нашем курсе вы научитесь:  * Рассказывать об отпуске и узнавать про это у других * Читать городские знаки и узнавать\n",
            "путь * Держать себя в руках и понимать правила разных стран * Купить билет на автобус, самолет, пароход или любой другой\n",
            "вид транспорта  Кроме того, на нашем курсе вы узнаете о особенностях въезда в США, типах жилья, популярных на вечеринках\n",
            "играх и многом другом.  Пройдите первый урок бесплатно и познакомьтесь с нашей платформой. Если вы решите продолжить\n",
            "обучение, мы предложим вам бонусы при оплате нескольких занятий.  Оставьте предзаказ на нашем сайте и начните свой путь\n",
            "к уверенному общению на английском языке!\n"
          ]
        }
      ],
      "source": [
        "# Список выявленных потребностей\n",
        "needs = \"Цель:путешествие\"\n",
        "prez_user_question_llama(model_prez, system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, max_tokens);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "sd41vk_Zd8W7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: жить за границей\"\n",
        "prez_user_question_llama(model_prez, system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d733c3ca-ded4-4bf6-eb86-2e9824686905",
        "id": "OaZKb0tod8W7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 118.52 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Добрый день!  Если вы мечтаете жить за границей, то знание английского языка - это ключ к вашей новой жизни. Мы\n",
            "предлагаем вам бесплатный курс английского языка, который поможет вам улучшить свои навыки и подготовиться к переезду.\n",
            "Наш курс включает в себя:  * Полезные диалоги в посольстве, банке, страховой компании и других местах, где вы будете\n",
            "общаться на английском языке * Чек-листы по жизни за границей, которые помогут вам подготовиться к переезду * Реальный\n",
            "опыт эмиграции наших учителей, которые поделятся с вами своими историями и советами  Курс ответит на такие вопросы, как:\n",
            "* Как выбрать страну для эмиграции? * Как получить визу и пройти интервью в посольстве на английском языке? * Как найти\n",
            "жилье и перевезти свои вещи? * Как устроить ребенка в детский сад? * Как начать бизнес и открыть счет в банке?  Обучение\n",
            "проходит в удобном для вас формате: вы созваниваетесь с преподавателем на нашей платформе, общаетесь на английском и\n",
            "выполняете упражнения. Вы также можете заниматься в браузере или через мобильное приложение.  Получите бонусы от Skyeng\n",
            "при покупке нескольких занятий и освойте язык для любых целей: общения, новых возможностей или просто для того, чтобы\n",
            "провести время с пользой.  Уже 103 000 учеников прокачивают английский с нами. Присоединяйтесь к ним!  Оставьте\n",
            "предзаказ на нашем сайте и начните свой путь к новой жизни за границей.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "gJJn9YIwd8W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: работа в международной компании\"\n",
        "prez_user_question_llama(model_prez, system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0e035c-fcf4-4adf-e119-e3adb1c9dc01",
        "id": "an-vXd3gd8W8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 99.54 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Добрый день!  Если вы стремитесь к карьерному росту в международной компании, то знание английского языка является\n",
            "ключевым фактором успеха. Наш курс делового английского предназначен именно для таких целеустремленных людей, как вы.  В\n",
            "нашей программе вы найдете 31 онлайн-урок, разделенных на 5 тематических модулей: Networking, Customer Care, Project\n",
            "Management, Leadership и Career Ladder. Мы поможем вам развить навыки делового общения, необходимые для работы в\n",
            "международной компании.  Вы узнаете, как вести small talk, знакомиться с бизнес-партнерами, эффективно использовать\n",
            "конференции и многое другое. Наши уроки позволят вам начинать разговор, знакомиться, находить нужные темы для беседы и\n",
            "избегать острых тем.  Кроме того, наш курс технического английского для IT-специалистов поможет вам общаться с\n",
            "зарубежными коллегами, читать техническую документацию, разбираться в интерфейсе ПО и многое другое.  Если вы готовы\n",
            "сделать шаг вперед в своей карьере, оставьте предзаказ на нашем сайте и получите доступ к нашим курсам. Наш методист\n",
            "поможет вам найти подходящую цель и настроить курс под ваш уровень языка.  Не упустите возможность улучшить свои навыки\n",
            "и достичь успеха в международной компании. Оставьте предзаказ уже сегодня!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "R8RqHKMUd8W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: Лучше всех знать английский язык\"\n",
        "prez_user_question_llama(model_prez, system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fd62bd-5c34-485d-a6d2-86fab2e21070",
        "id": "rHAtKa1Bd8W9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 72.80 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Добрый день!  Мы предлагаем уникальные курсы по английскому языку, которые помогут вам достичь ваших целей и улучшить\n",
            "вашу карьеру. Наше обучение доступно в различных форматах, включая ситуации, аудиокниги, тренажёр слов и видеопрактику.\n",
            "Более 103 000 учеников уже улучшили свой английский с нами. Мы предлагаем тренировку произношения с голосовым вводом\n",
            "ответов и анализом произношения.  Наши курсы доступны в браузере и через мобильное приложение, что позволяет вам изучать\n",
            "английский в любое время и в любом месте.  Мы также предлагаем бесплатный вводный урок, который поможет вам найти\n",
            "подходящую цель и настроить курс под ваш уровень языка.  Выберите свою цель и начните изучать английский с нами уже\n",
            "сегодня!  Оставьте предзаказ на нашем сайте и получите доступ к нашим уникальным курсам и ресурсам.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "6as3RKGnd8W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: Общение с иностранными друзьями\"\n",
        "prez_user_question_llama(model_prez, system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, max_tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374dfc2e-4364-42b4-cfd5-3d2a68b8a6f8",
        "id": "XxJheCOyd8W9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 76.78 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Добрый день!  Если вы хотите общаться с иностранными друзьями, то наш курс английского языка для делового общения -\n",
            "идеальный выбор для вас.   В нашем курсе вы научитесь:  * Ведению small talk и стратегиям знакомства с бизнес-партнерами\n",
            "* Эффективному использованию конференций и деловой переписке * Нахождению нужных тем для беседы и избеганию острых тем *\n",
            "Поддержанию контакта после знакомства  Курс состоит из 31 онлайн-урока и 5 тематических модулей: Networking, Customer\n",
            "Care, Project Management, Leadership и Career ladder.  Помимо этого, у нас есть бесплатный курс английского, который\n",
            "подойдет тем, кто хочет прокачать язык самостоятельно. В нем вы найдете авторские материалы и задания для практики в\n",
            "удобном формате.  Если вы хотите улучшить свои навыки английского языка для общения с иностранными друзьями, то оставьте\n",
            "предзаказ на нашем сайте и начните обучение уже сегодня!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель GPT-4o-mini"
      ],
      "metadata": {
        "id": "5zmElqoldPTI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz05r3qb7gYs"
      },
      "source": [
        "Параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfNW8E-57gYs"
      },
      "outputs": [],
      "source": [
        "# Задаем температуру генерации ответа\n",
        "# Температура 0 означает, что модель будет давать более детерминированные ответы, строго опираясь на предоставленный контекст\n",
        "temperature_prez = 0\n",
        "\n",
        "# Задаем количество релевантных чанков (фрагментов текста) для формирования ответа\n",
        "relevant_chanks = 3\n",
        "\n",
        "# Флаг для включения/выключения вывода релевантных чанков\n",
        "verbose_prez = 1\n",
        "\n",
        "# Имя модели, используемой для генерации ответов\n",
        "model_prez = \"gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ji3ld9M7gYt"
      },
      "source": [
        "Запрос 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8fbd19b-231f-4818-ee2b-9914b0ab8978",
        "id": "dY3bJ6c-7gYt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 2.33 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Добрый день!  Если ваша цель — путешествия, мы предлагаем идеальное решение для комфортного общения за границей. Наши\n",
            "курсы английского языка помогут вам не только улучшить навыки, но и уверенно чувствовать себя в любой стране.  Вы\n",
            "сможете: - Легко общаться с местными жителями. - Ориентироваться в аэропортах и на вокзалах. - Понимать культурные\n",
            "нюансы и наслаждаться искусством в оригинале.  Начните с бесплатного урока, чтобы оценить качество обучения и\n",
            "познакомиться с нашей платформой.   Не упустите возможность сделать первый шаг к вашим путешествиям! Оставьте предзаказ\n",
            "на нашем сайте и начните обучение уже сегодня.\n"
          ]
        }
      ],
      "source": [
        "# Список выявленных потребностей\n",
        "needs = \"Цель:путешествие\"\n",
        "prez_user_question(system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, model= model_prez);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 2"
      ],
      "metadata": {
        "id": "qw8ipbEhndXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: жить за границей\"\n",
        "prez_user_question(system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, model= model_prez);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iB9hz8onxgU",
        "outputId": "bde6993d-cbfc-44c1-ccc4-09985dddce52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 2.57 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Добрый день!  Если ваша цель — жизнь за границей, мы можем помочь вам достичь её с помощью наших курсов английского\n",
            "языка. Мы предлагаем уникальные программы, которые охватывают все аспекты, необходимые для комфортной жизни в другой\n",
            "стране.  Наши курсы включают: - Практические диалоги для общения в посольствах, банках и других учреждениях. - Полезные\n",
            "советы по эмиграции, включая выбор страны, получение визы и адаптацию на новом месте. - Разнообразные форматы обучения:\n",
            "от ситуационных упражнений до видеопрактики, что позволяет учиться в удобное время и в любом месте.  С нами вы сможете\n",
            "не только улучшить язык, но и открыть новые горизонты для карьеры, общения и культурного обогащения.  Не упустите\n",
            "возможность! Оставьте предзаказ на нашем сайте и начните свой путь к новой жизни уже сегодня.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 3"
      ],
      "metadata": {
        "id": "1n9tdiMineOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: работа в международной компании\"\n",
        "prez_user_question(system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, model= model_prez);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjIWa6fOnyJz",
        "outputId": "fdc55fe4-3673-43fc-c51f-6de5e2bdefc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 3.32 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Добрый день!  Если ваша цель — работа в международной компании, мы предлагаем курсы, которые помогут вам достичь этого.\n",
            "Наша программа делового английского включает 31 онлайн-урок и 5 тематических модулей, охватывающих ключевые навыки,\n",
            "такие как деловая переписка, ведение переговоров и networking.   Вы сможете не только улучшить свои языковые навыки, но\n",
            "и научиться эффективно общаться с зарубежными коллегами, что откроет новые карьерные возможности.   Также у нас есть\n",
            "бесплатный самоучитель, который позволит вам прокачать язык самостоятельно в удобном формате.  Если вы готовы сделать\n",
            "шаг к своей цели, оставьте предзаказ на нашем сайте. Это ваш шанс начать обучение уже сегодня!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 4"
      ],
      "metadata": {
        "id": "Eop6FjOynesL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: Лучше всех знать английский язык\"\n",
        "prez_user_question(system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, model= model_prez);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBJYzo1MnysE",
        "outputId": "12fc2a2b-aa8f-400e-fbdf-87f0f88b09cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 2.33 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Добрый день!  Мы предлагаем уникальные курсы английского языка, которые помогут вам достичь ваших целей. Наша программа\n",
            "охватывает все аспекты языка: от общения с иностранными партнерами до чтения оригинальных произведений искусства.   Вы\n",
            "сможете учиться в удобном формате: через браузер или мобильное приложение, а также использовать разнообразные материалы\n",
            "— от аудиокниг до видеопрактики. Более 103 000 учеников уже выбрали нас для улучшения своих навыков.  Если вы хотите\n",
            "прокачать английский самостоятельно, у нас есть бесплатный самоучитель с авторскими заданиями.   Не упустите\n",
            "возможность! Оставьте предзаказ на нашем сайте и начните свой путь к свободному владению английским языком.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрос 5"
      ],
      "metadata": {
        "id": "Cj7KuBtEnfJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needs = \"Цель: Общение с иностранными друзьями\"\n",
        "prez_user_question(system_prompt_prez, instructions_prez, needs, db, temperature_prez, verbose_prez, relevant_chanks, model= model_prez);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwVZEcrtnzOy",
        "outputId": "0b26a797-e024-4353-a442-dc4205dec9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время ответа: 2.24 секунд\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Мы предлагаем курс английского языка, который идеально подходит для общения с иностранными друзьями и расширения ваших\n",
            "горизонтов. Программа включает 31 онлайн-урок, охватывающий ключевые аспекты делового общения, такие как networking,\n",
            "customer care и leadership.   Вы сможете уверенно вести беседы, знакомиться с новыми людьми и поддерживать контакты, а\n",
            "также развивать навыки, необходимые для карьерного роста и международных поездок.   Обучение доступно в удобном формате:\n",
            "на компьютере, планшете или через мобильное приложение.   Не упустите возможность улучшить свои навыки! Оставьте\n",
            "предзаказ на нашем сайте и начните обучение уже сегодня.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEogfmrP7gY5"
      },
      "source": [
        "# Диалог"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fdf06cb-03ae-4799-e37b-1ce676390fe0",
        "cellView": "form",
        "id": "V7mkSAbl62P9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Здравствуйте, я нейро-консультант школы английского языка Skyeng. Чем я могу Вам помочь? \n",
            "\n",
            "Вопрос клиента:как у вас происходит обучение?\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Мы подбираем план обучения под потребности и цели каждого ученика, используя проверенную коммуникативную методологию и систему контроля прогресса. Это позволяет ученикам начать использовать язык уже с первого занятия.\n",
            "Как вы думаете, что могло бы помочь вам сохранять мотивацию и интерес к изучению английского языка?\n",
            "\n",
            "Вопрос клиента:я вспоминаю конечную цель и это меня вдохновляет\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Я думаю, что помочь сохранять мотивацию и интерес к изучению английского языка могут следующие факторы:\n",
            "\n",
            "- Установление четкой цели и плана обучения.\n",
            "- Регулярные достижения и прогресс в изучении языка.\n",
            "- Возможность выбора интересных и актуальных тем для изучения.\n",
            "- Поддержка и мотивация от преподавателя и сообщества учеников.\n",
            "- Использование различных методов обучения и материалов, чтобы избежать монотонности.\n",
            "\n",
            "Также, как вы упомянули, вспоминание конечной цели и ее важности для личной и профессиональной жизни может быть мощным мотиватором.\n",
            "Могли бы вы рассказать мне о том, как вы представляете свою жизнь после того, как вы достигнете своей конечной цели по изучению английского языка?\n",
            "\n",
            "Вопрос клиента:я работаю middle разработчиком в области искусственного интеллекта\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Я представляю свою жизнь после достижения конечной цели по изучению английского языка как жизнь, полную возможностей и перспектив. Я могу свободно общаться с коллегами и партнерами из разных стран, принимать участие в международных конференциях и проектах, и в конечном итоге, это поможет мне в моей карьере middle разработчика в области искусственного интеллекта.\n",
            "Могли бы вы рассказать мне о том, как вы видите себя в своей профессиональной карьере в области искусственного интеллекта через 5 лет после того, как вы достигнете своей конечной цели по изучению английского языка?\n",
            "\n",
            "Вопрос клиента:senior в иностранной IT компании\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Давайте разберем все вместе.\n",
            "\n",
            "Нам нужно создать курс, который поможет вам улучшить свои навыки английского языка и повысить свой карьерный рост в области искусственного интеллекта. Мы понимаем, что вы уже начали учить английский, но бросили из-за скучности. Нам нужно сделать этот курс интересным и эффективным.\n",
            "\n",
            "Наш курс будет включать в себя несколько передовых образовательных методик, которые помогут вам развить свои языковые навыки и soft skills одновременно. Мы предлагаем персонализированное обучение, которое поможет вам настроить программу под ваши особенности и повысить уровень языка.\n",
            "\n",
            "Наш курс будет включать в себя 5 тематических модулей:\n",
            "\n",
            "1. Networking - вы узнаете, как ведется small talk, стратегии знакомства с бизнес-партнерами онлайн и лично, секреты эффективного использования конференций TEDxSadovoeRing Conference.\n",
            "2. Customer Care - вы узнаете, как поддерживать отношения с клиентами и решать проблемы.\n",
            "3. Project Management - вы узнаете, как планировать и управлять проектами.\n",
            "4. Leadership - вы узнаете, как лидировать и мотивировать команду.\n",
            "5. Career ladder - вы узнаете, как подняться по карьерной лестнице и достичь своих целей.\n",
            "\n",
            "Наш курс будет включать в себя 31 онлайн-урок и будет полезен профессионалам, желающим получить работу в международной компании.\n",
            "\n",
            "Мы понимаем, что вы хотите получить результаты и повысить свой карьерный рост. Наш курс поможет вам:\n",
            "\n",
            "* Вырасти в должности\n",
            "* Повысить квалификацию за границей и учиться у зарубежных коллег\n",
            "* Посещать международные конференции и форумы, выступать на них\n",
            "* Изучать профессиональную литературу от иностранных авторов\n",
            "* Получить должность в зарубежной компании\n",
            "* Вести совместные проекты с коллегами из-за рубежа\n",
            "* Продавать товары и оказывать услуги иностранным клиентам\n",
            "* Привлекать инвестиции со всего мира и многое другое.\n",
            "\n",
            "Нам нужно, чтобы вы оставили предзаказ на нашем сайте, чтобы мы могли начать работать над вашим курсом и помочь вам достичь своих целей.\n",
            "Что бы Вы хотели еще узнать? \n",
            "\n",
            "Вопрос клиента:есть ли пробное занятие?\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Да, у нас есть пробное занятие. Вы можете пройти его бесплатно и познакомиться с нашим обучением.\n",
            "\n",
            "Вопрос клиента:стоп\n"
          ]
        }
      ],
      "source": [
        "#@title Запуск диалога Llama-3.1-8b\n",
        "# Инициализация списков для хранения истории чата, вопросов клиента и ответов менеджера\n",
        "history_chat = []\n",
        "history_user = []\n",
        "history_manager = []\n",
        "history_potr = []\n",
        "\n",
        "# Вывод ответов агентов\n",
        "verbose_router = 0\n",
        "verbose = 0\n",
        "verbose_question = 0\n",
        "verbose_prez = 0\n",
        "verbose_stilist = 0\n",
        "\n",
        "model = llm\n",
        "\n",
        "# Приветственное сообщение\n",
        "welcome_message = \"\"\"Здравствуйте, я нейро-консультант школы английского языка Skyeng. Чем я могу Вам помочь? \"\"\"\n",
        "\n",
        "# Добавление приветственного сообщения в историю чата и ответов\n",
        "history_chat.append(f\"Менеджер: {welcome_message}\")\n",
        "history_manager.append(welcome_message)\n",
        "print(welcome_message)\n",
        "\n",
        "# Бесконечный цикл для общения с клиентом\n",
        "first_question = True\n",
        "\n",
        "first_question_2 = True\n",
        "\n",
        "keywords_matched = False  # Флаг для отслеживания совпадения ключевых слов\n",
        "\n",
        "while True:\n",
        "    print()\n",
        "    # Получение вопроса от клиента\n",
        "    client_question = input('Вопрос клиента:')\n",
        "\n",
        "    # Добавление вопроса клиента в историю вопросов и чата\n",
        "    history_user.append(client_question)\n",
        "    history_chat.append(f\"Клиент: {client_question}\")\n",
        "\n",
        "    # Проверка, если клиент ввел 'stop' или 'стоп', прерываем цикл\n",
        "    if client_question.lower() in ['stop', 'стоп']:\n",
        "        break\n",
        "\n",
        "    # Генерация ответа от роутера на вопрос клиента\n",
        "    if first_question:\n",
        "        router_input = f\"Менеджер: {history_manager[-1]} Клиент: {history_user[-1]}\"\n",
        "        first_question = False\n",
        "    else:\n",
        "        router_input = f\"Менеджер: {answer_2} Клиент: {client_question}\"\n",
        "\n",
        "\n",
        "    router_response = user_question_router_llama(model=model,\n",
        "                                                 system=system_prompt_router,\n",
        "                                           instructions=instructions_router,\n",
        "                                           topic=router_input,\n",
        "                                           temp=temperature_router, verbose=verbose_router,\n",
        "                                           max_tokens=1000)\n",
        "\n",
        "\n",
        "    # Добавление ответа роутера в историю потребностей\n",
        "    history_potr.append(router_response)\n",
        "\n",
        "    #print(\"Отчет о потребностях: \", history_potr)\n",
        "    # Проверка результата роутера\n",
        "\n",
        "    if len(history_potr)>3: # Когда сделана презентация и выявлены потребности - свободные ответы на вопросы\n",
        "        #print(\"Ветка 2\")\n",
        "        if keywords_matched == False:\n",
        "            answers_test = user_potr_llama(model, history_potr, temp=0, verbose=0, max_tokens=1000)\n",
        "            #print(\"Основная потребность:\", answers_test)\n",
        "                # Генерация ответа менеджера с помощью prez_user_question\n",
        "            answer_prez = prez_user_question_d_llama(model, system_prompt_prez, instructions_prez, answers_test, db, temp=temperature_prez, verbose=1, k=relevant_chanks, max_tokens=1000)\n",
        "                # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "            #answer = stilizator_answer_d_llama(model, system_prompt_stilist_prez, instructions_stilist, answer_prez, temperature_stilist, verbose=1, max_tokens=1000)\n",
        "\n",
        "            test_mes = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "            print(test_mes)\n",
        "\n",
        "            keywords_matched = True  # Устанавливаем флаг, чтобы больше не входить в эту ветку\n",
        "\n",
        "        else:\n",
        "\n",
        "            answer = answer_kons_d_llama(model, system, instruction, client_question, db, history_chat, temperature, verbose, relevant_chanks, max_tokens=1000)\n",
        "            print(answer)\n",
        "\n",
        "        #print(answer)\n",
        "\n",
        "\n",
        "    else: # Когда не выявлены потребности\n",
        "        #print(\"Ветка 3\")\n",
        "        # Генерация ответа от роутера на вопрос клиента\n",
        "        if first_question_2:\n",
        "            answer_vopros = user_question_llama(model, system_prompt_question, instructions_question, client_question, temp=temperature_question, verbose=verbose_question, max_tokens=1000)\n",
        "            first_question_2 = False\n",
        "        else:\n",
        "            client_question_2 = answer_2 + client_question\n",
        "            answer_vopros = user_question_llama(model, system_prompt_question, instructions_question, client_question_2, temp=temperature_question, verbose=verbose_question, max_tokens=1000)\n",
        "        # Генерация ответа менеджера с использованием функций answer_kons и spez_user_question\n",
        "        answer_1 = answer_kons_d_llama(model, system, instruction, answer_vopros, db, history_chat, temperature, verbose, relevant_chanks, max_tokens=1000)\n",
        "        answer_2 = spez_user_question_llama(model, system_prompt_potr, instructions__potr, router_response, history_chat, temp, verbose=0, max_tokens=1000)\n",
        "\n",
        "        # Объединение первого и второго ответов менеджера\n",
        "        #answer_stilist = answer_1 + answer_2\n",
        "        # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "        #answer_stilist = stilizator_answer_d_llama(model, system_prompt_stilist, instructions_stilist, answer_1, temperature_stilist, verbose=1, max_tokens=1000)\n",
        "        answer = answer_1 +\"\\n\"+ answer_2\n",
        "        print(answer)\n",
        "\n",
        "    # Добавление ответа менеджера в историю чата и ответов\n",
        "    history_chat.append(f\"Менеджер: {answer}\")\n",
        "    history_manager.append(answer)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77e603a-bddb-432b-a958-dd5f52e4bc37",
        "cellView": "form",
        "id": "i-iGk9kfS-9T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Здравствуйте, я нейро-консультант школы английского языка Skyeng. Чем я могу Вам помочь? \n",
            "\n",
            "Вопрос клиента:как у вас происходит обучение?\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Мы подбираем план обучения под потребности и цели каждого ученика и, самое главное, доводим до результата с помощью проверенной коммуникативной методологии и системы контроля прогресса.\n",
            "Вы когда-нибудь думали о том, чтобы улучшить свой английский язык для личного развития или хобби?\n",
            "\n",
            "Вопрос клиента:нет, я хочу работать в иностранной IT компании\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Чтобы улучшить свой английский язык для работы в иностранной IT компании, можно начать с изучения технического английского языка, который включает в себя уроки по коммуникации и работе в команде. Это поможет вам научиться общаться с зарубежными коллегами, читать техническую документацию, разбираться в интерфейсе ПО и заниматься программированием сайтов и других продуктов.\n",
            "Вы планируете работать в конкретной стране или готовы рассматривать предложения из разных стран?\n",
            "\n",
            "Вопрос клиента:я хочу работать удаленно и готов рассматривать предложения из разных стран\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Если вы готовы рассматривать предложения из разных стран, то изучение английского языка будет особенно полезно для вас. Английский язык является lingua franca в международном бизнесе и будет открывать для вас возможности работать с компаниями из разных стран.\n",
            "Вы планируете использовать английский язык только для профессиональной коммуникации или также хотели бы улучшить его для общения с коллегами неформально?\n",
            "\n",
            "Вопрос клиента:в основном для профессиональной коммуникации\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            " Добрый день!\n",
            "\n",
            "Если вы стремитесь построить успешную карьеру в иностранной IT компании, то знание английского языка является ключевым фактором вашего успеха. Наш курс \"Английский для IT специалистов\" предназначен именно для вас.\n",
            "\n",
            "Он разработан для технических сотрудников, которые хотят улучшить свои навыки английского языка и повысить свою квалификацию в сфере IT. Программа курса включает в себя несколько ключевых навыков, которые помогут вам не только улучшить знание языка, но и развить soft skills.\n",
            "\n",
            "Вы научитесь общаться с зарубежными коллегами, читать техническую документацию, разбираться в интерфейсе ПО и многое другое. Кроме того, вы получите возможность прокачать soft skills, такие как планирование времени, распределение ресурсов и выстраивание приоритетов.\n",
            "\n",
            "Наш курс основан на передовых образовательных методиках, включая персонализированное обучение, коммуникативную методику и предметно-языковое интегрированное обучение.\n",
            "\n",
            "Вы сможете общаться с преподавателем 80% урока, а не ждать удобного момента. Кроме того, вы получите возможность улучшить свои профессиональные знания во время изучения языка.\n",
            "\n",
            "Если вы заинтересованы в нашем курсе, мы предлагаем оставить предзаказ на сайте. Наш методист поможет вам найти подходящую цель и настроить курс под ваш уровень языка.\n",
            "\n",
            "Не упустите возможность построить успешную карьеру в иностранной IT компании. Оставьте предзаказ на сайте и начните свой путь к успеху уже сегодня!\n",
            "Что бы Вы хотели еще узнать? \n",
            "\n",
            "Вопрос клиента:есть ли пробное занятие?\n",
            "\n",
            "==================\n",
            "Менеджер:\n",
            "Да, есть пробное занятие. На нем мы познакомимся, проверим уровень языка и покажем, как проходят занятия на онлайн-платформе.\n",
            "\n",
            "Вопрос клиента:стоп\n"
          ]
        }
      ],
      "source": [
        "#@title Запуск диалога Llama-3.1-70b\n",
        "# Инициализация списков для хранения истории чата, вопросов клиента и ответов менеджера\n",
        "history_chat = []\n",
        "history_user = []\n",
        "history_manager = []\n",
        "history_potr = []\n",
        "\n",
        "# Вывод ответов агентов\n",
        "verbose_router = 0\n",
        "verbose = 0\n",
        "verbose_question = 0\n",
        "verbose_prez = 0\n",
        "verbose_stilist = 0\n",
        "\n",
        "model = llm\n",
        "\n",
        "# Приветственное сообщение\n",
        "welcome_message = \"\"\"Здравствуйте, я нейро-консультант школы английского языка Skyeng. Чем я могу Вам помочь? \"\"\"\n",
        "\n",
        "# Добавление приветственного сообщения в историю чата и ответов\n",
        "history_chat.append(f\"Менеджер: {welcome_message}\")\n",
        "history_manager.append(welcome_message)\n",
        "print(welcome_message)\n",
        "\n",
        "# Бесконечный цикл для общения с клиентом\n",
        "first_question = True\n",
        "\n",
        "first_question_2 = True\n",
        "\n",
        "keywords_matched = False  # Флаг для отслеживания совпадения ключевых слов\n",
        "\n",
        "while True:\n",
        "    print()\n",
        "    # Получение вопроса от клиента\n",
        "    client_question = input('Вопрос клиента:')\n",
        "\n",
        "    # Добавление вопроса клиента в историю вопросов и чата\n",
        "    history_user.append(client_question)\n",
        "    history_chat.append(f\"Клиент: {client_question}\")\n",
        "\n",
        "    # Проверка, если клиент ввел 'stop' или 'стоп', прерываем цикл\n",
        "    if client_question.lower() in ['stop', 'стоп']:\n",
        "        break\n",
        "\n",
        "    # Генерация ответа от роутера на вопрос клиента\n",
        "    if first_question:\n",
        "        router_input = f\"Менеджер: {history_manager[-1]} Клиент: {history_user[-1]}\"\n",
        "        first_question = False\n",
        "    else:\n",
        "        router_input = f\"Менеджер: {answer_2} Клиент: {client_question}\"\n",
        "\n",
        "\n",
        "    router_response = user_question_router_llama(model=model,\n",
        "                                                 system=system_prompt_router,\n",
        "                                           instructions=instructions_router,\n",
        "                                           topic=router_input,\n",
        "                                           temp=temperature_router, verbose=verbose_router,\n",
        "                                           max_tokens=1000)\n",
        "\n",
        "\n",
        "    # Добавление ответа роутера в историю потребностей\n",
        "    history_potr.append(router_response)\n",
        "\n",
        "    #print(\"Отчет о потребностях: \", history_potr)\n",
        "    # Проверка результата роутера\n",
        "\n",
        "    if len(history_potr)>3: # Когда сделана презентация и выявлены потребности - свободные ответы на вопросы\n",
        "        #print(\"Ветка 2\")\n",
        "        if keywords_matched == False:\n",
        "            answers_test = user_potr_llama(model, history_potr, temp=0, verbose=0, max_tokens=1000)\n",
        "            #print(\"Основная потребность:\", answers_test)\n",
        "                # Генерация ответа менеджера с помощью prez_user_question\n",
        "            answer_prez = prez_user_question_d_llama(model, system_prompt_prez, instructions_prez, answers_test, db, temp=temperature_prez, verbose=1, k=relevant_chanks, max_tokens=1000)\n",
        "                # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "            #answer = stilizator_answer_d_llama(model, system_prompt_stilist_prez, instructions_stilist, answer_prez, temperature_stilist, verbose=1, max_tokens=1000)\n",
        "\n",
        "            test_mes = \"\"\"Что бы Вы хотели еще узнать? \"\"\"\n",
        "            print(test_mes)\n",
        "\n",
        "            keywords_matched = True  # Устанавливаем флаг, чтобы больше не входить в эту ветку\n",
        "\n",
        "        else:\n",
        "\n",
        "            answer = answer_kons_d_llama(model, system, instruction, client_question, db, history_chat, temperature, verbose, relevant_chanks, max_tokens=1000)\n",
        "            print(answer)\n",
        "\n",
        "        #print(answer)\n",
        "\n",
        "\n",
        "    else: # Когда не выявлены потребности\n",
        "        #print(\"Ветка 3\")\n",
        "        # Генерация ответа от роутера на вопрос клиента\n",
        "        if first_question_2:\n",
        "            answer_vopros = user_question_llama(model, system_prompt_question, instructions_question, client_question, temp=temperature_question, verbose=verbose_question, max_tokens=1000)\n",
        "            first_question_2 = False\n",
        "        else:\n",
        "            client_question_2 = answer_2 + client_question\n",
        "            answer_vopros = user_question_llama(model, system_prompt_question, instructions_question, client_question_2, temp=temperature_question, verbose=verbose_question, max_tokens=1000)\n",
        "        # Генерация ответа менеджера с использованием функций answer_kons и spez_user_question\n",
        "        answer_1 = answer_kons_d_llama(model, system, instruction, answer_vopros, db, history_chat, temperature, verbose, relevant_chanks, max_tokens=1000)\n",
        "        answer_2 = spez_user_question_llama(model, system_prompt_potr, instructions__potr, router_response, history_chat, temp, verbose=0, max_tokens=1000)\n",
        "\n",
        "        # Объединение первого и второго ответов менеджера\n",
        "        #answer_stilist = answer_1 + answer_2\n",
        "        # Стилизация объединенного ответа с использованием функции stilizator_answer\n",
        "        #answer_stilist = stilizator_answer_d_llama(model, system_prompt_stilist, instructions_stilist, answer_1, temperature_stilist, verbose=1, max_tokens=1000)\n",
        "        answer = answer_1 +\"\\n\"+ answer_2\n",
        "        print(answer)\n",
        "\n",
        "    # Добавление ответа менеджера в историю чата и ответов\n",
        "    history_chat.append(f\"Менеджер: {answer}\")\n",
        "    history_manager.append(answer)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g1gTmyg1Njkc",
        "gzYUtDYXRWQO",
        "x0kRQto9VI8H",
        "sva8njDmagMo",
        "5zmElqoldPTI",
        "Y2ZcOP_2k5Hi"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}